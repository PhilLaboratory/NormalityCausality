---
title: "Normal Causation"
author: "| Catherine Holland and others and \n| Jonathan Phillips\n"
date: "12/2021"
output:
  html_document:
    df_print: paged
  pdf_document:
    fig_caption: yes
shorttitle: Normal Causation
bibliography: r-references.bib
csl: apa.csl
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Intro:

Alice was supposed to take the train to visit her parents, but she was not attentive to the time. When she rushed to the station, the train doors were closing. The conductor saw Alice running toward the train and he could briefly open the door to let her in because she was the only one on the platform and there was still time till the departure. However, the conductor chose not to in order to ensure safety and to avoid any additional hassle. Later that day, Alice learned from the news that the train she missed got into an accident and she thought to herself: "I dodged the accident because the conductor didn't want to open the door for me!" Instead of considering both her lateness and the conductor's not opening the door, Alice chose the latter to be the cause of her being able to avoid the accident and this act can be termed as "causal selection". Just like Alice, we perform causal selection in our daily life. 

There are two types of norms that are important to causal cognition: descriptive and prescriptive norms. Descriptive norms refer to how people generally behave while prescriptive norms refer to how people believe we should behave. Prior research has found that both types of norms affect how we think of the cause of an outcome. There has been a number of competing explanations for this effect. For descriptive norms, most researchers believe that the effect is best accounted for by the standard processes of causal reasoning. However, for prescriptive norms, opinions differ. Some believe that the effect simply stems from the responsibility judgment, especially when the outcome is adverse, while others have argued for a more general account emphasizing the general role of normality in causal judgments for both descriptive and prescriptive norms.  

We bring in new perspectives to the debate. First, we compare two kinds of prescriptive norms: rationality and morality. Second, we investigate the importance of whether the agent is knowledgeable about violating a norm. Third, unlike prior work, we separate the normality of the action and the valence of the outcome, and we ask whether the effect of the former changes depending on the latter. Fourth, we examine whether descriptive normality of the outcome impacts causal judgments. Accordingly, we add four new findings to the field. First, our studies provide evidence in favor of the general normality account as the two prescriptive norms - rational norms and moral norms - exert similar influence in causal judgment. Second, agent's ignorance about norm violation affects both kinds of norms similarly. Third, both effects are moderated by the valence of the outcome as well as the descriptive normality of the outcome. Fourth, both effects discussed above can be explained by the counterfactual judgment, which provides further support to the theory that normality affects causal judgments by affecting counterfactuals. 





## Descriptive Norms
Descriptive norms, including statistical norms, shape judgments of causal selection; specifically, events which violate descriptive norms (e.g., low probability events) are often selected as the cause of later events that depended on their occurrence. It has long been discussed that causal judgments may be sensitive to norm violations or expectations about what will occur (Gorovitz, 1965; Hart & Honor√©, 1985; Hilton & Slugoski, 1986; Kahneman & Miller,1986). More recent studies delve into the mechanisms of statistical norm violation in cognition and several models have been proposed to account for the effect. For instance, the counterfactual simulation model (CSM) constructed by Gerstenberg and colleagues shows that the difference between the counterfactual considered and what in fact happened factors into people's causal judgment (2014). Later, researchers expanded the model, arguing that when an unexpected action led to a favorable outcome, the actor would be given credit but when an unexpected action led to an unfavorable outcome, the actor would be assigned blame (Stephan et al., 2017). Furthermore, more credit would be given or more blame would be assigned to agents who are believed to be dispositionally good or bad at acting optimally because when predicting future behavior, people make inferences about agents based on the action history of the latter (Gerstenberg et al., 2017). More specifically, researchers have argued that statistical normality exerts influence on people's causal judgment through probabilistic sampling (Hitchcock & Knobe, 2009). And people's understanding of norms, such as the strength of norm violation, also plays an important role in the causal calculation (Icard et al., 2017). A key concept, counterfactual potency, is constructed to measure the "strength and impact of counterfactual" and has performed well in predicting the impact of counterfactual reasoning in causal judgments (Petrocelli et al., 2011). In addition, the effect of assigning more causation to low probability events is present regardless of the valence of the outcome and it also affects causal attribution to other agents, while higher frequency of norm violation are associated with increased causal attribution (Kominsky et al., 2015; Kirfel & Lagnado, 2017).

## Prescriptive Norms
Prescriptive norms, including moral norms and rational norms, have been shown to have similar effects as descriptive norms: immoral actions, for example, tend to be selected as the causes of later events that depended on their occurrence (Alicke, 1992). Moreover, moral norms have been shown to play a distinct part by itself in causal cognition (Knobe & Fraser, 2008; Knobe, 2010). Important models proposed for moral norms include the culpable control model, the counterfactual reasoning in causal selection model and the accountability hypothesis (Alicke, 2000; Samland & Waldmann, 2016). The three models attempt to decipher the causal attribution by, respectively, referring to people's exaggeration of the causal strength of moral norm violation, tendency to consider abnormal counterfactuals over normal ones, and propensity to consider factors that are present in moral reasoning generally (Samland & Waldmann, 2016). However, there is no consensus in sight on which account is the most favorable. And as in the case of descriptive norms, the relevance of moral norms is quite important in the reasoning process (Phillips et al., 2015).

## Ongoing Debate
There is an ongoing debate about whether the two effects discussed above should be understood as arising from the normal process by which people make causal judgments. On the one hand, many have argued that they should not, and that the effect of moral norms or statistical norms are not part of the process of causal reasoning. Rather, the significant element in the causal reasoning is the valence of the situation or ascription of responsibility (Samland & Waldman, 2016; Alicke et al., 2011; Livengood et al., 2017). On the other hand, a number of researchers have argued that they should both be understood as part of the normal process of causal judgments and counterfactual structure by appealing to the role of counterfactuals in causal cognition. Relevant studies suggest taking the route of a unified account of modality or a high-level representation of general possibilities (Phillips et al., 2015; Phillips & Knobe, 2018).

Using empirical experiments reported below, we contribute to the existing debate in several ways. First, we consider a new kind of norm violations, rational norm violations, and find that they have the same impact as moral norm violations (see Johnson & Rips, 2015 and Halpern & Hitchcock, 2015 for previous work on what effect violating rational norms has on causal judgments). Second, we replicate the previously demonstrated outcome moderation effects where negative outcomes are more associated with causal attribution than positive outcomes. but also find that they occur for rational norm violations, further prompting the search for a theory that is not specific to moral norm violations. Third, we find that all of the above-mentioned effects are mediated by partcipants'counterfactual judgments [needs further investigation]. Fourth, we demonstrate that these outcome effects are not driven by the valence of the outcome but rather by the normality of the outcome by showing that the same pattern is more frequently observed in the cases of abnormal outcomes than normal outcomes. Finally, we test three different accounts of these effects, one that depends only on the morality of the events, one that depends only on the probability of the events, and one that depends on the normality of the events. We find that the normality accounts best captures people's causal judgments, which calls for a unifying model of causal judgments that is grounded in the normality of relevant events.
```{r load_pkg, include=FALSE}
#install.packages("wesanderson", repos = "http://cran.us.r-project.org")
#install.packages("lme4", repos = "http://cran.us.r-project.org")
#install.packages("gridExtra", repos = "http://cran.us.r-project.org")
#install.packages("mediation", repos = "http://cran.us.r-project.org")
library(wesanderson)
library(lme4)
library(gridExtra)
library(mediation)
library(tidyverse)
library(tinytex)
library(apa)
library(dplyr)
#setwd("~/Dropbox (Dartmouth College)/causalityNormality/data")
library(emmeans)
library(lmerTest)
library(pbkrtest)
```

# Experiment 1: Characterizing moral norm violations in causal chains

In experiment 1, 

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

```{r study1 participants, echo=FALSE, warning=FALSE, message=FALSE}
d1demo <- read.csv("../data/d2demo.csv") # remember that we aren't including the first study with only 3 vignettes
d1demo$age[d1demo$age==1993] <- NA ## one person entered their age as 1993 (presumably the year that they were born) 
d1demo$gender <- factor(c("Male","Female")[d1demo$gender])
d1demo$edu <- factor(c("Grammar School","Highschool or Equivalent","Vocational/Technical School",
                                 "Some College","College Graduate (4 years)","Master's Degree",
                                 "Doctoral Degree (PhD)","Professional Degree (JD,MD,etc.)","Other")[d1demo$edu])
##Age and Gender
d1.age <- matrix(c("mean",mean(d1demo$age,na.rm=T),"sd",sd(d1demo$age,na.rm=T),"n",length(d1demo$age)),ncol = 3)

d1.ageMean <- mean(d1demo$age, na.rm=T)
  
d1.gender <- table(d1demo$gender, exclude=NULL)

###Education
d1.education <- table(d1demo$edu)


```

In Experiment 1, `r d1.age[2,3]` participants (*M*~age~=`r round(mean(d1demo$age, na.rm=T),digits=2)`, *SD*~age~=`r round(sd(d1demo$age, na.rm=T),digits=2)`; `r d1.gender[[1]]` females) were recruited through Amazon Mechanical Turk (<http://www.mturk.com>).

### Materials

Participants completed 24 trials which each involved reading a brief vignette about a causal chain that was initiated by a distal cause, which led to some immediate outcome. This immediate outcome was then the more proximal cause a second, further outcome. This eventual outcome was either described a positive or negative, and the distal cause was described as either a knowledgeable agent (who knew that his action would lead to the occurrence of the secondary outcome), or an ignorant agent (who didn't know that his action would lead to the occurrence of the secondary outcome) or an inanimate object. Thus, for example, participants may have read a vignette in which an agent acted with the knowledge that the action in question would result in the occurrence of a bad outcome:

> **Knowledgeable Agent / Bad Outcome**:A farmer plans to clear a plot of land near a forest of rare trees to expand the area in which he can grow his cash crops. As he is clearing this area, an environmentalist sees him and tells him that if he clears this plot of land, he'll actually kill the rare trees in the forest by getting rid of a vine that has been protecting the trees' roots. The farmer replies that he does not care at all about the trees, he just wants to make more money by planting cash crops. He finishes clearing the land and makes more money selling his new crops just like he planned. Not long after the vine is removed, the trees lose all their leaves.

To continue to illustrate with this example, we also altered this vignette in the Ignorant Agent conditions so that the agent simply had no way of knowing that clearing the land would lead the trees to be damaged. In the Inanimate Object conditions, we replaced the farmer with a flood that cleared the same plot of land. Finally in the conditions where the action eventuated in a Good Outcome, the vine was described has having been damaging the tree's roots and thus removing the vine caused the trees to grow new leaves.

### Procedure

After reading each vignette, participants answered two questions about the events that had occurred. The first asked them to rate their agreement with a statement about the distal agent causing the outcome, as in the following example:

> *Causal question*: The farmer caused the trees to lose all their leaves.

\noindent Participants responded to each of these questions on a scale from 1 ("Completely disagree") to 7 ("Completely agree"). The second question asked participants to complete a counterfactual question, as in the following example:

> *Counterfactual question*: If only $\underline{\hspace{3cm}}$ had been different, the trees wouldn't have lost their leaves.

> a.  The farmer
> b.  The vine

\noindent After completing all 24 trials, participants were asked to complete some optional demographic questions.

### Data analysis

No participants were excluded from the analyses as long as they completed the entire study. The primary analyses were conducted with linear mixed-effects models and included random effects for both participnts and scenarios. These analyses were carried out using the the lme4 pacakage in $\textsf{R}$ [@bates2014lme4]. The significance of an effect for particular factor is calculated by comparing two linear mixed-effects models that vary only in whether factor in question was included in the fixed-effects structure. to the extent that the models differ significantly in their fit, this provides evidence that the factor in question signficantly affected participants' responses.

## Results

```{r study1 Causeanalyses, echo=FALSE, warning=FALSE, message=FALSE}
d1 <- read.csv("../data/Study2.csv")

d1$Agent <- factor(c("Knowledge","Ignorance","Object")[d1$Agent])
d1$Agent <- factor(d1$Agent, levels=c("Object", "Ignorance","Knowledge"))
d1$Outcome <- factor(c("Good","Bad")[d1$Outcome])
d1$Outcome <- factor(d1$Outcome, levels=c("Good","Bad"))

d1$causeS <- scale(d1$Cause)
  
## Interaction:
# lmr1.0 <- lmer(causeS ~ Agent * Outcome + (Agent*Outcome|Subj) + (1|Vignette), data=d1)
# lmr1.1 <- lmer(causeS ~ Agent + Outcome + (Agent*Outcome|Subj) + (1|Vignette), data=d1) #uncon
# lmr1.i <- anova(lmr1.0,lmr1.1)
# saveRDS(lmr1.i,"models/lmr1i.rds")
lmr1.i <- readRDS("models/lmr1i.rds")


## main effect of agent
# lmr1.2 <- lmer(causeS ~ Outcome + (Agent*Outcome|Subj) + (1|Vignette), data=d1)
# lmr1.a <- anova(lmr1.1,lmr1.2)
# saveRDS(lmr1.a,"models/lmr1a.rds")
lmr1.a <- readRDS("models/lmr1a.rds")

# effect of outcome (allcom)
# lmr1.3 <- lmer(causeS ~ Agent + (Agent*Outcome|Subj) + (1|Vignette), data=d1)
# lmr1.o <- anova(lmr1.1,lmr1.3)
# saveRDS(lmr1.o,"models/lmr1o.rds")
lmr1.o <- readRDS("models/lmr1o.rds")

d1.sumA <- d1 %>% 
  select(Agent,Cause,Subj) %>%
  group_by(Agent,Subj) %>%
  summarise(CauseM = mean(Cause),na.rm=TRUE) %>%
  group_by(Agent) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))

d1.sumO <- d1 %>% 
  select(Outcome,Cause,Subj) %>%
  group_by(Outcome,Subj) %>%
  summarise(CauseM = mean(Cause),na.rm=TRUE) %>%
  group_by(Outcome) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))

d1.sum <- d1 %>% 
  select(Agent,Outcome,Cause,Subj) %>%
  group_by(Agent,Outcome,Subj) %>%
  summarise(CauseM = mean(Cause),na.rm=TRUE) %>%
  group_by(Agent,Outcome) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))
```

#### Causal judgments

We first analyzed participants' causal judgments, which revealed a main effect of the kind of *Agent* the distal event involved, $\chi^2(2)$ = `r round(lmr1.a$Chisq[2],digits=2)`, *p* $<$ `r max(.001,round(lmr1.a$'Pr(>Chisq)'[2],digits=3))`, such that ignorant agents were overall seen as less causal (*M* = `r round(d1.sumA$mean[d1.sumA$Agent=="Ignorance"],digits=1)`, *SD* = `r round(d1.sumA$sd[d1.sumA$Agent=="Ignorance"],digits=1)`) than knowledgeable agents (*M* = `r round(d1.sumA$mean[d1.sumA$Agent=="Knowledge"],digits=1)`, *SD* = `r round(d1.sumA$sd[d1.sumA$Agent=="Knowledge"],digits=1)`), or inanimae objects (*M* = `r round(d1.sumA$mean[d1.sumA$Agent=="Object"],digits=1)`, *SD* = `r round(d1.sumA$sd[d1.sumA$Agent=="Object"],digits=1)`). We also observed a main effect of the kind of *Outcome* that eventuated, $\chi^2(2)$ = `r round(lmr1.o$Chisq[2],digits=2)`, *p* $<$ `r max(.001,round(lmr1.o$'Pr(>Chisq)'[2],digits=3))`, such that causal judgments were higher overall for bad outcomes (*M* = `r round(d1.sumO$mean[d1.sumO$Outcome=="Bad"],digits=1)`, *SD* = `r round(d1.sumO$sd[d1.sumO$Outcome=="Bad"],digits=1)`) than for good outcomes (*M* = `r round(d1.sumO$mean[d1.sumO$Outcome=="Good"],digits=1)`, *SD* = `r round(d1.sumO$sd[d1.sumO$Outcome=="Good"],digits=1)`). More importantly, however, these main effects were qualified by an *Agent* $\times$ *Outcome* interaction, $\chi^2(2)$ = `r round(lmr1.i$Chisq[2],digits=2)`, *p* $<$ `r max(.001,round(lmr1.i$'Pr(>Chisq)'[2],digits=3))`.

```{r study1 interaction, echo=FALSE, warning=FALSE, message=FALSE}

# create averages for each partcpant for each condition
d1.sumI <- d1 %>% 
  select(Agent,Outcome,Cause,Subj) %>%
  group_by(Agent,Outcome,Subj) %>%
  summarise(CauseM = mean(Cause,na.rm=TRUE),
            CauseSD = sd(Cause, na.rm=TRUE))

#var.test(d1.sumI$CauseM[d1.sumI$Agent=="Knowledge" & d1.sumI$Outcome=="Good"],
#         d1.sumI$CauseM[d1.sumI$Agent=="Knowledge" & d1.sumI$Outcome=="Bad"])
d1.k.t <- t.test(d1.sumI$CauseM[d1.sumI$Agent=="Knowledge" & d1.sumI$Outcome=="Bad"],
         d1.sumI$CauseM[d1.sumI$Agent=="Knowledge" & d1.sumI$Outcome=="Good"])
d1.i.t <- t.test(d1.sumI$CauseM[d1.sumI$Agent=="Ignorance" & d1.sumI$Outcome=="Bad"],
         d1.sumI$CauseM[d1.sumI$Agent=="Ignorance" & d1.sumI$Outcome=="Good"])
d1.o.t <- t.test(d1.sumI$CauseM[d1.sumI$Agent=="Object" & d1.sumI$Outcome=="Bad"],
         d1.sumI$CauseM[d1.sumI$Agent=="Object" & d1.sumI$Outcome=="Good"])


```

We decomposed this interaction using planned comparisons, which revealed that when the agent knew about the outcome that his or her action would lead to, the agent was judged as much more causal of bad outcomes ($M_{cause}$ = `r round(d1.sum$mean[d1.sum$Agent=="Knowledge" & d1.sum$Outcome=="Bad"], digits=1)`, $SD_{cause}$ = `r round(d1.sum$sd[d1.sum$Agent=="Knowledge" & d1.sum$Outcome=="Bad"], digits=1)`) than good outcomes ($M_{cause}$ = `r round(d1.sum$mean[d1.sum$Agent=="Knowledge" & d1.sum$Outcome=="Good"], digits=1)`, $SD_{cause}$ = `r round (d1.sum$sd[d1.sum$Agent=="Knowledge" & d1.sum$Outcome=="Good"], digits=1)`), *t*(`r round(d1.k.t$parameter,digits=2)`) $=$ `r round(d1.k.t$statistic,digits=2)`.

In contrast, when agents did not know that his or her action would lead to the outcome, they were not judged to be any more causal of bad outcomes ($M_{cause}$ = `r round(d1.sum$mean[d1.sum$Agent=="Ignorance" & d1.sum$Outcome=="Bad"], digits=1)`, $SD_{cause}$ = `r round(d1.sum$sd[d1.sum$Agent=="Ignorance" & d1.sum$Outcome=="Bad"], digits=1)`) than good outcomes ($M_{cause}$ = `r round(d1.sum$mean[d1.sum$Agent=="Ignorance" & d1.sum$Outcome=="Good"], digits=1)`, $SD_{cause}$ = `r round(d1.sum$sd[d1.sum$Agent=="Ignorance" & d1.sum$Outcome=="Good"], digits=1)`), *t*(`r round(d1.i.t$parameter,digits=2)`) $=$ `r round(d1.i.t$statistic,digits=2)`. Similarly, non-agentic objects were not judged to be more causal of bad outcomes ($M_{cause}$ = `r round(d1.sum$mean[d1.sum$Agent=="Object" & d1.sum$Outcome=="Bad"], digits=1)`, $SD_{cause}$ = `r round(d1.sum$sd[d1.sum$Agent=="Object" & d1.sum$Outcome=="Bad"], digits=1)`) than good outcomes ($M_{cause}$ = `r round(d1.sum$mean[d1.sum$Agent=="Object" & d1.sum$Outcome=="Good"], digits=1)`, $SD_{cause}$ = `r round(d1.sum$sd[d1.sum$Agent=="Object" & d1.sum$Outcome=="Good"], digits=1)`), *t*(`r round(d1.o.t$parameter,digits=2)`) $=$ `r round(d1.o.t$statistic,digits=2)`. In short, the valence of the outcome only affected participants' causal judgments when the agent at the beginning of the causal chain *knew* about the valence of the outcome (see *Figure* 1a).

#### Counterfactual judgments

```{r study1 cf, echo=FALSE, warning=FALSE, message=FALSE}
  
d1$Counterfactual <- factor(d1$Counterfactual)

## Interaction:
#glmr1.0 <- glmer(Counterfactual ~ Agent * Outcome + (Agent*Outcome|Subj) + (1|Vignette), data=d1, family = "binomial")
#glmr1.1 <- glmer(Counterfactual ~ Agent + Outcome + (Agent*Outcome|Subj) + (1|Vignette), data=d1, family = "binomial")
#glmr1.i <- anova(glmr1.0,glmr1.1)
#saveRDS(glmr1.i,"models/glmr1i.rds")
glmr1.i <- readRDS("models/glmr1i.rds")

## main effect of agent
#glmr1.2 <- glmer(Counterfactual ~ Outcome + (Agent*Outcome|Subj) + (1|Vignette), data=d1, family = "binomial")
#glmr1.a <- anova(glmr1.1,glmr1.2)
#saveRDS(glmr1.a,"models/glmr1a.rds")
glmr1.a <- readRDS("models/glmr1a.rds")

# effect of outcome
#glmr1.3 <- glmer(Counterfactual ~ Agent + (Agent*Outcome|Subj) + (1|Vignette), data=d1, family = "binomial")
#glmr1.o <- anova(glmr1.1,glmr1.3)
#saveRDS(glmr1.o,"models/glmr1o.rds")
glmr1.o <- readRDS("models/glmr1o.rds")


d1.tabA <- data.frame(aggregate(Counterfactual ~ Agent, FUN=table,data=d1))
d1.tabO <- data.frame(aggregate(Counterfactual ~ Outcome, FUN=table,data=d1))
d1.tabI <- data.frame(aggregate(Counterfactual ~ Outcome * Agent, FUN=table,data=d1))

#, such that ignorant agents were overall less frequently selected as the more relevant focus of counterfactuals (*M* = `r round(d1.sumA_cf$mean[d1.sumA$Agent=="Ignorance"],digits=2)`, *SD* = `r round(d1.sumA$sd[d1.sumA$Agent=="Ignorance"],digits=2)`) than knowledgeable agents (*M* = `r round(d1.sumA$mean[d1.sumA$Agent=="Knowledge"],digits=2)`, *SD* = `r round(d1.sumA$sd[d1.sumA$Agent=="Knowledge"],digits=2)`), or inanimae objects (*M* = `r round(d1.sumA$mean[d1.sumA$Agent=="Object"],digits=2)`, *SD* = `r round(d1.sumA$sd[d1.sumA$Agent=="Object"],digits=2)`).
```

We next analyzed participants' counterfactul judgments using generalized linear mixed-effects models. These analyses again revealed a main effect of the kind of *Agent* the distal event involved, $\chi^2(2)$ = `r round(glmr1.a$Chisq[2],digits=2)`, *p* $<$ `r max(.001,round(glmr1.a$'Pr(>Chisq)'[2],digits=3))`, such that ignorant agents were less frequently selected as the focus of the most relevant counterfactual (`r 100*(round(d1.tabA$Counterfactual[2,1][[1]]/(d1.tabA$Counterfactual[2,2][[1]]+d1.tabA$Counterfactual[2,1][[1]]), digits=2))`%), than knowledgeable agents were (`r 100*(round(d1.tabA$Counterfactual[3,1][[1]]/(d1.tabA$Counterfactual[3,2][[1]]+d1.tabA$Counterfactual[3,1][[1]]), digits=2))`%), or objects were (`r 100*(round(d1.tabA$Counterfactual[1,1][[1]]/(d1.tabA$Counterfactual[1,2][[1]]+d1.tabA$Counterfactual[1,1][[1]]), digits=2))`%). In addition, we again observed a main effect of *Outcome valence*, $\chi^2(2)$ = `r round(glmr1.o$Chisq[2],digits=2)`, *p* = `r max(.001,round(glmr1.o$'Pr(>Chisq)'[2],digits=3))`, such that the distal agent was more selected as the focus of the most relevant counterfactual for bad outcomes (`r 100*(round(d1.tabO$Counterfactual[2,2][[1]]/(d1.tabO$Counterfactual[2,2][[1]]+d1.tabO$Counterfactual[2,1][[1]]), digits=2)`%) than for good outcomes (`r 100*(round(d1.tabO$Counterfactual[1,2][[1]]/(d1.tabO$Counterfactual[1,2][[1]]+d1.tabO$Counterfactual[1,1][[1]]), digits=2))`%). More importantly, we again observed a significant *Agent* $\times$ *Object* interaction effect, $\chi^2(2)$ = `r round(glmr1.i$Chisq[2],digits=2)`, *p* = `r max(.001,round(glmr1.i$'Pr(>Chisq)'[2],digits=3))`.

Mirroring participants' causal judgments, we found that outcome valence strongly affected participants' counterfactual judgments when the agent was knowledgeable, such that the distal agent was the focus of counterfactuals more for bad outcomes (`r 100*(round(d1.tabI$Counterfactual[6,1][[1]]/(d1.tabI$Counterfactual[6,2][[1]]+d1.tabI$Counterfactual[6,1][[1]]), digits=2))`%), than for good outcomes (`r 100*(round(d1.tabI$Counterfactual[5,1][[1]]/(d1.tabI$Counterfactual[5,2][[1]]+d1.tabI$Counterfactual[5,1][[1]]), digits=2))`%). In contrast, when the agent was ignorant of the outcome, or was a non-agentic object, there was little difference in their tendency to focous on the distal agent in their counterfactual judgments in cases with bad (Ignorant agent: `r 100*(round(d1.tabI$Counterfactual[4,1][[1]]/(d1.tabI$Counterfactual[4,2][[1]]+d1.tabI$Counterfactual[4,1][[1]]), digits=2))`%; Object: `r 100*(round(d1.tabI$Counterfactual[2,1][[1]]/(d1.tabI$Counterfactual[2,2][[1]]+d1.tabI$Counterfactual[2,1][[1]]), digits=2))`%) or good outcomes (Ignorant agent: `r 100*(round(d1.tabI$Counterfactual[3,1][[1]]/(d1.tabI$Counterfactual[3,2][[1]]+d1.tabI$Counterfactual[3,1][[1]]), digits=2))`%; Object: `r 100*(round(d1.tabI$Counterfactual[1,1][[1]]/(d1.tabI$Counterfactual[1,2][[1]]+d1.tabI$Counterfactual[1,1][[1]]), digits=2))`%). In short, participants' counterfactual judgments were only affected by the valence of the outcome when the agent acted with knowledge of the valence (see *Figure* 1b).

```{r, d1Fig, fig.width=8.5, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Participants' causal and counterfactual judgments as a function of both the kind of agent who initiated the causal chain and the valence of the outcome that eventuated. Error bars indicate +/- 1 *SEM*."}

d1.plot1 <- ggplot(d1.sum, aes(x=Agent, y=mean, fill=Outcome)) +
  geom_bar(stat="identity", position="dodge") + 
  ylab("Didn't Cause (1) ~ Caused (7)") +
  xlab("") +
  scale_fill_manual("Outcome:", values=wes_palette("Royal1",2)) + 
  coord_cartesian(ylim=c(1,7)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1, position=position_dodge(.9)) +
  theme_bw() +
  theme(
    plot.background = element_blank()
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    #,legend.position = c(.1,.9)
    ,legend.title=element_text(size=rel(1))
    ,legend.text=element_text(size=rel(1))
    ,axis.text.y=element_text(size=rel(1))
    ,axis.text.x=element_text(size=rel(1))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1))
  )


d1$Counterfactual <- factor(c("Distal","Proximal")[d1$Counterfactual])
d1$Counterfactual <- factor(d1$Counterfactual, levels=c("Proximal","Distal"))

d1.plot2 <- ggplot(d1,aes(x=Outcome, fill=Counterfactual)) +
  geom_bar(position="stack") +
  ylab("Number of times selected as focus of counterfactual") +
  xlab("") +
  scale_fill_manual("Event:",values=wes_palette("Chevalier1",2)) + 
  facet_grid( ~ Agent) +
  theme_bw() +
  theme(
    plot.background = element_blank()
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    ,legend.text=element_text(size=rel(1))
    ,axis.text.y=element_text(size=rel(1))
    ,axis.text.x=element_text(size=rel(1))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1))
    ,strip.text=element_text(size=rel(.9))
  )

grid.arrange(d1.plot1, d1.plot2, ncol=2)

```

## Relationship between causal and counterfactual judgments

```{r study1 correlation and mediation, echo=FALSE, message=FALSE}

## correlation at the level of participants
d1.sumCorSub <- d1 %>% 
  select(Agent,Outcome,Cause,Counterfactual,Subj,Vignette) %>%
  group_by(Agent,Outcome,Subj,Vignette) %>%
  summarise(CauseM = mean(Cause,na.rm=TRUE),
            CntrfM = mean(as.numeric(Counterfactual)))

d1.corSub <- cor.test(d1.sumCorSub$CauseM,d1.sumCorSub$CntrfM)

## correlation at the level of scenario
d1.sumCorVign <- d1 %>% 
  select(Agent,Outcome,Cause,Counterfactual,Vignette) %>%
  group_by(Agent,Outcome,Vignette) %>%
  summarise(CauseM = mean(Cause,na.rm=TRUE),
            CntrfM = mean(as.numeric(Counterfactual)))

d1.corVign <- cor.test(d1.sumCorVign$CauseM,d1.sumCorVign$CntrfM)

# SO FAR THIS IS STILL NOT WORKING
# d1.m <- d1[d1$Agent!="Object",]
# 
# #lm1.m1 <- lmer(causeS ~ Counterfactual + Agent*Outcome + (Agent*Outcome|Subj) + (1|Vignette), data=d1.m)
# #lm1.m2 <- lmer(causeS ~ Counterfactual + Agent + Outcome + (Agent*Outcome|Subj) + (1|Vignette), data=d1.m)
# #anova(lm1.m1,lm1.m2)
#   
# d1.m$Interaction[d1.m$Agent=="Knowledge" & d1.m$Outcome=="Bad"] <- -1
# d1.m$Interaction[d1.m$Agent=="Knowledge" & d1.m$Outcome=="Good"] <- 1
# d1.m$Interaction[d1.m$Agent=="Ignorance" & d1.m$Outcome=="Bad"] <- 1
# d1.m$Interaction[d1.m$Agent=="Ignorance" & d1.m$Outcome=="Good"] <- -1
# 
# #d1$Interaction <- factor(d1$Interaction)
# d1.m$Counterfactual <- as.numeric(as.character(d1.m$Counterfactual))
# d1.m$Agent <- as.numeric(as.character(d1.m$Agent))
# 
# med.fit <- glm(Counterfactual ~ Agent, data=d1.m, family="binomial")
# out.fit <- lm(Cause ~ Counterfactual + Agent, data=d1.m)
# 
# med.out <- mediate.sed("causeS", "Counterfactual", boot=TRUE, treat="Agent", SI=TRUE,data=d1.m)
# 

# library(arm)
# d1.m$Subj <- factor(d1.m$Subj)
# med.fit <- glmer(Counterfactual ~ Interaction + Agent + Outcome + (1|Subj), family=binomial(link="logit"), data=d1.m)
# out.fit <- lmer(causeS ~ Interaction + Counterfactual + Agent + Outcome + (Agent*Outcome|Subj), data=d1.m)
# med.out <- mediate(med.fit, out.fit, sims=1000, treat="Interaction", mediator="Counterfactual")

```

Finally, we considered the relationship between participants' causal and counterfactual judgments, and found that they were highly correlated both when considered at the level of each participants' judgments ($r =$ `r d1.corSub$estimate[[1]]`, $p$ = `r format.pval(d1.corSub$p.value, digits = 2)`, and at the level of each the different scenarios ($r =$ `r d1.corVign$estimate[[1]]`, $p$ = `r format.pval(d1.corVign$p.value, digits = 2)`) (see *Figure* 2). Finally, we also asked whether the counterfactual judgments mediated the observed Knowledge $\times$ Outcome interaction effect observed for agents, and found that they did [to be reported].

```{r fig.width=8.5, echo=FALSE, message=FALSE, fig.cap="Depiction of the relationship between participants' causal and counterfactual judgments for each of the scenaros. Shape depicts the valence of the outcome; color indicates the kind of agent involved in the distal event; and the number indicates the which of the 24 vignettes the judgments were about."}

d1.sumCorGraph <- d1 %>% 
  select(Agent,Outcome,Cause,Counterfactual,Vignette) %>%
  group_by(Agent,Outcome,Vignette) %>%
  summarise(CauseM = mean(Cause,na.rm=TRUE),
            CauseN = length(Cause),
            CauseSD = sd(Cause,na.rm=TRUE),
            CauseSE =  CauseSD / sqrt(CauseN),
            CntrfM = mean(as.numeric(Counterfactual)),
            CntrfN = length(Counterfactual),
            CntrfSD = sd(as.numeric(Counterfactual),na.rm=TRUE),
            CntrfSE =  CntrfSD / sqrt(CntrfN)) %>%
  select(Agent,Outcome,Vignette,CauseM,CauseSE,CntrfM,CntrfSE) %>%
  gather("JudgmentSE","SE",c("CauseSE","CntrfSE")) %>%
  mutate(CntrfMr = (CntrfM-1))


d1.plot3 <- ggplot(d1.sumCorGraph, aes(y=CauseM, x=CntrfMr,color=Outcome))+
                  geom_smooth(method=lm, formula = y ~ x) +
                  geom_point(aes(color=Outcome, shape=Outcome),size=3) +
                  geom_text(aes(label=Vignette),size=1.5,color="black") +
                  facet_grid(~Agent) + 
                  #geom_errorbar(aes(ymax=CauseM - SE, ymin=CauseM-SE)) +
                  #geom_errorbarh(aes(xmax=CntrfMr - SE, xmin=CntrfMr-SE)) +
                  xlab("Average Counterfactual Prefence for the distal agent per Scenario") +
                  ylab("Average Causal Judgment per Scenario") +
                  scale_color_manual("Outcome", values=wes_palette("Royal1",2)) + 
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    ,legend.text=element_text(size=rel(1))
                    #,legend.position=c(.9,.25)
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                    ,strip.text=element_text(size=rel(.9))
                  )

plot(d1.plot3)
```

## Discussion

This study investigated participants' causal and counterfactual judgments in simple causal chains which eventuate in either good or bad outcomes. We found that agents who started this causal chain with knowledge of the outcome that their action would lead to were judged to be more causal of bad than good outcomes. By comparison, agents who were ignorant about the outcome that would eventually occur were not judged to be more causal of bad (vs good) outcomes. A similar pattern was also observed for inanimate objects which inititated the causal chain.

The interaction effect observed in participants' causal judgments was mirrored by a similar pattern in their counterfactual judgments: in cases where the agent *knew* about the outcome, participants were inclined to judge that the bad (vs. good) outcome would not have occurred if the agent had acted differently. This effect was again not observed for agents who acted in ignorance of the outcome, or for inanimate objects. More generally, we also found that participants' causal and counterfactual judgments were tightly correlated in each of these conditions.

This experiment helps to establish the effect of norm violations in causal chains across many scenarios and importantly carefully manipulates the agent's culpability only by changing which information the agent had acess to. At the same time, the experiment suffers from a confound that persists throughout the empirical work on this topic: the morality of the agent's action is always confounded with the goodness or badness of the outcome (see @hitchcock2009cause and @kominsky2015superseding for two exceptions). In the next series of studies, we systematically and independently vary both the valence of the outcome and the morality of the agents' actions and ask how both contribute to participants' causal judgments.

### Previous outline:

-   Agents who acted with the knowledge of the outcome that would result from their action were judged to be more causal of bad (vs. good) outcomes.

-   Objects and ignorant agents were not affected by the valence of the outcome, and were generally treated similarly.

-   This interaction effect in participants' causal judgments was mirrored by a similar parttern in their counterfactual judgments

-   The counterfacutal judgments also mediated the interaction effect.

-   This experiment confounds the normality of the action (whether or not it is a norm violation) and the normality of the outcome (whether the outcome is positive or negative). In the following studies we next seek to ask about the independent contribution of these.

-   Experiment 2a: Normality of actions independent of the outcome: Rational and moral norm violations

    -   Intro
        -   A number of theories make predictions that the effect of observed in Experiment 1 is specific to morality in some way or another (Alicke; Samland & Waldmann; Danks, Rose & Machery; Alicke, Bloom & Rose)
        -   To ensure that we are generalizing beyond any effect that is specific to morality, we also ask investigate cases in which the agent either knowingly or unknowingly violates a rational norm.
        -   We also dissociated the normality of the outcome from the normality of the action by holding fixed the outcome as bad and always having the agent be ignorant of the fact that this outcome would occur when acting.
    -   Methods
    -   Results
    -   Discussion
        -   Agents who knowingly preformed immoral or irrational actions were judged as more causal of the subsequent outcomes, even when the immorality/irrationality of the action was completely independent of the outcomes.
        -   Causal judgments of agents who were ignorant that their action was a norm violation did not show a similar effect.

# Experiment 2a: Norm violations in cases of bad outcomes

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

```{r study2a participants, echo=FALSE}
d2ademo <- read.csv("../data/d4demo.csv") # remember that we aren't including the first study with only 3 vignettes
#d2demo$age[d1demo$age==1993] <- NA ## one person entered their age as 1993 (presumably the year that they were born) 
d2ademo$gender <- factor(c("Male","Female")[d2ademo$gender])
d2ademo$edu <- factor(c("Grammar School","Highschool or Equivalent","Vocational/Technical School",
                                 "Some College","College Graduate (4 years)","Master's Degree",
                                 "Doctoral Degree (PhD)","Professional Degree (JD,MD,etc.)","Other")[d2ademo$edu])
##Age and Gender
d2a.age <- matrix(c("mean",mean(d2ademo$age,na.rm=T),"sd",sd(d2ademo$age,na.rm=T),"n",length(d2ademo$age)),ncol = 3)
d2a.gender <- table(d2ademo$gender, exclude=NULL)

###Education
d2.education <- table(d2ademo$edu)

```

In Experiment 2a, `r d2a.age[2,3]` participants (*M*~age~=`r round(mean(d2ademo$age, na.rm=T),digits=2)`, *SD*~age~=`r round(sd(d2ademo$age, na.rm=T),digits=2)`; `r d2a.gender[[1]]` females) were recruited through Amazon Mechanical Turk (<http://www.mturk.com>).

### Materials

Participants completed 16 trials which each involved reading a brief vignette about a causal chain. As in the previous study, the causal chain was initiated by a distal event, which led to some immediate outcome. This intermediate event then led to a second, final outcome. However, in this study, the distal event always involved agents who were completely ignorant of the fact that their actions may lead to some final negative outcome. Instead, we simply manipulated whether the agent had knowledge that their action would violate a separate moral norm. Consider the following example from one of the scenarios we used:

> **Moral Norm / Ignorant Agent**: Harry was a fisherman applying for a license to fish in a certain coastal area. The government said that Harry could have a license to fish in this area or in a second area. They failed to tell him that choosing to fish in the first area would cause him to put a single working mother out of business. Without this information, Harry chose the license to fish in the area he initially wanted. He fished in this area every day, significantly reducing the local fish population. As a result of the lower fish population, the coral reef along the coast shrunk by several meters in every direction.

In this version, the agent did not know that his action (fishing in the first location) would directly lead to negative consequences to another person (putting a single mother out of work). Not knowing this, the agent fished in that location, which resulted in the intermediate event occurring (the reducton of the fish population). This event led to the occurence of a final negative outcome (the coral reef shrinking). In other cases, the agent was actually told that fishing in that area would put a single mother out of business but decided to do so anyway, making his action immoral.

Finally, in addition to having the agent violate moral norms, we also included cases where the agent instead violated rational norms. Consider the following example from the same scenario:

> **Rational Norm / Knowledgeable Agent** Harry was a fisherman applying for a license to fish in a certain coastal area. The government said that Harry could have a license to fish in this area, but that fishing there would be very difficult due to dangerous conditions. They recommended that he accept a license to fish in a second area that was much safer. Harry chose the license to fish in the area he initially wanted. He fished in this area every day, until a large wave knocked him into the rocks and he injured his leg. As a result of the lower fish population, the coral reef along the coast shrunk by several meters in every direction.

Systemactically manipulating these factors resulted in an overall 2 (Norm Type) $\times$ 2 (Agent Knowledge) $\times$ 16 (Scenario) design, that was administered in a mixed within- and between-subjects fashion, such that participants saw all 16 scenarios, and on each trial were randomly assigned to read one of the 4 different versions of that scenario.

### Procedure

After reading each vignette, participants rated their agreement with a statement about the distal agent causing the outcome, as in the following example:

> *Causal question*: Herny cause the coral reef to shrink by several meters in every direction.

\noindent Participants responded to each of these questions on a scale from 1 ("Completely disagree") to 7 ("Completely agree"). After completing all 16 trials, participants were asked to complete some optional demographic questions.

### Data analysis

No participants were excluded from the analyses as long as they completed the entire study. The primary analyses were conducted with linear mixed-effects models and included random effects for both participants and scenarios.

## Results

```{r study2a causeAnalyses, echo=FALSE, warning=FALSE, message=FALSE}

d2a <- read.csv("../data/irrationalityBadLong.csv")

d2a$knowledge <- factor(d2a$knowledge, levels=c("Ignorance","Knowledge"))
d2a$norm <- factor(d2a$norm)
d2a <- d2a %>%
  mutate(norm = case_when(norm =="Rationality" ~ "Rational Norm",
            norm == "Morality" ~ "Moral Norm"))
d2a$causeS <- scale(d2a$cause)
  
## I need to go back through this and switch everything from d2 to d2a (including updating the models...)
## ESW: who needs? still need?

## Interaction:
# lmr2a.0 <- lmer(causeS ~ knowledge * norm + (knowledge*norm|subj) + (1|vign), data=d2a)
# lmr2a.1 <- lmer(causeS ~ knowledge + norm + (knowledge*norm|subj) + (1|vign), data=d2a)
# lmr2a.i <- anova(lmr2a.0,lmr2a.1)
# saveRDS(lmr2a.i,"models/lmr2ai.rds")
lmr2a.i <- readRDS("models/lmr2ai.rds")

# main effect of knowledge
# lmr2a.2 <- lmer(causeS ~ norm + (knowledge*norm|subj) + (1|vign), data=d2a)
# lmr2a.k <- anova(lmr2a.1,lmr2a.2)
# saveRDS(lmr2a.k,"models/lmr2ak.rds")
lmr2a.k <- readRDS("models/lmr2ak.rds")

# effect of norm
# lmr2a.3 <- lmer(causeS ~ knowledge + (knowledge*norm|subj) + (1|vign), data=d2a)
# lmr2a.n <- anova(lmr2a.1,lmr2a.3)
# saveRDS(lmr2a.n,"models/lmr2an.rds")
lmr2a.n <- readRDS("models/lmr2an.rds")

d2a.sumK <- d2a %>% 
  select(knowledge,cause,subj) %>%
  group_by(knowledge,subj) %>%
  summarise(CauseM = mean(cause),na.rm=TRUE) %>%
  group_by(knowledge) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))

d2a.sumN <- d2a %>% 
  select(norm,cause,subj) %>%
  group_by(norm,subj) %>%
  summarise(CauseM = mean(cause),na.rm=TRUE) %>%
  group_by(norm) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))

d2a.sum <- d2a %>% 
  select(knowledge,norm,cause,subj) %>%
  group_by(knowledge,norm,subj) %>%
  summarise(CauseM = mean(cause),na.rm=TRUE) %>%
  group_by(knowledge,norm) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))
```

We analyzed participants' causal judgments, which revealed a main effect of whether the distal event agent knew that the action violated a moral norm, $\chi^2(2)$ = `r round(lmr2a.k$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2a.k$'Pr(>Chisq)'[2],digits=3))`, such that ignorant agents were overall seen as less causal (*M* = `r round(d2a.sumK$mean[d2a.sumK$knowledge=="Ignorance"],digits=2)`, *SD* = `r round(d2a.sumK$sd[d2a.sumK$knowledge=="Ignorance"],digits=2)`) than knowledgeable agents (*M* = `r round(d2a.sumK$mean[d2a.sumK$knowledge=="Knowledge"],digits=2)`, *SD* = `r round(d2a.sumK$sd[d2a.sumK$knowledge=="Knowledge"],digits=2)`). Importantly, we did not observe either a main effect of the kind of *Norm* that was relevant for the agent's action, $\chi^2(2)$ = `r round(lmr2a.n$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2a.n$'Pr(>Chisq)'[2]),digits=3)`, or a *Knowledge* $\times$ *Norm* interaction effect, $\chi^2(2)$ = `r round(lmr2a.i$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2a.i$'Pr(>Chisq)'[2],digits=3))`, suggesting that moral and rational norm violations had much the same impact on causal judgments (*Fig*. 3a).

```{r 2aFig, fig.width=8.5, echo=FALSE, fig.cap="Participants' causal judgments as a function of both the knowledge of the agent who initiated the causal chain and the kind of norm that governed the agent's action, for both bad outcomes. Error bars indicate +/- 1 *SEM*."}
d2a.plot <- ggplot(d2a.sum, aes(x=norm, y=mean, fill=knowledge)) +
  geom_bar(stat="identity", position="dodge") + 
  ylab("Didn't Cause (1) ~ Caused (7)") +
  xlab("") +
  scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
  coord_cartesian(ylim=c(1,7)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1, position=position_dodge(.9)) +
  ggtitle("Bad Outcomes") +
  theme_bw() +
  theme(
    plot.background = element_blank()
    ,plot.title=element_text(hjust=.5)
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    ,legend.position = c(.175,.85)
    #,legend.position = "null"
    ,legend.title=element_text(size=rel(1))
    ,legend.text=element_text(size=rel(1))
    ,axis.text.y=element_text(size=rel(1))
    ,axis.text.x=element_text(size=rel(1))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1))
  )

d2a.plot


```

## Discussion

fill in here!

### from outline:

-   Agents who knowingly preformed immoral or irrational actions were judged as more causal of the subsequent outcomes, even when the immorality/irrationality of the action was completely independent of the outcomes.
-   Causal judgments of agents who were ignorant that their action was a norm violation did not show a similar effect.
-   Overall this looks good The two things it gives us above and beyond what we had before are that we've now shown that what is important is the knowledge of the norm violation, not the knowledge of the outcome the agent brings about (as in earlier studies). This is pretty good evidence for cf accessibility driving these effects. Additionally, the obvious cool other thing it gives us is that we get an effect of rationality that looks exactly like the effect of morality, which is clearly not predicted on the sort of account that says these effects are motivated.

# Experiment 2b: Norm violations in cases of good outcomes

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

```{r study2b participants, echo=FALSE}
d2bdemo <- read.csv("../data/d5demo.csv") # remember that we aren't including the first study with only 3 vignettes
#d2demo$age[d1demo$age==1993] <- NA ## one person entered their age as 1993 (presumably the year that they were born) 
d2bdemo$gender <- factor(c("Male","Female")[d2bdemo$gender])
d2bdemo$edu <- factor(c("Grammar School","Highschool or Equivalent","Vocational/Technical School",
                                 "Some College","College Graduate (4 years)","Master's Degree",
                                 "Doctoral Degree (PhD)","Professional Degree (JD,MD,etc.)","Other")[d2bdemo$edu])
##Age and Gender
d2b.age <- matrix(c("mean",mean(d2bdemo$age,na.rm=T),"sd",sd(d2bdemo$age,na.rm=T),"n",length(d2bdemo$age)),ncol = 3)
d2b.gender <- table(d2bdemo$gender, exclude=NULL)

###Education
d2b.education <- table(d2bdemo$edu)

```

In Experiment 2b, `r d2b.age[2,3]` participants (*M*~age~=`r round(mean(d2bdemo$age, na.rm=T),digits=2)`, *SD*~age~=`r round(sd(d2bdemo$age, na.rm=T),digits=2)`; `r d2b.gender[[1]]` females) were recruited through Amazon Mechanical Turk (<http://www.mturk.com>).

### Materials

Participants completed 16 trials which each involved reading a brief vignette about a causal chain. As in the previous studies, the causal chain was initiated by a distal event, which led to some immediate outcome. This intermediate event then led to a second, final outcome. As in Study 2a, the distal event always involved agents who were completely ignorant of the fact that their actions may lead to some final outcome, however, in this study the outcomes that occurred were always positive rather than negative. Once again, however, we manipulated whether the agent had knowledge that their action would violate a separate moral or rational norm. Consider the following variation from the scenario described above used:

> **Good Outcome / Rational Norm / Knowledgeable Agent** Harry was a fisherman applying for a license to fish in a certain coastal area. The government said that Harry could have a license to fish in this area, but that fishing there would be very difficult due to dangerous conditions. They recommended that he accept a license to fish in a second area that was much safer. Harry chose the license to fish in the area he initially wanted. He fished in this area every day, until a large wave knocked him into the rocks and he injured his leg. As a result of the lower fish population, the coral reef along the coast grew by several meters in every direction.

This design again resulted in an overall 2 (Norm Type) $\times$ 2 (Agent Knowledge) $\times$ 16 (Scenario) design, that was administered in a mixed within- and between-subjects fashion, such that participants saw all 16 scenarios, and on each trial were randomly assigned to read one of the 4 different versions of that scenario.

### Procedure

After reading each vignette, participants rated their agreement with a statement about the distal agent causing the outcome, as in the following example:

> *Causal question*: Herny cause the coral reef to grow by several meters in every direction.

\noindent Participants responded to each of these questions on a scale from 1 ("Completely disagree") to 7 ("Completely agree"). After completing all 16 trials, participants were asked to complete some optional demographic questions.

### Data analysis

No participants were excluded from the analyses as long as they completed the entire study. The primary analyses were conducted with linear mixed-effects models and included random effects for both participnts and scenarios.

## Results

```{r study2b causeAnalyses, echo=FALSE, warning=FALSE, message=FALSE}

d2b <- read.csv("../data/irrationalityGoodLong.csv")


d2b$knowledge <- factor(d2b$knowledge)
d2b$knowledge <- factor(d2b$knowledge, levels=c("Ignorance","Knowledge"))
d2b$norm <- factor(d2b$norm)
d2b <- d2b %>%
  mutate(norm = case_when(norm =="Rationality" ~ "Rational Norm",
            norm == "Morality" ~ "Moral Norm"))
d2b$causeS <- scale(d2b$cause)
  
## Interaction:
# lmr2b.0 <- lmer(causeS ~ knowledge * norm + (knowledge*norm|subj) + (1|vign), data=d2b)
# lmr2b.1 <- lmer(causeS ~ knowledge + norm + (knowledge*norm|subj) + (1|vign), data=d2b)
# lmr2b.i <- anova(lmr2b.0,lmr2b.1)
# saveRDS(lmr2b.i,"models/lmr2bi.rds")
lmr2b.i <- readRDS("models/lmr2bi.rds")

# main effect of knowledge
# lmr2b.2 <- lmer(causeS ~ norm + (knowledge*norm|subj) + (1|vign), data=d2b)
# lmr2b.k <- anova(lmr2b.1,lmr2b.2)
# saveRDS(lmr2b.k,"models/lmr2bk.rds")
lmr2b.k <- readRDS("models/lmr2bk.rds")

# effect of norm
# lmr2b.3 <- lmer(causeS ~ knowledge + (knowledge*norm|subj) + (1|vign), data=d2b)
# lmr2b.n <- anova(lmr2b.1,lmr2b.3)
# saveRDS(lmr2b.n,"models/lmr2bn.rds")
lmr2b.n <- readRDS("models/lmr2bn.rds")

d2b.sumK <- d2b %>% select(knowledge,cause,subj) %>%
  group_by(knowledge,subj) %>%
  summarise(CauseM = mean(cause),na.rm=TRUE) %>%
  group_by(knowledge) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))

d2b.sumN <- d2b %>% 
  select(norm,cause,subj) %>%
  group_by(norm,subj) %>%
  summarise(CauseM = mean(cause),na.rm=TRUE) %>%
  group_by(norm) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))

d2b.sum <- d2b %>% 
  select(knowledge,norm,cause,subj) %>%
  group_by(knowledge,norm,subj) %>%
  summarise(CauseM = mean(cause),na.rm=TRUE) %>%
  group_by(knowledge,norm) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))

```

We analyzed participants' causal judgments, which did not revea main effect of whether the distal event agent knew that the action violated a moral norm, $\chi^2(2)$ = `r round(lmr2b.k$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2b.k$'Pr(>Chisq)'[2],digits=3))`, such that *ignorant* agents were not significantly seen as less causal (*M* = `r round(d2b.sumK$mean[d2b.sumK$knowledge=="Ignorance"],digits=2)`, *SD* = `r round(d2b.sumK$sd[d2b.sumK$knowledge=="Ignorance"],digits=2)`) than *knowledgeable* agents (*M* = `r round(d2b.sumK$mean[d2b.sumK$knowledge=="Knowledge"],digits=2)`, *SD* = `r round(d2b.sumK$sd[d2b.sumK$knowledge=="Knowledge"],digits=2)`). We again did not observe either a main effect of the kind of *Norm* that was relevant for the agent's action, $\chi^2(2)$ = `r round(lmr2b.n$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2b.n$'Pr(>Chisq)'[2],digits=3))`, or a *Knowledge* $\times$ *Norm* interaction effect, $\chi^2(2)$ = `r round(lmr2b.i$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2b.i$'Pr(>Chisq)'[2],digits=3))` (*Fig*. 3b).

```{r 2abFig, fig.width=8.5, echo=FALSE, fig.cap="Participants' causal judgments as a function of both the knowledge of the agent who initiated the causal chain and the kind of norm that governed the agent's action, for good outcomes. Error bars indicate +/- 1 *SEM*."}



d2b.plot <- ggplot(d2b.sum, aes(x=norm, y=mean, fill=knowledge)) +
  geom_bar(stat="identity", position="dodge") + 
  ylab("Didn't Cause (1) ~ Caused (7)") +
  xlab("") +
  scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
  coord_cartesian(ylim=c(1,7)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1, position=position_dodge(.9)) +
  ggtitle("Good Outcomes") +
  theme_bw() +
  theme(
    plot.background = element_blank()
    ,plot.title=element_text(hjust=.5)
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    ,legend.position = c(.175,.85)
    ,legend.title=element_text(size=rel(1))
    ,legend.text=element_text(size=rel(1))
    ,axis.text.y=element_text(size=rel(1))
    ,axis.text.x=element_text(size=rel(1))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1))
  )

d2b.plot

#grid.arrange(d2a.plot, d2b.plot, ncol=2) --> ESW: moved d2a.plot up with d2a study, changed the titles of d2a.plot and d2b.plot as well.


```

## Discussion

fill in here!

### from outline:

-   When the outcome was good, we no longer found a significant effect of whether the agents knowingly preformed immoral or irrational actions on judgments of whether the agent caused the eventual outcome.

# Experiment 2c: Manipulating valence outcome and norm violations

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

```{r study2c participants, echo=FALSE, message=FALSE, warning=FALSE}
d2cdemo <- read.csv("../data/d6demo.csv") # remember that we aren't including the first study with only 3 vignettes
d2cdemo$gender <- factor(c("Male","Female")[d2cdemo$gender])
d2cdemo$edu <- factor(c("Grammar School","Highschool or Equivalent","Vocational/Technical School",
                                 "Some College","College Graduate (4 years)","Master's Degree",
                                 "Doctoral Degree (PhD)","Professional Degree (JD,MD,etc.)","Other")[d2cdemo$edu])
##Age and Gender
d2c.age <- matrix(c("mean",mean(d2cdemo$age,na.rm=T),"sd",sd(d2cdemo$age,na.rm=T),"n",length(d2cdemo$age)),ncol = 3)
d2c.gender <- table(d2cdemo$gender, exclude=NULL)

###Education
d2c.education <- table(d2cdemo$edu)

```

In Experiment 2c, `r d2c.age[2,3]` participants (*M*~age~=`r round(mean(d2cdemo$age, na.rm=T),digits=2)`, *SD*~age~=`r round(sd(d2cdemo$age, na.rm=T),digits=2)`; `r d2c.gender[[1]]` females) were recruited through Amazon Mechanical Turk (<http://www.mturk.com>).

### Materials

Once agian, participants completed 16 trials which each involved reading a brief vignette about a causal chain. As in the previous studies, the causal chain was initiated by a distal event, which led to some immediate outcome. This intermediate event then led to a second, final outcome, which either had a positive or a negative valence. The distal event always involved agents who were completely ignorant of the fact that their actions may lead to some final outcome. In addition, we again manipulated whether the agent had knowledge that their action would violate a separate moral or rational norm.

This design resulted in an overall 2 (Norm Type) $\times$ 2 (Agent Knowledge) $\times$ 2 (Outcome Valence) $\times$ 16 (Scenario) design, that was administered in a mixed within- and between-subjects fashion, such that participants saw all 16 scenarios, and on each trial were randomly assigned to read one of the 8 different versions of that scenario.

### Procedure

After reading each vignette, participants rated their agreement with a statement about the distal agent causing the final, as in the previous studies. Participants again responded to each of these questions on a scale from 1 ("Completely disagree") to 7 ("Completely agree"), and were asked to complete some optional demographic questions after rating all 16 scenarios..

### Data analysis

No participants were excluded from the analyses as long as they completed the entire study. The primary analyses were conducted with linear mixed-effects models and included random effects for both participnts and scenarios.

## Results

```{r study2c causeAnalyses, echo=FALSE, message=FALSE, warning=FALSE}

d2c <- read.csv("../data/irrationalityWithin-subjsLong.csv")

d2c$knowledge <- factor(d2c$knowledge, levels=c("Ignorance","Knowledge"))
d2c$norm <- factor(d2c$norm)
d2c <- d2c %>%
  mutate(norm = case_when(norm =="Rationality" ~ "Rational Norm",
            norm == "Morality" ~ "Moral Norm"))
d2c$outcome <- factor(d2c$outcome)
d2c$causeS <- scale(d2c$cause)

## three-way interaction
# lmr2c.0 <- lmer(causeS ~ knowledge * norm * outcome + (knowledge*norm*outcome|subj) + (1|vign), data=d2c)
# lmr2c.1 <- lmer(causeS ~ (knowledge * norm) + (outcome * knowledge) + (outcome * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2c)
# lmr2c.i3x <- anova(lmr2c.0,lmr2c.1)
# saveRDS(lmr2c.i3x,"models/lmr2ci3x.rds")
lmr2c.i3x <- readRDS("models/lmr2ci3x.rds")

## Norm x Knowledge interaction
# lmr2c.1 <- lmer(causeS ~ (knowledge * outcome) + (outcome * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2c)
# lmr2c.NxK <- anova(lmr2c.0,lmr2c.1)
# saveRDS(lmr2c.NxK,"models/lmr2cNxK.rds")
lmr2c.NxK <- readRDS("models/lmr2cNxK.rds")

## Norm x Outcome interaction
# lmr2c.1 <- lmer(causeS ~ (knowledge * outcome) + (knowledge * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2c)
# lmr2c.NxO <- anova(lmr2c.0,lmr2c.1)
# saveRDS(lmr2c.NxO,"models/lmr2cNxO.rds")
lmr2c.NxO <- readRDS("models/lmr2cNxO.rds")

## Outcome Valence x Knowledge interaction
# lmr2c.1 <- lmer(causeS ~ (knowledge * norm) + (outcome * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2c)
# lmr2c.OxK <- anova(lmr2c.0,lmr2c.1)
# saveRDS(lmr2c.OxK,"models/lmr2cOxK.rds")
lmr2c.OxK <- readRDS("models/lmr2cOxK.rds")

## decomposing the interaction effect, by asking about the effect of knowledge for both bad and good outcomes:

### Bad outcomes
# lmr2c.4b1 <- lmer(causeS ~ knowledge + norm + (knowledge*norm|subj) + (1|vign), data=d2c[d2c$outcome=="Bad Outcome",])
# lmr2c.4b2 <- lmer(causeS ~ norm + (knowledge*norm|subj) + (1|vign), data=d2c[d2c$outcome=="Bad Outcome",])
# lmr2c.K_B <- anova(lmr2c.4b1,lmr2c.4b2)
# saveRDS(lmr2c.K_B,"models/lmr2cK_B.rds")
lmr2c.K_B <- readRDS("models/lmr2cK_B.rds")

### Good outcomes
# lmr2c.4g1 <- lmer(causeS ~ knowledge + norm + (knowledge*norm|subj) + (1|vign), data=d2c[d2c$outcome=="Good Outcome",])
# lmr2c.4g2 <- lmer(causeS ~ norm + (knowledge*norm|subj) + (1|vign), data=d2c[d2c$outcome=="Good Outcome",])
# lmr2c.K_G <- anova(lmr2c.4g1,lmr2c.4g2)
# saveRDS(lmr2c.K_G,"models/lmr2cK_G.rds")
lmr2c.K_G <- readRDS("models/lmr2cK_G.rds")

d2c.sumOK <- d2c %>% select(knowledge,outcome,cause,subj) %>%
  group_by(knowledge,outcome,subj) %>%
  summarise(CauseM = mean(cause),na.rm=TRUE) %>%
  group_by(knowledge,outcome) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))

d2c.sum <- d2c %>% 
  select(knowledge,norm,outcome,cause,subj) %>%
  group_by(knowledge,norm,outcome,subj) %>%
  summarise(CauseM = mean(cause),na.rm=TRUE) %>%
  group_by(knowledge,norm,outcome) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))

```

We analyzed participants' causal judgments to investigate whether we replicated the effect of the agents' knowledge of violating a norm and the interaction of this factor with the valence of the outcome. We first asked whether there was a significant *Knowledge* $\times$ *Norm* $\times$ *Outcome* interaction effect, but did not find one, $\chi^2(2)$ = `r round(lmr2c.i3x$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2c.i3x$'Pr(>Chisq)'[2],digits=3))`. Accordingly, we next investigated three possible 2-way interactions. These analyses revealed no *Norm* $\times$ *Outcome* interaction, $\chi^2(2)$ = `r round(lmr2c.NxO$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2c.NxO$'Pr(>Chisq)'[2],digits=3))`, and also no *Norm* $\times$ *Knowledge* interaction, $\chi^2(2)$ = `r round(lmr2c.NxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2c.NxK$'Pr(>Chisq)'[2],digits=3))`. There was, however, a significant *Knowledge* $\times$ *Outcome* interaction effect, mirroring the results of Study 2a and 2b, $\chi^2(2)$ = `r round(lmr2c.OxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2c.OxK$'Pr(>Chisq)'[2],digits=3))`.

To decompose this interaction, we next asked whether there was an effect of knowledge for the bad and good outcomes separately. For the bad outcomes, we found a highly significant effect of whether the agent knew that the action violated a norm, $\chi^2(2)$ = `r round(lmr2c.K_B$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2c.K_B$'Pr(>Chisq)'[2],digits=3))`, such that *ignorant* agents were seen as less causal (*M* = `r round(d2c.sumOK$mean[d2c.sumOK$knowledge=="Ignorance" & d2c.sumOK$outcome=="Bad Outcome"],digits=2)`, *SD* = `r round(d2c.sumOK$sd[d2c.sumOK$knowledge=="Ignorance" & d2c.sumOK$outcome=="Bad Outcome"],digits=2)`) than *knowledgeable* agents (*M* = `r round(d2c.sumOK$mean[d2c.sumOK$knowledge=="Knowledge" & d2c.sumOK$outcome=="Bad Outcome"],digits=2)`, *SD* = `r round(d2c.sumOK$sd[d2c.sumOK$knowledge=="Knowledge" & d2c.sumOK$outcome=="Bad Outcome"],digits=2)`). For the good outcomes, we found a still significant, but much less strong effect of knowledge, $\chi^2(2)$ = `r round(lmr2c.K_G$Chisq[2],digits=3)`, *p* = = `r max(.001,round(lmr2c.K_G$'Pr(>Chisq)'[2],digits=3))`, such that *ignorant* agents were again seen as less causal (*M* = `r round(d2c.sumOK$mean[d2c.sumOK$knowledge=="Ignorance" & d2c.sumOK$outcome=="Good Outcome"],digits=2)`, *SD* = `r round(d2c.sumOK$sd[d2c.sumOK$knowledge=="Ignorance" & d2c.sumOK$outcome=="Good Outcome"],digits=2)`) than *knowledgeable* agents (*M* = `r round(d2c.sumOK$mean[d2c.sumOK$knowledge=="Knowledge" & d2c.sumOK$outcome=="Good Outcome"],digits=2)`, *SD* = `r round(d2c.sumOK$sd[d2c.sumOK$knowledge=="Knowledge" & d2c.sumOK$outcome=="Good Outcome"],digits=2)`) (*Fig*. 4a).

```{r 2cdFig, fig.width=8.5, echo=FALSE, fig.cap="Participants' causal judgments as a function of both the knowledge of the agent who initiated the causal chain and the kind of norm that governed the agent's action, for both bad outcomes (left) and good outcomes (right). Error bars indicate +/- 1 *SEM*."}
d2c.plot <- ggplot(d2c.sum, aes(x=norm, y=mean, fill=knowledge)) +
  geom_bar(stat="identity", position="dodge") + 
  facet_wrap(~outcome) +
  ylab("Didn't Cause (1) ~ Caused (7)") +
  xlab("") +
  scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
  coord_cartesian(ylim=c(1,7)) +
  geom_errorbar(aes(ymin=mean-se, ymax=mean+se), width=.1, position=position_dodge(.9)) +
  #ggtitle("Bad Outcomes") +
  theme_bw() +
  theme(
    plot.background = element_blank()
    ,plot.title=element_text(hjust=.5)
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    #,legend.position = c(.9,.85)
    #,legend.position = "null"
    ,legend.title=element_text(size=rel(1))
    ,legend.text=element_text(size=rel(1))
    ,axis.text.y=element_text(size=rel(1))
    ,axis.text.x=element_text(size=rel(1))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1))
  )


print(d2c.plot)

#grid.arrange(d2a.plot, d2b.plot, ncol=2)

```

## Discussion

### from outline:

-   There is a significant interaction effect
    -   Imporantly this interaction arises for both the moral and rational norm violations, suggesting that the effect is unlikely to be explained by the motivational/polysemy accounts.
    -   However, if not explained by those accounts, then what does explain this interaction effect. One previously undiscussed feature of good vs. bad outcomes is that they differ in their normality -- in particular, good outcoems in these cases have all been more normal than bad outcomes (normality here referencing Bear & Knobe).

# Experiment 2d: Combined analyses and new ratings

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study. <!-- 21-word solution (Simmons, Nelson & Simonsohn, 2012; retrieved from http://ssrn.com/abstract=2160588) -->

### Participants

```{r study2d participants, echo=FALSE}

# morality and rationality ratings of the agent's actions: 
d2da_demo <- read.csv("../data/d8demo.csv")
d2da_demo$gender <- factor(c("Male","Female")[d2da_demo$gender])
d2da_demo$edu <- factor(c("Grammar School","Highschool or Equivalent","Vocational/Technical School",
                                 "Some College","College Graduate (4 years)","Master's Degree",
                                 "Doctoral Degree (PhD)","Professional Degree (JD,MD,etc.)","Other")[d2da_demo$edu])
##Age and Gender
d2da.age <- matrix(c("mean",mean(d2da_demo$age,na.rm=T),"sd",sd(d2da_demo$age,na.rm=T),"n",length(d2da_demo$age)),ncol = 3)
d2da.gender <- table(d2da_demo$gender, exclude=NULL)

###Education
d2da.education <- table(d2da_demo$edu)

# counterfactual ratings: 
d2dc_demo <- read.csv("../data/d9demo.csv")
d2dc_demo$gender <- factor(c("Male","Female")[d2dc_demo$gender])
d2dc_demo$edu <- factor(c("Grammar School","Highschool or Equivalent","Vocational/Technical School",
                                 "Some College","College Graduate (4 years)","Master's Degree",
                                 "Doctoral Degree (PhD)","Professional Degree (JD,MD,etc.)","Other")[d2dc_demo$edu])
##Age and Gender
d2dc.age <- matrix(c("mean",mean(d2dc_demo$age,na.rm=T),"sd",sd(d2dc_demo$age,na.rm=T),"n",length(d2dc_demo$age)),ncol = 3)
d2dc.gender <- table(d2dc_demo$gender, exclude=NULL)

###Education
d2dc.education <- table(d2dc_demo$edu)

```

For ratings of the morality and rationality of the agent's actions, `r d2da.age[2,3]` participants (*M*~age~=`r round(mean(d2da_demo$age, na.rm=T),digits=2)`, *SD*~age~=`r round(sd(d2da_demo$age, na.rm=T),digits=2)`; `r d2da.gender[[1]]` females) were recruited. For ratings of which counterfactual choices were relevant, `r d2dc.age[2,3]` participants (*M*~age~=`r round(mean(d2dc_demo$age, na.rm=T),digits=2)`, *SD*~age~=`r round(sd(d2dc_demo$age, na.rm=T),digits=2)`; `r d2dc.gender[[1]]` females) were recruited. All participants were recruited through Amazon Mechanical Turk (<http://www.mturk.com>).

### Materials

In both studies, participants completed 16 trials which each involved reading the brief vignettes about causal chains as in the previous studies. As in Study 2c, the design for both studies was a 2 (Norm Type) $\times$ 2 (Agent Knowledge) $\times$ 2 (Outcome Valence) $\times$ 16 (Scenario) design that was administered in a mixed within- and between-subjects fashion, such that participants saw all 16 scenarios and on each trial were randomly assigned to read 1 of the 8 different versions of that scenario.

### Procedure

For the ratings of the morality and rationality, participants first read the brief vignette and then answered two questions about the morality and rationality of the agent's action. In the example scenario we have been using throughout, these questions read as follows:

> *Morality Question*: Was it immoral for Harry to choose the lisence to fish in the area he initially wanted?

> *Rationality Question*: Was it irrational for Harry to choose the lisence to fish in the area he initially wanted?

Participants answered both questions on a 7-point Likert scale from 1 ('Not at all') to 7 ('Completely'), with a midpoint of 4 ('In between').

For the counterfactual judgments, participants selected the best way to complete a counterfactual statement about the prevention of the outcome. For example, in the good outcome versions of the scenario with Harry, this question reads as follows:

> *Counterfactual Question*: If only $\underline{\hspace{3cm}}$ had been different, the coral reef would not have grown by several meters in every direction.\
> a. Harry\
> b. the fish population

Participants were asked to complete a brief demographic questionnaire after completing all 16 trials.

### Data analysis

No participant was excluded from the analyses as long as the entire study was completed. For analyses involving causal judgments, we used data collected in Studies 2a-2c. We then combined and analyzed all relevant data at the level of the various scenarios.

## Results

```{r study2d combinedAnalyses, echo=FALSE, message=FALSE, warning=FALSE}

d2a$outcome <- "Bad Outcome"
d2b$outcome <- "Good Outcome"
d2 <- rbind(d2a,d2b,d2c)

d2.sums <- d2 %>% 
  group_by(knowledge,norm,outcome,vign) %>% 
                  summarise(N.cause = length(cause),
                           mean.cause = mean(cause, na.rm=TRUE),
                           sd.cause = sd(cause,na.rm=TRUE),
                           se.cause = sd.cause / sqrt(N.cause))


d2da <- read.csv("../data/d8data.csv")

d2da$norm <- factor(d2da$norm)
d2da$norm <- factor(c("Moral Norm","Rational Norm")[d2da$norm])

d2da$quest <- factor(d2da$quest)
d2da$quest <- factor(c("Morality","Rationality")[d2da$quest])

d2da$valueS[d2da$quest=="Morality"] <- scale(d2da$value[d2da$quest=="Morality"])
d2da$valueS[d2da$quest=="Rationality"] <- scale(d2da$value[d2da$quest=="Rationality"])

#MORALITY RATINGS:

## three-way interaction
# lmr2d.0m <- lmer(valueS ~ knowledge * norm * outcome + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Morality",])
# lmr2d.1m <- lmer(valueS ~ (knowledge * norm) + (outcome * knowledge) + (outcome * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Morality",])
# lmr2da.i3x.m <- anova(lmr2d.0m,lmr2d.1m)
# saveRDS(lmr2da.i3x.m,"models/lmr2di3x_m.rds")
lmr2d.i3x.m <- readRDS("models/lmr2di3x_m.rds")


## Morality: Norm x Knowledge interaction 
# lmr2d.2m <- lmer(valueS ~ (knowledge * outcome) + (outcome * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Morality",])
# lmr2d.NxK.m <- anova(lmr2d.1m,lmr2d.2m)
# saveRDS(lmr2d.NxK.m,"models/lmr2dNxK_m.rds")
lmr2d.NxK.m <- readRDS("models/lmr2dNxK_m.rds")
d2da.NxK.m <- d2da %>% filter(d2da$quest=="Morality") %>%
                       group_by(knowledge,norm,subj) %>% 
                       summarise(means=mean(value, na.rm = T)) 
# ### Moral norms, knowledge vs. ignorance t-test (decided to use estimated marginal means instead)
# include <- d2da.NxK.m$subj[d2da.NxK.m$norm=="Moral Norm" & d2da.NxK.m$knowledge=="Ignorance"] %in% d2da.NxK.m$subj[d2da.NxK.m$norm=="Moral Norm" & d2da.NxK.m$knowledge=="Knowledge"]
# # var.test(d2da.NxK.m$means[d2da.NxK.m$norm=="Moral Norm" & d2da.NxK.m$knowledge=="Knowledge"][include],
# #        d2da.NxK.m$means[d2da.NxK.m$norm=="Moral Norm" & d2da.NxK.m$knowledge=="Ignorance"][include])
# d2da.M.KvI <- t.test(d2da.NxK.m$means[d2da.NxK.m$norm=="Moral Norm" & d2da.NxK.m$knowledge=="Knowledge"][include],
#                      d2da.NxK.m$means[d2da.NxK.m$norm=="Moral Norm" & d2da.NxK.m$knowledge=="Ignorance"][include],  paired=T, var.equal = T)
# ### Rational norms, knowledge vs. ignorance
# # var.test(d2da.NxK.m$means[d2da.NxK.m$norm=="Rational Norm" & d2da.NxK.m$knowledge=="Knowledge"],
# #          d2da.NxK.m$means[d2da.NxK.m$norm=="Rational Norm" & d2da.NxK.m$knowledge=="Ignorance"])
# d2da.R.KvI <- t.test(d2da.NxK.m$means[d2da.NxK.m$norm=="Rational Norm" & d2da.NxK.m$knowledge=="Knowledge"],
#                      d2da.NxK.m$means[d2da.NxK.m$norm=="Rational Norm" & d2da.NxK.m$knowledge=="Ignorance"],  paired=T, var.equal = T)

### Norm x Knowledge interaction EMM
#em.M.NxK <- summary((emmeans(lmr2d.0m, specs = pairwise ~ knowledge:norm, lmerTest.limit = 3200, pbkrtest.limit= 3200))$contrasts)
d2da.NxK.m <- d2da.NxK.m %>%
               group_by(knowledge,norm) %>% 
               summarise(N = length(means),
                       mean = mean(means, na.rm=TRUE),
                       sd = sd(means,na.rm=TRUE),
                       se = sd / sqrt(N))
#saveRDS(em.M.NxK, "models/em.M.NxK.rds")
em.M.NxK <- readRDS("models/em.M.NxK.rds")



## Morality: Norm x Outcome interaction
# lmr2d.3m <- lmer(valueS ~ (knowledge * outcome) + (knowledge * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Morality",])
# lmr2d.NxO.m <- anova(lmr2d.1m,lmr2d.3m)
# saveRDS(lmr2d.NxO.m,"models/lmr2dNxO_m.rds")
lmr2d.NxO.m <- readRDS("models/lmr2dNxO_m.rds")
d2da.NxO.m <- d2da %>% 
              filter(d2da$quest=="Morality") %>%
              group_by(norm,outcome,subj) %>% 
              summarise(means=mean(value, na.rm = T)) 
# ### Moral norms, good outcome vs. bad outcome t-test (decided to use estimated marginal means instead)
# include.NxO.m.moral <- d2da.NxO.m$subj[d2da.NxO.m$norm=="Moral Norm" & d2da.NxO.m$outcome=="Good Outcome"] %in% d2da.NxO.m$subj[d2da.NxO.m$norm=="Moral Norm" & d2da.NxO.m$outcome=="Bad Outcome"]
# include.NxO.m.rational <- d2da.NxO.m$subj[d2da.NxO.m$norm=="Rational Norm" & d2da.NxO.m$outcome=="Bad Outcome"] %in% d2da.NxO.m$subj[d2da.NxO.m$norm=="Rational Norm" & d2da.NxO.m$outcome=="Good Outcome"]
# d2da.M.GvB.m <- t.test(d2da.NxO.m$means[d2da.NxO.m$norm=="Moral Norm" & d2da.NxO.m$outcome=="Good Outcome"][include.NxO.m.moral],
#                      d2da.NxO.m$means[d2da.NxO.m$norm=="Moral Norm" & d2da.NxO.m$outcome=="Bad Outcome"][include.NxO.m.moral],  paired=T, var.equal = T)
# ### Rational norms, good outcome vs. bad outcome
# d2da.M.GvB.r <- t.test(d2da.NxO.m$means[d2da.NxO.m$norm=="Rational Norm" & d2da.NxO.m$outcome=="Good Outcome"][include.NxO.m.rational],                     d2da.NxO.m$means[d2da.NxO.m$norm=="Rational Norm" & d2da.NxO.m$outcome=="Bad Outcome"][include.NxO.m.rational], paired=T, var.equal = T)
# #######(different lengths if paired=T)

### Outcome x Norm interaction EMM
#em.M.NxO <- summary((emmeans(lmr2d.0m, specs = pairwise ~ outcome:norm, lmerTest.limit = 3200, pbkrtest.limit= 3200))$contrasts)
#saveRDS(em.M.NxO, "models/em.M.NxO.rds")
em.M.NxO <- readRDS("models/em.M.NxO.rds")



## Morality: Outcome Valence x Knowledge interaction (insignificant)
#lmr2d.4m <- lmer(valueS ~ (norm * outcome) + (knowledge * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Morality",])
#lmr2d.OxK.m <- anova(lmr2d.1m,lmr2d.4m)
#saveRDS(lmr2d.OxK.m,"models/lmr2dOxK_m.rds")
lmr2d.OxK.m <- readRDS("models/lmr2dOxK_m.rds") 



## Morality: Main effects
# lmr2d.m.main <- lmer(valueS ~ knowledge + outcome + norm + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Morality",])

# lmr2d.m.outcome <- lmer(valueS ~ knowledge + norm + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Morality",])
# lmr2d.m.outcome <- anova(lmr2d.m.main,lmr2d.m.outcome)
# saveRDS(lmr2d.m.outcome,"models/lmr2d.m.outcome.rds")
lmr2d.m.outcome <- readRDS("models/lmr2d.m.outcome.rds")

# lmr2d.m.norm <- lmer(valueS ~ knowledge + outcome + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Morality",])
# lmr2d.m.norm <- anova(lmr2d.m.main,lmr2d.m.norm)
# saveRDS(lmr2d.m.norm,"models/lmr2d.m.norm.rds")
lmr2d.m.norm <- readRDS("models/lmr2d.m.norm.rds")

# lmr2d.m.knowledge <- lmer(valueS ~ outcome + norm + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Morality",])
# lmr2d.m.knowledge <- anova(lmr2d.m.main,lmr2d.m.knowledge)
# saveRDS(lmr2d.m.knowledge,"models/lmr2d.m.knowledge.rds")
lmr2d.m.knowledge <- readRDS("models/lmr2d.m.knowledge.rds")


d2da.m.sumK <- d2da %>% 
  filter(quest == "Morality") %>%
  dplyr::select(knowledge,value,subj) %>%
  group_by(knowledge, subj) %>%
  summarise(moralityK = mean(value),na.rm=TRUE) %>%
  group_by(knowledge) %>%
  summarise(N = length(moralityK),
           mean = mean(moralityK, na.rm=TRUE),
           sd = sd(moralityK,na.rm=TRUE),
           se = sd / sqrt(N))

d2da.m.sumO <- d2da %>% 
  filter(quest == "Morality") %>%
  dplyr::select(outcome,value,subj) %>%
  group_by(outcome, subj) %>%
  summarise(moralityO = mean(value),na.rm=TRUE) %>%
  group_by(outcome) %>%
  summarise(N = length(moralityO),
           mean = mean(moralityO, na.rm=TRUE),
           sd = sd(moralityO,na.rm=TRUE),
           se = sd / sqrt(N))

d2da.m.sumN <- d2da %>% 
  filter(quest == "Morality") %>%
  dplyr::select(norm,value,subj) %>%
  group_by(norm, subj) %>%
  summarise(moralityN = mean(value),na.rm=TRUE) %>%
  group_by(norm) %>%
  summarise(N = length(moralityN),
           mean = mean(moralityN, na.rm=TRUE),
           sd = sd(moralityN,na.rm=TRUE),
           se = sd / sqrt(N))






#RATIONALITY RATINGS: 

## three-way interaction (insignificant)
# lmr2d.0r <- lmer(valueS ~ knowledge * norm * outcome + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Rationality",])
# lmr2d.1r <- lmer(valueS ~ (knowledge * norm) + (outcome * knowledge) + (outcome * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Rationality",])
# lmr2da.i3x.r <- anova(lmr2d.0r,lmr2d.1r)
# saveRDS(lmr2da.i3x.r,"models/lmr2di3x_r.rds")
lmr2d.i3x.r <- readRDS("models/lmr2di3x_r.rds")

## Rationality: Norm x Knowledge interaction (insignificant)
# lmr2d.2r <- lmer(valueS ~ (knowledge * outcome) + (outcome * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Rationality",])
# lmr2d.NxK.r <- anova(lmr2d.1r,lmr2d.2r)
# saveRDS(lmr2d.NxK.r,"models/lmr2dNxK_r.rds")
lmr2d.NxK.r <- readRDS("models/lmr2dNxK_r.rds")
d2da.NxK.r <- d2da %>% filter(d2da$quest=="Rationality") %>%
                       group_by(knowledge,norm,subj) %>% 
                       summarise(means=mean(value, na.rm = T)) 
d2da.NxK.r <- d2da.NxK.r %>%
               group_by(knowledge,norm) %>% 
               summarise(N = length(means),
                       mean = mean(means, na.rm=TRUE),
                       sd = sd(means,na.rm=TRUE),
                       se = sd / sqrt(N))



## Rationality: Norm x Outcome interaction
# lmr2d.3r <- lmer(valueS ~ (knowledge * outcome) + (knowledge * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Rationality",])
# lmr2d.NxO.r <- anova(lmr2d.1r,lmr2d.3r)
#saveRDS(lmr2d.NxO.r,"models/lmr2dNxO_r.rds")
lmr2d.NxO.r <- readRDS("models/lmr2dNxO_r.rds")

d2da.NxO.r <- d2da %>% filter(d2da$quest=="Rationality") %>%
                       group_by(norm,outcome,subj) %>% 
                       summarise(means=mean(value, na.rm = T)) 
      # ### Norm*Outcome t-test (decided to use estimted marginal means instead)
      # include.NxO.r.moral <- d2da.NxO.r$subj[d2da.NxO.r$norm=="Moral Norm" & d2da.NxO.r$outcome=="Good Outcome"] %in% d2da.NxO.r$subj[d2da.NxO.r$norm=="Moral Norm" & d2da.NxO.r$outcome=="Bad Outcome"]
      # include.NxO.r.rational <- d2da.NxO.r$subj[d2da.NxO.r$norm=="Rational Norm" & d2da.NxO.r$outcome=="Bad Outcome"] %in% d2da.NxO.r$subj[d2da.NxO.r$norm=="Rational Norm" & d2da.NxO.r$outcome=="Good Outcome"]
      # d2da.R.GvB.m <- t.test(d2da.NxO.r$means[d2da.NxO.r$norm=="Moral Norm" & d2da.NxO.r$outcome=="Bad Outcome"][include.NxO.r.moral], d2da.NxO.r$means[d2da.NxO.r$norm=="Moral Norm" & d2da.NxO.r$outcome=="Good Outcome"][include.NxO.r.moral],  paired=T, var.equal = T)
      # ### Rational norms, good outcome vs. bad outcome
      # d2da.R.GvB.r <- t.test(d2da.NxO.r$means[d2da.NxO.r$norm=="Rational Norm" & d2da.NxO.r$outcome=="Good Outcome"][include.NxO.r.rational],                     d2da.NxO.r$means[d2da.NxO.r$norm=="Rational Norm" & d2da.NxO.r$outcome=="Bad Outcome"][include.NxO.r.rational], paired=T, var.equal = T)

### Outcome x Norm interaction EMM
#em.R.NxO <- summary((emmeans(lmr2d.0r, specs = pairwise ~ norm:outcome, lmerTest.limit = 3200, pbkrtest.limit= 3200)$contrasts))
#saveRDS(em.R.NxO, "models/em.R.NxO.rds")
em.R.NxO <- readRDS("models/em.R.NxO.rds")

d2da.NxO.r <- d2da.NxO.r %>%
               group_by(norm,outcome) %>% 
               summarise(N = length(means),
                       mean = mean(means, na.rm=TRUE),
                       sd = sd(means,na.rm=TRUE),
                       se = sd / sqrt(N))



## Rationality: Outcome Valence x Knowledge interaction
# lmr2d.4r <- lmer(valueS ~ (norm * outcome) + (knowledge * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Rationality",])
# lmr2d.OxK.r <- anova(lmr2d.1r,lmr2d.4r)
# saveRDS(lmr2d.OxK.r,"models/lmr2dOxK_r.rds")
lmr2d.OxK.r <- readRDS("models/lmr2dOxK_r.rds")
d2da.OxK.r <- d2da %>% filter(d2da$quest=="Rationality") %>%
                       group_by(knowledge,outcome,subj) %>% 
                       summarise(means=mean(value, na.rm = T)) 
      # ### Knowledge*Outcome t-test (decided to use estimted marginal means instead)
      # include.OxK.r.knowledge <- d2da.OxK.r$subj[d2da.OxK.r$knowledge=="Knowledge" & d2da.OxK.r$outcome=="Good Outcome"] %in% d2da.OxK.r$subj[d2da.OxK.r$knowledge=="Knowledge" & d2da.OxK.r$outcome=="Bad Outcome"]
      # include.OxK.r.ignorance <- d2da.OxK.r$subj[d2da.OxK.r$knowledge=="Ignorance" & d2da.OxK.r$outcome=="Bad Outcome"] %in% d2da.OxK.r$subj[d2da.OxK.r$knowledge=="Ignorance" & d2da.OxK.r$outcome=="Good Outcome"]
      # d2da.R.GvB.k <- t.test(d2da.OxK.r$means[d2da.OxK.r$knowledge=="Knowledge" & d2da.OxK.r$outcome=="Bad Outcome"][include.OxK.r.knowledge], d2da.OxK.r$means[d2da.OxK.r$knowledge=="Knowledge" & d2da.OxK.r$outcome=="Good Outcome"][include.OxK.r.knowledge],  paired=T, var.equal = T)
      # ### Ignorance, good outcome vs. bad outcome
      # d2da.R.GvB.i <- t.test(d2da.OxK.r$means[d2da.OxK.r$knowledge=="Ignorance" & d2da.OxK.r$outcome=="Good Outcome"][include.OxK.r.ignorance],                     d2da.OxK.r$means[d2da.OxK.r$knowledge=="Ignorance" & d2da.OxK.r$outcome=="Bad Outcome"][include.OxK.r.ignorance], paired=T, var.equal = T)

###  Outcome x Knowledge interaction EMM
#em.R.OxK <- summary((emmeans(lmr2d.0r, specs = pairwise ~ knowledge:outcome, lmerTest.limit = 3200, pbkrtest.limit= 3200))$contrasts)
#saveRDS(em.R.OxK, "models/em.R.OxK.rds")
em.R.OxK <- readRDS("models/em.R.OxK.rds")

d2da.OxK.r <- d2da.OxK.r %>%
               group_by(knowledge,outcome) %>% 
               summarise(N = length(means),
                       mean = mean(means, na.rm=TRUE),
                       sd = sd(means,na.rm=TRUE),
                       se = sd / sqrt(N))






##Rationality: Main effects
# lmr2d.r.main <- lmer(valueS ~ knowledge + outcome + norm + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Rationality",])

# lmr2d.r.outcome <- lmer(valueS ~ knowledge + norm + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Rationality",]) 
# lmr2d.r.outcome <- anova(lmr2d.r.main,lmr2d.r.outcome)
# saveRDS(lmr2d.r.outcome,"models/lmr2d.r.outcome.rds")
lmr2d.r.outcome <- readRDS("models/lmr2d.r.outcome.rds")

# lmr2d.r.norm <- lmer(valueS ~ knowledge + outcome + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Rationality",]) 
# lmr2d.r.norm <- anova(lmr2d.r.main,lmr2d.r.norm)
# saveRDS(lmr2d.r.norm,"models/lmr2d.r.norm.rds")
lmr2d.r.norm <- readRDS("models/lmr2d.r.norm.rds")

# lmr2d.r.knowledge <- lmer(valueS ~ outcome + norm + (knowledge*norm*outcome|subj) + (1|vign), data=d2da[d2da$quest=="Rationality",]) 
# lmr2d.r.knowledge <- anova(lmr2d.r.main,lmr2d.r.knowledge)
# saveRDS(lmr2d.r.knowledge,"models/lmr2d.r.knowledge.rds")
lmr2d.r.knowledge <- readRDS("models/lmr2d.r.knowledge.rds")


d2da.r.sumK <- d2da %>% 
  filter(quest == "Rationality") %>%
  dplyr::select(knowledge,value,subj) %>%
  group_by(knowledge, subj) %>%
  summarise(rationalityK = mean(value),na.rm=TRUE) %>%
  group_by(knowledge) %>%
  summarise(N = length(rationalityK),
           mean = mean(rationalityK, na.rm=TRUE),
           sd = sd(rationalityK,na.rm=TRUE),
           se = sd / sqrt(N))

d2da.r.sumO <- d2da %>% 
  filter(quest == "Rationality") %>%
  dplyr::select(outcome,value,subj) %>%
  group_by(outcome, subj) %>%
  summarise(rationalityO = mean(value),na.rm=TRUE) %>%
  group_by(outcome) %>%
  summarise(N = length(rationalityO),
           mean = mean(rationalityO, na.rm=TRUE),
           sd = sd(rationalityO,na.rm=TRUE),
           se = sd / sqrt(N))

d2da.r.sumN <- d2da %>% 
  filter(quest == "Rationality") %>%
  dplyr::select(norm,value,subj) %>%
  group_by(norm, subj) %>%
  summarise(rationalityN = mean(value),na.rm=TRUE) %>%
  group_by(norm) %>%
  summarise(N = length(rationalityN),
           mean = mean(rationalityN, na.rm=TRUE),
           sd = sd(rationalityN,na.rm=TRUE),
           se = sd / sqrt(N))

```

First, we asked whether participants' judgments of the morality and rationality of the agents' actions tracked our manipulations as intended. Then we examined the counterfactual choices in a similar fashion.

### Morality Question

We started with participants' moral judgments and found main effects across *Knowledge*, *Norm* and *Outcome* respectively. First, there is a main effect of the agent's knowledge about the consequences of their action, $\chi^2(1)$ = `r round(lmr2d.m.knowledge$Chisq[2],digits=3)`, *p* $<$ `r max(.001,round(lmr2d.m.knowledge$'Pr(>Chisq)'[2],digits=3))`, such that knowledgeable agents were overall seen as less moral (*M* = `r round(d2da.m.sumK$mean[d2da.m.sumK$knowledge=="Knowledge"],digits=2)`, *SD* = `r round(d2da.m.sumK$sd[d2da.m.sumK$knowledge=="Knowledge"],digits=2)`) than ignorant agents (*M* = `r round(d2da.m.sumK$mean[d2da.m.sumK$knowledge=="Ignorance"],digits=2)`, *SD* = `r round(d2da.m.sumK$sd[d2da.m.sumK$knowledge=="Ignorance"],digits=2)`). Second, we found a main effect of the type of norm agent violated, $\chi^2(1)$ = `r round(lmr2d.m.norm$Chisq[2],digits=3)`, *p* $<$ `r max(.001,round(lmr2d.m.norm$'Pr(>Chisq)'[2],digits=3))`, which suggests that agents who violated rational norms were judged as less immoral (*M* = `r round(d2da.m.sumN$mean[d2da.m.sumN$norm=="Rational Norm"],digits=2)`, *SD* = `r round(d2da.m.sumN$sd[d2da.m.sumN$norm=="Rational Norm"],digits=2)`) than agents who violated moral norms (*M* = `r round(d2da.m.sumN$mean[d2da.m.sumN$norm=="Moral Norm"],digits=2)`, *SD* = `r round(d2da.m.sumN$sd[d2da.m.sumN$norm=="Moral Norm"],digits=2)`). Third, a main effect of the final outcome was discovered, $\chi^2(1)$ = `r round(lmr2d.m.outcome$Chisq[2],digits=3)`, *p* $<$ `r max(.001,round(lmr2d.m.outcome$'Pr(>Chisq)'[2],digits=3))`: participants considered agents whose actions resulted in a bad outcome to be more immoral (*M* = `r round(d2da.m.sumO$mean[d2da.m.sumO$outcome=="Bad Outcome"],digits=2)`, *SD* = `r round(d2da.m.sumO$sd[d2da.m.sumO$outcome=="Bad Outcome"],digits=2)`) than agents whose actions resulted in a good outcome (*M* = `r round(d2da.m.sumO$mean[d2da.m.sumO$outcome=="Good Outcome"],digits=2)`, *SD* = `r round(d2da.m.sumO$sd[d2da.m.sumO$outcome=="Good Outcome"],digits=2)`).

We then conducted analysis to see whether there was a significant *Knowledge* $\times$ *Norm* $\times$ *Outcome* interaction effect. We did not find one, $\chi^2(1)$ = `r round(lmr2d.i3x.m$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2d.i3x.m$'Pr(>Chisq)'[2],digits=3))`. We next investigated three possible 2-way interactions and used estimated marginal means for pairwise comparisons. As expected, we found a significant *Norm* $\times$ *Knowledge* interaction, $\chi^2(1)$ = `r round(lmr2d.NxK.m$Chisq[2],digits=3)`, *p* $<$ `r max(.001,round(lmr2d.NxK.m$'Pr(>Chisq)'[2],digits=3))`. This interaction reflects the fact that participants judged that agents acted more immorally when knowingly violating a moral norm (*M* = `r round(d2da.NxK.m$mean[d2da.NxK.m$knowledge=="Knowledge" & d2da.NxK.m$norm=="Moral Norm"],digits=2)`, *SD* = `r round(d2da.NxK.m$sd[d2da.NxK.m$knowledge=="Knowledge" & d2da.NxK.m$norm=="Moral Norm"],digits=2)`) than when doing so unknowingly (*M* = `r round(d2da.NxK.m$mean[d2da.NxK.m$knowledge=="Ignorance" & d2da.NxK.m$norm=="Moral Norm"],digits=2)`, *SD* = `r round(d2da.NxK.m$sd[d2da.NxK.m$knowledge=="Ignorance" & d2da.NxK.m$norm=="Moral Norm"],digits=2)`), *t-ratio(`r round(em.M.NxK[1,4],digits=3)`)* $=$ `r round(em.M.NxK[1,5],digits=3)`, *p* $<$ `r max(.001, round(em.M.NxK[1,6],digits=3))`, but differentiated less between the morality of knowingly violating a rational norm (*M* = `r round(d2da.NxK.m$mean[d2da.NxK.m$knowledge=="Knowledge" & d2da.NxK.m$norm=="Rational Norm"],digits=2)`, *SD* = `r round(d2da.NxK.m$sd[d2da.NxK.m$knowledge=="Knowledge" & d2da.NxK.m$norm=="Rational Norm"],digits=2)`) and unknowingly doing so (*M* = `r round(d2da.NxK.m$mean[d2da.NxK.m$knowledge=="Ignorance" & d2da.NxK.m$norm=="Rational Norm"],digits=2)`, *SD* = `r round(d2da.NxK.m$sd[d2da.NxK.m$knowledge=="Ignorance" & d2da.NxK.m$norm=="Rational Norm"],digits=2)`), *t-ratio(`r round(em.M.NxK[6,4],digits=3)`)* $=$ `r round(em.M.NxK[6,5],digits=3)`, *p* $<$ `r max(.001, round(em.M.NxK[6,6],digits=3))`. We also observed an unexpected yet significant *Norm* $\times$ *Outcome* interaction $\chi^2(1)$ = `r round(lmr2d.NxO.m$Chisq[2],digits=3)`, *p* $<$ `r max(.001, round(lmr2d.NxO.m$'Pr(>Chisq)'[2], digits=3))`, indicating that participants considered agents as acting more immorally when violating a rational norm resulted in a bad outcome than when doing so resulted in a good outcome, *t-ratio(`r round(em.M.NxO[6,4],digits=3)`)* $=$ `r round(em.M.NxO[6,5],digits=3)`, *p* $<$ `r max(.001, round(em.M.NxO[6,6],digits=3))`, but more consistently regarded the agent as simply having acted immorally when the agent violated a moral norm, regardless of outcome, *t-ratio(`r round(em.M.NxO[1,4],digits=3)`)* $=$ `r round(em.M.NxO[1,5],digits=3)`, *p* $<$ `r max(.001, round(em.M.NxO[1,6],digits=3))`. No significant *Knowledge* $\times$ *Outcome* interaction effect was found, $\chi^2(1)$ = `r round(lmr2d.OxK.m$Chisq[2],digits=3)`, *p* = `r max(.001, round(lmr2d.OxK.m$'Pr(>Chisq)'[2], digits=3))`.

### Rationality Questions

We next subjected participants' judgments of rationality to the same set of analyses. We found main effects in *Knowledge* and *Outcome*, but not *Norm*, $\chi^2(1)$ = `r round(lmr2d.r.norm$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr2d.r.norm$'Pr(>Chisq)'[2],digits=3))`. The analysis revealed a main effect of the agent's knowledge about the consequences of their action, $\chi^2(1)$ = `r round(lmr2d.r.knowledge$Chisq[2],digits=3)`, *p* $<$ `r max(.001,round(lmr2d.r.knowledge$'Pr(>Chisq)'[2],digits=3))`, suggesting that knowledgeable agents were in general seen as less rational (*M* = `r round(d2da.r.sumK$mean[d2da.r.sumK$knowledge=="Knowledge"],digits=2)`, *SD* = `r round(d2da.r.sumK$sd[d2da.r.sumK$knowledge=="Knowledge"],digits=2)`) than their ignorant counterparts (*M* = `r round(d2da.r.sumK$mean[d2da.r.sumK$knowledge=="Ignorance"],digits=2)`, *SD* = `r round(d2da.r.sumK$sd[d2da.r.sumK$knowledge=="Ignorance"],digits=2)`). We also discovered the main effect of the final outcome, $\chi^2(1)$ = `r round(lmr2d.r.outcome$Chisq[2],digits=3)`, *p* $<$ `r max(.001,round(lmr2d.r.outcome$'Pr(>Chisq)'[2],digits=3))`: agents whose actions resulted in a bad outcome were considered to be more irrational (*M* = `r round(d2da.r.sumO$mean[d2da.r.sumO$outcome=="Bad Outcome"],digits=2)`, *SD* = `r round(d2da.r.sumO$sd[d2da.r.sumO$outcome=="Bad Outcome"],digits=2)`) than agents whose actions resulted in a good outcome (*M* = `r round(d2da.r.sumO$mean[d2da.r.sumO$outcome=="Good Outcome"],digits=2)`, *SD* = `r round(d2da.r.sumO$sd[d2da.r.sumO$outcome=="Good Outcome"],digits=2)`).

The analysis also revealed no *Knowledge* $\times$ *Norm* $\times$ *Outcome* interaction effect, $\chi^2(1)$ = `r round(lmr2d.i3x.r$Chisq[2],digits=3)`, *p* = `r max(.001, round(lmr2d.i3x.r$'Pr(>Chisq)'[2], digits=3))`. We also did not find a significant *Norm* $\times$ *Knowledge* interaction, $\chi^2(1)$ = `r round(lmr2d.NxK.r$Chisq[2],digits=3)`, *p* = `r max(.001, round(lmr2d.NxK.r$'Pr(>Chisq)'[2], digits=3))`, suggesting that knowing violations of moral norms and rational norms were both perceived as similarly more irrational than ignorant violations of those norms. We again observed an unexpected, small but significant *Norm* $\times$ *Outcome* interaction effect, $\chi^2(1)$ = `r round(lmr2d.NxO.r$Chisq[2],digits=3)`, *p* = `r max(.001, round(lmr2d.NxO.r$'Pr(>Chisq)'[2], digits=3))`, indicating that participants differentiated more between violations of rational norms that result in different outcomes, *t-ratio(`r round(em.R.NxO[5,4],digits=3)`)* $=$ `r round(em.R.NxO[5,5],digits=3)`, *p* $<$ `r max(.001, round(em.R.NxO[5,6],digits=3))`, than between violations of moral norms resulting in different outcomes, *t-ratio(`r round(em.R.NxO[2,4],digits=3)`)* $=$ `r round(em.R.NxO[2,5],digits=3)`, *p*=`r max(.001, round(em.R.NxO[2,6],digits=3))`. In addition, we found a *Knowledge* $\times$ *Outcome* interaction effect, $\chi^2(1)$ = `r round(lmr2d.OxK.r$Chisq[2],digits=3)`, *p* = `r max(.001, round(lmr2d.OxK.r$'Pr(>Chisq)'[2], digits=3))`, which shows that when agents were ignorant about violating a norm, judgments of their rationality were less influenced by the valence of the outcome, *t-ratio(`r round(em.R.OxK[2,4],digits=3)`)* $=$ `r round(em.R.OxK[2,5],digits=3)`, *p* $<$ `r max(.001, round(em.R.OxK[2,6],digits=3))`, than when agents were knowledgeable about violating a norm, *t-ratio(`r round(em.R.OxK[5,4],digits=3)`)* $=$ `r round(em.R.OxK[5,5],digits=3)`, *p* $<$`r max(.001, round(em.R.OxK[5,6],digits=3))`.

```{r moralRationalfig, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Participants' ratings of the agent's morality (top) and rationality (bottom) as a function of the knowledge status, the type of norm violated and the outcome valence.", fig.height=6}

d2da.sum <- d2da %>% group_by(knowledge,norm,outcome,quest,subj) %>% 
                     summarise(means=mean(value, na.rm = T)) %>%
                     group_by(knowledge,norm,outcome,quest) %>% 
                     summarise(N = length(means),
                               mean = mean(means, na.rm=TRUE),
                               sd = sd(means,na.rm=TRUE),
                               se = sd / sqrt(N))


d2d.fig.m <- ggplot(d2da.sum[d2da.sum$quest=="Morality",],aes(y=mean,x=outcome,fill=knowledge)) +
                  facet_grid(~norm) +
                  geom_bar(position = "dodge",stat="identity") +
                  geom_errorbar(aes(ymin= mean - se, ymax = mean + se),width=0.2,position=position_dodge(.9)) +
                  ylab("Not Immoral (1) ~ Immoral (7)") +
                  xlab("") +
                  ggtitle("Moral Question") +
                  scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
                  coord_cartesian(ylim=c(1,7)) +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,plot.title=element_text(hjust=.5)
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    #,legend.position = c(.9,.85)
                    #,legend.position = "null"
                    ,legend.title=element_text(size=rel(1))
                    ,legend.text=element_text(size=rel(1))
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                  )
    #move morality plot under morality writing?

d2d.fig.r <- ggplot(d2da.sum[d2da.sum$quest=="Rationality",],aes(y=mean,x=outcome,fill=knowledge)) +
                  facet_grid(~norm) +
                  geom_bar(position = "dodge",stat="identity") +
                  geom_errorbar(aes(ymin= mean - se, ymax = mean + se),width=0.2,position=position_dodge(.9)) +
                  ylab("Not Irrational (1) ~ Irrational (7)") +
                  xlab("") +
                  ggtitle("Rational Question") +
                  scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
                  coord_cartesian(ylim=c(1,7)) +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,plot.title=element_text(hjust=.5)
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    #,legend.position = c(.9,.85)
                    #,legend.position = "null"  
                    ,legend.title=element_text(size=rel(1))
                    ,legend.text=element_text(size=rel(1))
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                  )


grid.arrange(d2d.fig.m, d2d.fig.r, nrow=2,heights = c(100,100))
#plot_grid(d2d.fig.m, d2d.fig.r, align = "v", nrow = 2)
```

```{r combinedAnalyses, echo=FALSE, warning=FALSE, message=FALSE}

d2da.sums <- d2da %>% group_by(knowledge,norm,outcome,vign,quest) %>% 
                      summarise(N = length(value),
                                mean = mean(value, na.rm=TRUE),
                                sd = sd(value,na.rm=TRUE),
                                se = sd / sqrt(N))

## attach the ratings
d2.r <-left_join(d2.sums,d2da.sums[d2da.sums$quest=="Morality",-5],by=c("knowledge","norm","outcome","vign"))

d2.r <-left_join(d2.r,d2da.sums[d2da.sums$quest=="Rationality",-5],by=c("knowledge","norm","outcome","vign"))

colnames(d2.r) <- c("knowledge","norm","outcome","vign",
                    "cause.n","cause.mean","cause.sd","cause.se",
                    "moral.n","moral.mean","moral.sd","moral.se",
                    "rational.n","rational.mean","rational.sd","rational.se")

d2dc <- read.csv("../data/irrationalityCounterfactuals.csv")

colnames(d2dc) <- c("subj","condCode","cf","norm","outcome","knowledge","vign")
  
d2dc$norm <- factor(d2dc$norm)
d2dc$norm <- factor(c("Moral Norm","Rational Norm")[d2dc$norm])

d2dc$outcome <- factor(d2dc$outcome)
d2dc$outcome <- factor(c("Bad Outcome","Good Outcome")[d2dc$outcome])

d2dc.sums <- d2dc %>% group_by(knowledge,norm,outcome,vign) %>% 
                      summarise(cf.n = length(cf),
                                cf.mean = mean(cf, na.rm=TRUE),
                                cf.sd = sd(cf,na.rm=TRUE),
                                cf.se = cf.sd / sqrt(cf.n))

d2.r <- left_join(d2.r,d2dc.sums,by=c("knowledge","norm","outcome","vign"))

d2.r$cf.meanS <- scale(d2.r$cf.mean)
d2.r$cause.meanS <- scale(d2.r$cause.mean) 

d2d.sums1 <- d2.r %>% group_by(knowledge,norm,outcome) %>%
                      summarise(moral.Mean = mean(moral.mean),
                                rational.Mean = mean(rational.mean),
                                cf.Mean = mean(cf.mean))
# 
# 
# d2d.lm_m <- summary(aov(moral.mean ~ knowledge*norm*outcome + Error(vign/ (knowledge*norm*outcome)), data=d2.r))
# d2d.lm_r <- summary(aov(rational.mean ~ knowledge*norm*outcome + Error(vign/ (knowledge*norm*outcome)), data=d2.r))
# 
# d2d.lm_cf <- summary(aov(cause.meanS ~ cf.meanS + knowledge*norm*outcome + Error(vign/(cf.mean + knowledge*norm*outcome)), data=d2.r)) 
#   
# anova(lm(cause.mean ~ cf.mean, data=d2.r))
```

```{r study2d cf, echo=FALSE, warning=FALSE, message=FALSE}
#reformat counterfactual choice in d2dc to 1) make it a factor and 2) change numbers to words (result is cf.re column)
d2dc <- d2dc %>%
  mutate(cf.re = case_when(cf==1 ~ "Agent",
            cf==2 ~ "External environment"),
         cf.re = factor(cf.re, levels=c("External environment", "Agent")))

d2dc$cf.re <- factor(d2dc$cf.re)

# 3-way Interaction:
# glmr2d_cf_3way.0 <- glmer(cf.re ~ knowledge * norm * outcome + (knowledge*norm*outcome|subj) + (1|vign), data=d2dc, family = "binomial")
# glmr2d_cf_3way.1 <- glmer(cf.re ~ (knowledge * norm) + (outcome * knowledge) + (outcome * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2dc, family = "binomial")
# glmr2d_cf_3way <- anova(glmr2d_cf_3way.0, glmr2d_cf_3way.1)
# saveRDS(glmr2d_cf_3way,"models/glmr2d_cf_3way.rds")
glmr2d_cf_3way <- readRDS("models/glmr2d_cf_3way.rds")                     

## knowledge x norm interaction
# glmr2d_cf_kn <- glmer(cf.re ~ (knowledge * outcome) + (outcome * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2dc, family = "binomial")
# glmr2d_cf_KxN <- anova(glmr2d_cf_3way.1, glmr2d_cf_kn)
# saveRDS(glmr2d_cf_KxN, "models/glmr2d_cf_KxN.rds")
glmr2d_cf_KxN <- readRDS("models/glmr2d_cf_KxN.rds")

## knowledge x outcome interaction
# glmr2d_cf_ko <- glmer(cf.re ~ (knowledge * norm) + (outcome * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2dc, family = "binomial")
# glmr2d_cf_KxO <- anova(glmr2d_cf_3way.1, glmr2d_cf_ko)
# saveRDS(glmr2d_cf_KxO, "models/glmr2d_cf_KxO.rds")
glmr2d_cf_KxO <- readRDS("models/glmr2d_cf_KxO.rds")
d2da.OxK.r <- d2da %>% filter(d2da$quest=="Rationality") %>%
                       group_by(knowledge,outcome,subj) %>% 
                       summarise(means=mean(value, na.rm = T)) 
###  knowledge x outcome interaction EMM
#em_2d_cf_KxO <- summary((emmeans(glmr2d_cf_3way.0, specs = pairwise ~ knowledge:outcome))$contrasts)
#saveRDS(em_2d_cf_KxO, "models/em_2d_cf_KxO.rds")
em_2d_cf_KxO <- readRDS("models/em_2d_cf_KxO.rds")
#emmeans(glmr2d_cf_3way.0, specs = pairwise ~ knowledge:outcome)
#emmip(glmr2d_cf_3way.0, knowledge~outcome)

## outcome x norm interaction
# glmr2d_cf_on <- glmer(cf.re ~ (knowledge * outcome) + (knowledge * norm) + (knowledge*norm*outcome|subj) + (1|vign), data=d2dc, family = "binomial")
# glmr2d_cf_OxN <- anova(glmr2d_cf_3way.1, glmr2d_cf_on)
# saveRDS(glmr2d_cf_OxN, "models/glmr2d_cf_OxN.rds")
glmr2d_cf_OxN <- readRDS("models/glmr2d_cf_OxN.rds")
```

### Counterfactual Question

We asked participants about the relevance of counterfactuals by examining their choice of the cause - the human agent or the external environment. Again, we asked whether there was a significant *Knowledge* $\times$ *Norm* $\times$ *Outcome* interaction effect but did not find one, $\chi^2(1)$ = `r round(glmr2d_cf_3way$Chisq[2],digits=3)`, *p* = `r max(.001,round(glmr2d_cf_3way$'Pr(>Chisq)'[2],digits=3))`. Using estimated marginal means, among the three possible 2-way interactions we only found an effect in *Knowledge* $\times$ *Outcome*, $\chi^2(1)$ = `r round(glmr2d_cf_KxO$Chisq[2],digits=3)`, *p* $<$ `r max(.001,round(glmr2d_cf_KxO$'Pr(>Chisq)'[2],digits=3))`, suggesting that participants' counterfactual choice tends to differentiate more between knowledgeable agent and ignorant agent when the event resulted in a bad outcome, *z-ratio* $=$ `r round(em_2d_cf_KxO[1,5],digits=3)`, *p* $<$`r round(em_2d_cf_KxO[1,6],digits=3)`, than in a good outcome, *z-ratio* $=$ `r round(em_2d_cf_KxO[6,5],digits=3)`, *p* $<$ `r round(em_2d_cf_KxO[6,6],digits=3)`.

```{r, d2dFig, fig.width=8.5, echo=FALSE, message=FALSE, warning=FALSE}


#plots

d2dc_counterfactual.plot.bo <- ggplot(d2dc[d2dc$outcome=="Bad Outcome",], aes(x=knowledge, fill=cf.re)) +
  geom_bar(position="stack") + 
  geom_text(aes(label = ..count..), stat = "count", hjust=1, size=3, position = position_stack(vjust = .5)) +
  ggtitle("Counterfactual choice in cases of bad outcome") + 
  ylab("Counterfactual choice") +
  facet_grid(~norm) +
  xlab("") +
  scale_fill_manual("Counterfactual choice:", values=wes_palette("Royal2",2)) + 
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.background = element_blank()
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    #,legend.position = c(.1,.9)
    ,legend.title=element_text(size=rel(1))
    ,legend.text=element_text(size=rel(1))
    ,axis.text.y=element_text(size=rel(1))
    ,axis.text.x=element_text(size=rel(1))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1))
  )

d2dc_counterfactual.plot.go <- ggplot(d2dc[d2dc$outcome=="Good Outcome",], aes(x=knowledge, fill=cf.re)) +
  geom_bar(position="stack") + 
  geom_text(aes(label = ..count..), stat = "count", hjust=1, size=3, position = position_stack(vjust = .5)) +
  ggtitle("Counterfactual choice in cases of good outcome") + 
  ylab("Counterfactual choice") +
  facet_grid(~norm) +
  xlab("") +
  scale_fill_manual("Counterfactual choice:", values=wes_palette("Royal2",2)) + 
  theme_bw() +
  theme(
    plot.title = element_text(hjust = 0.5),
    plot.background = element_blank()
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    #,legend.position = c(.1,.9)
    ,legend.title=element_text(size=rel(1))
    ,legend.text=element_text(size=rel(1))
    ,axis.text.y=element_text(size=rel(1))
    ,axis.text.x=element_text(size=rel(1))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1))
  )

print(d2dc_counterfactual.plot.bo)
print(d2dc_counterfactual.plot.go)

```

```{r study2d correlation and mediation, echo=FALSE, message=FALSE, warning=FALSE}
#for correlation analysis and plotting, recoded cf rating [(1/2) to (1/0), 0=environment 1= agent].
d2dc.cor <- d2dc
d2dc.cor$cf <- ifelse(d2dc.cor$cf == 2, 0, 1)

d2dc.cor <- d2dc.cor %>%
  dplyr::select(cf, norm, outcome, knowledge, vign) %>%
  group_by(norm, outcome, knowledge, vign) %>%
  summarise(cfM = mean(as.numeric(cf),na.rm=TRUE),
            cfN = length(cf),
            cfSD = sd(as.numeric(cf),na.rm=TRUE),
            cfSE =  cfSD / sqrt(cfN))

#join cf ratings with causal ratings from 2a~2c
d2d.cor <- inner_join(d2dc.cor, d2.sums, by=c("norm", "knowledge", "outcome", "vign"))
#cor.test(d2d.cor$cfM, d2d.cor$mean.cause)
#plot(d2d.cor$cfM, d2d.cor$mean.cause)

##won't need participant level because data come from two studies
# correlation at the level of scenario
d2d.corVign <- cor.test(d2d.cor$mean.cause,d2d.cor$cfM)
```

#### Relationship between counterfactual and causal judgments

We considered the relationship between causal judgments and counterfactual choices, using data from the current study and Studies 2a-2c. We found that they were highly correlated at the level of different scenarios, $r(`r d2d.corVign$parameter[[1]]`)$ =`r round(d2d.corVign\$estimate[[1]], digits=2)`,  *p* $<$`r max(.001,round(d2d.corVign\$p.value, digits=3))\`(see *Figure* [??]).

```{r fig.width=8.5, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Depiction of the relationship between participants' causal and counterfactual judgments for each of the scenarios."}
#"Shape depicts the valence of the outcome; color indicates the kind of agent involved in the distal event; and the number indicates the which of the 16 vignettes the judgments were about."

# d2d_cor.plot<- ggplot(d2d.cor, aes(y=mean.cause, x=cfM,color=factor(outcome, levels = c("Good Outcome", "Bad Outcome")), shape=factor(outcome, levels = c("Good Outcome", "Bad Outcome")))) +
#                   geom_smooth(method=lm, formula = y ~ x) +
#                   geom_point(aes(color=factor(outcome, levels = c("Good Outcome", "Bad Outcome")), shape=factor(outcome, levels = c("Good Outcome", "Bad Outcome"))), size=2) +
#                   geom_text(aes(label=vign), size=1.5,color="black") +
#                   facet_grid(norm~knowledge) + 
#                   xlab("Average Counterfactual Prefence: 0 = External environment, 1 = agent") +
#                   ylab("Average Causal Judgment per Scenario") +
#                   scale_color_manual("Outcome", values=wes_palette("Royal1",2)) + 
#                   scale_shape_manual("Outcome", values=c(16, 17)) +
#                   #labs(color="Outcome", shape="Outcome") +
#                   theme_bw() +
#                   theme(
#                     plot.background = element_blank()
#                     ,panel.grid.major = element_blank()
#                     ,panel.grid.minor = element_blank()
#                     ,legend.text=element_text(size=rel(1))
#                     #,legend.position=c(.9,.25)
#                     ,axis.text.y=element_text(size=rel(1))
#                     ,axis.text.x=element_text(size=rel(1))
#                     ,axis.title.y=element_text(vjust=.9)
#                     ,axis.ticks = element_blank()
#                     ,axis.title=element_text(size=rel(1))
#                     ,strip.text=element_text(size=rel(.9))
#                   )
# d2d_cor.plot

#simple version of cf and causal plot
d2d_cor.plot <- ggplot(d2d.cor, aes(y=mean.cause, x=cfM)) +
                  geom_smooth(method=lm, formula = y ~ x) +
                  geom_point(size=2) +
                  geom_text(aes(label=vign), size=1.5,color="black") +
                  xlab("Average Counterfactual Prefence for the Agent per Condition") +
                  ylab("Average Causal Judgment per Scenario") +
                  scale_color_manual("Outcome", values=wes_palette("Royal1",2)) + 
                  scale_shape_manual("Outcome", values=c(16, 17)) +
                  #labs(color="Outcome", shape="Outcome") +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    ,legend.text=element_text(size=rel(1))
                    #,legend.position=c(.9,.25)
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                    ,strip.text=element_text(size=rel(.9))
                  )
d2d_cor.plot
#cor.test(d2d.cor$cfM, d2d.cor$mean.cause)
```

```{r, fig.width=8.5, echo=FALSE, warning=FALSE, message=FALSE}
d2da.m <- d2da %>%
  subset(quest == "Morality") %>%
  dplyr::select(value, norm, outcome, knowledge, vign) %>%
  group_by(knowledge,norm,outcome,vign) %>% 
                      summarise(N = length(value),
                                mean = mean(value, na.rm=TRUE),
                                sd = sd(value,na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(moralityN = N) %>%
  rename(moralityMean = mean) %>%
  rename(moralitySD = sd) %>%
  rename(moralitySE = se)

d2da.r <- d2da %>%
  subset(quest == "Rationality") %>%
  dplyr::select(value, norm, outcome, knowledge, vign) %>%
  group_by(knowledge,norm,outcome,vign) %>% 
                      summarise(N = length(value),
                                mean = mean(value, na.rm=TRUE),
                                sd = sd(value,na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(rationalityN = N) %>%
  rename(rationalityMean = mean) %>%
  rename(rationalitySD = sd) %>%
  rename(rationalitySE = se)

d2d.cor.cf <- d2d.cor %>%
  select(outcome, knowledge, norm, vign, cfM, cfN, cfSD, cfSE)

d2d.cf.m <- inner_join(d2d.cor.cf, d2da.m, by=c("norm", "knowledge", "outcome", "vign"))
d2d.cf.r <- inner_join(d2d.cor.cf, d2da.r, by=c("norm", "knowledge", "outcome", "vign"))


#Cf & Morality correlation:
d2d.cf.m.cor <- cor.test(d2d.cf.m$cfM, d2d.cf.m$moralityMean)

#Cf & Rationality correlation: 
d2d.cf.r.cor <- cor.test(d2d.cf.r$cfM, d2d.cf.r$rationalityMean) 


#Cf & Normality correlation: 
#average morality / rationality rating for each condition within scenario
d2da.normality <- d2da %>%
  dplyr::select(quest, value, norm, outcome, knowledge, vign) %>%
  group_by(knowledge,norm,outcome,vign) %>%
                      summarise(N = length(value),
                                mean = mean(value, na.rm=TRUE),
                                sd = sd(value,na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(noramalityN = N) %>%
  rename(normalityMean = mean) %>%
  rename(normalitySD = sd) 

d2d.cf.normality <- inner_join(d2d.cor.cf, d2da.normality, by=c("norm", "knowledge", "outcome", "vign"))

d2d.cf.normality.cor <- cor.test(d2d.cf.normality$cfM, d2d.cf.normality$normalityMean)

```

#### Relationship between counterfactual judgment and morality/rationality rating

We also considered the relationships between counterfactual choices and morality rating, rationality rating and normality rating, using data from the current study. Normality rating is constructed by averaging morality and rationality rating. We found that counterfactual choice is correlated with all three types of ratings at the level of different scenarios (see *Figure* [??]): morality rating, $r(`r d2d.cf.m.cor$parameter[[1]]`)$ =`r round(d2d.cf.m.cor\$estimate[[1]], digits=2)`,  *p* $<$`r max(.001,round(d2d.cf.m.cor\$p.value, digits=3))`, rationality rating, $r(`r d2d.cf.r.cor$parameter[[1]]`)$ = `r round(d2d.cf.r.cor$estimate[[1]], digits=2)`, *p* $<$ `r max(.001,round(d2d.cf.r.cor$p.value, digits=3))`, and normality rating, $r(`r d2d.cf.normality.cor$parameter[[1]]`)$ =`r round(d2d.cf.normality.cor\$estimate[[1]], digits=2)`,  *p* $<$`r max(.001,round(d2d.cf.normality.cor\$p.value, digits=3))\`.

```{r, fig.width=8.5, echo=FALSE, warning=FALSE, message=FALSE, fig.cap="Depiction of the relationship between participants' counterfactual judgments and morality/rationality/normality for each of the scenarios."}
#Cf & Morality correlation:
ggplot(d2d.cf.m, aes(y=moralityMean, x=cfM)) +
                  geom_smooth(method=lm, formula = y ~ x) +
                  geom_point(size=2) +
                  geom_text(aes(label=vign), size=1.5,color="black") +
                  xlab("Average Counterfactual Prefence for the Agent per Condition") +
                  ylab("Average Morality Rating per Scenario") +
                  scale_color_manual("Outcome", values=wes_palette("Royal1",2)) + 
                  scale_shape_manual("Outcome", values=c(16, 17)) +
                  #labs(color="Outcome", shape="Outcome") +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    ,legend.text=element_text(size=rel(1))
                    #,legend.position=c(.9,.25)
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                    ,strip.text=element_text(size=rel(.9))
                  )


#Cf & Rationality correlation: 
ggplot(d2d.cf.r, aes(y=rationalityMean, x=cfM)) +
                  geom_smooth(method=lm, formula = y ~ x) +
                  geom_point(size=2) +
                  geom_text(aes(label=vign), size=1.5,color="black") +
                  xlab("Average Counterfactual Prefence for the Agent per Condition") +
                  ylab("Average Rationality Rating per Scenario") +
                  scale_color_manual("Outcome", values=wes_palette("Royal1",2)) + 
                  scale_shape_manual("Outcome", values=c(16, 17)) +
                  #labs(color="Outcome", shape="Outcome") +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    ,legend.text=element_text(size=rel(1))
                    #,legend.position=c(.9,.25)
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                    ,strip.text=element_text(size=rel(.9))
                  )


#Cf & Normality correlation: 
#average morality / rationality rating for each condition within scenario
# d2da.normality <- d2da %>%
#   dplyr::select(quest, value, norm, outcome, knowledge, vign) %>%
#   group_by(knowledge,norm,outcome,vign) %>%
#                       summarise(N = length(value),
#                                 mean = mean(value, na.rm=TRUE),
#                                 sd = sd(value,na.rm=TRUE),
#                                 se = sd / sqrt(N)) %>%
#   dplyr::rename(noramalityN = N) %>%
#   rename(normalityMean = mean) %>%
#   rename(normalitySD = sd) 

# d2d.cf.normality <- inner_join(d2d.cor.cf, d2da.normality, by=c("norm", "knowledge", "outcome", "vign"))

ggplot(d2d.cf.normality, aes(y=normalityMean, x=cfM)) +
                  geom_smooth(method=lm, formula = y ~ x) +
                  geom_point(size=2) +
                  geom_text(aes(label=vign), size=1.5,color="black") +
                  xlab("Average Counterfactual Prefence for the Agent per Condition") +
                  ylab("Average Normality Rating per Scenario") +
                  scale_color_manual("Outcome", values=wes_palette("Royal1",2)) + 
                  scale_shape_manual("Outcome", values=c(16, 17)) +
                  #labs(color="Outcome", shape="Outcome") +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    ,legend.text=element_text(size=rel(1))
                    #,legend.position=c(.9,.25)
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                    ,strip.text=element_text(size=rel(.9))
                  )
#d2d.cf.normality.cor <- cor.test(d2d.cf.normality$cfM, d2d.cf.normality$normalityMean)

```

# Experiment 3

# Experiment 3a: Causal judgments in normal and abnormal outcomes

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study.

```{r study3a participants&demo, echo=FALSE, warning=FALSE, message=FALSE}
d3.cs <- read.csv("../data/probnor_Causation_num.csv")
d3.cs <- d3.cs[-c(1:2), ]

# ProbNor Causation demo (age, gender, education, ethnicity, ses):
d3.cs_demo <- read.csv("../data/probnor_Causation_txt.csv")
d3.cs_demo <- d3.cs_demo[-(1:2),] %>%
  select(c("age", "edu", "gender", "ethn", "ses"))
d3.cs_demo$gender <- as.factor(d3.cs_demo$gender)
d3.cs_demo$edu <- as.factor(d3.cs_demo$edu)
d3.cs_demo$ethn <- as.factor(d3.cs_demo$ethn)
d3.cs_demo$ses <- as.factor(d3.cs_demo$ses)
######d2da.age <- matrix(c("mean",mean(d2da_demo$age,na.rm=T),"sd",sd(d2da_demo$age,na.rm=T),"n",length(d2da_demo$age)),ncol = 3)
```

### Participants

For ratings of causation for outcomes that were categorized as normal versus abnormal, `r length(d3.cs_demo$age)` participants were recruited (*M*~age~=`r round(mean(as.numeric(d3.cs_demo$age), na.rm=T),digits=2)`, *SD*~age~=`r round(sd(as.numeric(d3.cs_demo$age), na.rm=T),digits=2)`; `r length(which(d3.cs_demo$gender=="Female"))` females), among which `r sum(!is.na(d3.cs_demo$age))` answered all our demographic questions.\
All participants were recruited through Amazon Mechanical Turk (<http://www.mturk.com>).

```{r study3a dataset, echo=FALSE, warning=FALSE, message=FALSE}
# ProbNor Causation cleaning
# d3.cspb <- d3.cs[,grepl("caus|ResponseId", colnames(d3.cs))] %>%
#   pivot_longer(col=2:129, names_to = "condition", values_to = "causation response", values_drop_na = T) %>%
#   filter(`causation response` != "") %>%
#   mutate(norm = case_when(str_detect(condition, "R") ~ "Rationality",
#                           str_detect(condition, "M") ~ "Morality")) %>%
#   mutate(knowledge = case_when(str_detect(condition, "K") ~ "Knowledge",
#                           str_detect(condition, "I") ~ "Ignorance")) %>%
#   mutate(outcome = case_when(str_detect(condition, "B") ~ "Abnormal",
#                           str_detect(condition, "G") ~ "Normal")) %>%
#   mutate(scenario = case_when(str_detect(condition, "\\bcaus10.\\b") ~ 10,
#                               str_detect(condition, "\\bcaus11.\\b") ~ 11,
#                               str_detect(condition, "\\bcaus12.\\b") ~ 12,
#                               str_detect(condition, "\\bcaus13.\\b") ~ 13,
#                               str_detect(condition, "\\bcaus14.\\b") ~ 14,
#                               str_detect(condition, "\\bcaus15.\\b") ~ 15,
#                               str_detect(condition, "\\bcaus16.\\b") ~ 16,
#                               str_detect(condition, "\\bcaus1.\\b") ~ 1,
#                               str_detect(condition, "\\bcaus2.\\b") ~ 2,
#                               str_detect(condition, "\\bcaus3.\\b") ~ 3,
#                               str_detect(condition, "\\bcaus4.\\b") ~ 4,
#                               str_detect(condition, "\\bcaus5.\\b") ~ 5,
#                               str_detect(condition, "\\bcaus6.\\b") ~ 6,
#                               str_detect(condition, "\\bcaus7.\\b") ~ 7,
#                               str_detect(condition, "\\bcaus8.\\b") ~ 8,
#                               str_detect(condition, "\\bcaus9.\\b") ~ 9,
#                               )) %>%
#   dplyr::rename(condCod = condition) %>%
#   mutate(condition = case_when(str_detect(condCod, "MKB") ~ "MKB",
#                                str_detect(condCod, "MKG") ~ "MKG",
#                                str_detect(condCod, "MIB") ~ "MIB",
#                                str_detect(condCod, "MIG") ~ "MIG",
#                                str_detect(condCod, "RKB") ~ "RKB",
#                                str_detect(condCod, "RKG") ~ "RKG",
#                                str_detect(condCod, "RIB") ~ "RIB",
#                                str_detect(condCod, "RIG") ~ "RIG"))
# write.csv(d3.cspb, "../data/d3cspb.csv", row.names = FALSE)
d3.cspb <- read.csv("../data/d3cspb.csv")
```

### Materials

In this experiment, participants completed 16 trials which each involved reading a vignette where an agent's action resulted in an outcome that was normal or abnormal (defined by probability of occurrence). The action would have violated a moral or a rational norm. In addition, the agent was either ignorant or knowledgeable about the norm violated. The study used a 2 (Norm Type) $\times$ 2 (Agent Knowledge) $\times$ 2 (Outcome Probability) $\times$ 16 (Scenario) design that was administered in a mixed within- and between-subjects fashion, such that participants saw all 16 scenarios and on each trial were randomly assigned to read 1 of the 8 different versions of that scenario.

For instance, participants may read a vignette as follows:

> **Rational Norm / Knowledgeable Agent / Abnormal Outcome** : The owner of a construction company, who was hired to remodel a skyscraper, decided to use a new material called Plyvex to cover the inner walls of the building. When the building inspector reviewed the plans, she realized that Plyvex was one of the least efficient choices for this project. She told the owner of the construction company about this. Although the owner of the construction company understood this, he decided to use Plyvex anyway, like he originally planned. It turns out that Plyvex creates a scent that smells almost exactly like ripe kiwis. Because of this, a number of people in the company noticed that the entire building smelled of kiwis after the Plyvex had been installed.

### Procedure

After reading the brief vignette, participants rated their agreement with a statement about the agent causing the outcome, as in the following example:

> *Causal Question*: The owner of the construction company caused the entire building to smell of kiwis.

Participants answered the question on a 7-point Likert scale from 1 ('Completely disagree') to 7 ('Completely agree'), with a midpoint of 4 ('In between').

Participants were asked to complete a brief demographic questionnaire after completing all 16 trials.

```{r study3a analyses, echo=FALSE, warning=FALSE, message=FALSE}
## ProbNor Causation
###cspb main effects (only knowledge significant)
  # lmr3cspb.main <- lmer(causation.response ~ knowledge + outcome + norm +  (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.cspb)
  # 
  # lmr3cspb.outcome <- lmer(causation.response ~ knowledge + norm + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.cspb)
  # lmr3cspb.outcome <- anova(lmr3cspb.main,lmr3cspb.outcome)
  # saveRDS(lmr3cspb.outcome,"models/lmr3cspb.outcome.rds")
lmr3cspb.outcome <- readRDS("models/lmr3cspb.outcome.rds")

  # lmr3cspb.norm <- lmer(causation.response ~ knowledge + outcome + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.cspb)
  # lmr3cspb.norm <- anova(lmr3cspb.main,lmr3cspb.norm)
  # saveRDS(lmr3cspb.norm,"models/lmr3cspb.norm.rds")
lmr3cspb.norm <- readRDS("models/lmr3cspb.norm.rds")

  # lmr3cspb.knowledge <- lmer(causation.response ~ outcome + norm + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.cspb)
  # lmr3cspb.knowledge <- anova(lmr3cspb.main,lmr3cspb.knowledge)
  # saveRDS(lmr3cspb.knowledge,"models/lmr3cspb.knowledge.rds")
lmr3cspb.knowledge <- readRDS("models/lmr3cspb.knowledge.rds")
d3a.sumK <- d3.cspb %>% 
  select(knowledge,causation.response,ResponseId) %>%
  group_by(knowledge,ResponseId) %>%
  summarise(CauseM = mean(causation.response),na.rm=TRUE) %>%
  group_by(knowledge) %>%
  summarise(N = length(CauseM),
           mean = mean(CauseM, na.rm=TRUE),
           sd = sd(CauseM,na.rm=TRUE),
           se = sd / sqrt(N))


###cspb interactions

  ## cspb three-way interaction (insignificant)
# lmr3cspb.i0 <- lmer(causation.response ~ knowledge * norm * outcome + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.cspb)
# lmr3cspb.i1 <- lmer(causation.response ~ (knowledge * norm) + (outcome * knowledge) + (outcome * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.cspb)
# lmr3cspb.3way <- anova(lmr3cspb.i0,lmr3cspb.i1)
# saveRDS(lmr3cspb.3way,"models/lmr3cspb.3way.rds")
lmr3cspb.3way <- readRDS("models/lmr3cspb.3way.rds")

  ## cspb two-way: Norm x Knowledge interaction (insignificant)
# lmr3cspb.NK <- lmer(causation.response ~ (knowledge * outcome) + (outcome * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.cspb)
# lmr3cspb.NxK <- anova(lmr3cspb.i1, lmr3cspb.NK)
# saveRDS(lmr3cspb.NxK,"models/lmr3cspb.NxK.rds")
lmr3cspb.NxK <- readRDS("models/lmr3cspb.NxK.rds")
    # d3.cspb %>% 
    # group_by(knowledge,norm,ResponseId) %>% 
    # summarise(means=mean(causation.response, na.rm = T)) 

  ## cspb two-way: Norm x Outcome interaction (insignificant)
# lmr3cspb.NO <- lmer(causation.response ~ (knowledge * outcome) + (knowledge * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.cspb)
# lmr3cspb.NxO <- anova(lmr3cspb.i1, lmr3cspb.NO)
# saveRDS(lmr3cspb.NxO,"models/lmr3cspb.NxO.rds")
lmr3cspb.NxO <- readRDS("models/lmr3cspb.NxO.rds")

  ## cspb two-way: Outcome x Knowledge interaction (insignificant)
# lmr3cspb.OK <- lmer(causation.response ~ (norm * outcome) + (knowledge * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.cspb)
# lmr3cspb.OxK <- anova(lmr3cspb.i1,lmr3cspb.OK)
# saveRDS(lmr3cspb.OxK,"models/lmr3cspb.OxK.rds")
lmr3cspb.OxK <- readRDS("models/lmr3cspb.OxK.rds")
```

### Data analysis

No participant was excluded from the analyses as long as the entire study was completed.

## Results

We analyzed participants' causal judgments, which revealed a main effect of whether the agent knew that the action would violate a norm, $\chi^2(2)$ = `r round(lmr3cspb.knowledge$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3cspb.knowledge$'Pr(>Chisq)'[2],digits=3))`, such that ignorant agents were overall seen as less causal (*M* = `r round(d3a.sumK$mean[d3a.sumK$knowledge=="Ignorance"],digits=2)`, *SD* = `r round(d3a.sumK$sd[d3a.sumK$knowledge=="Ignorance"],digits=2)`) than knowledgeable agents (*M* = `r round(d3a.sumK$mean[d3a.sumK$knowledge=="Knowledge"],digits=2)`, *SD* = `r round(d3a.sumK$sd[d3a.sumK$knowledge=="Knowledge"],digits=2)`). Importantly, we did not observe either a main effect of the kind of *Norm* that the agent has violated, $\chi^2(2)$ = `r round(lmr3cspb.norm$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3cspb.norm$'Pr(>Chisq)'[2]),digits=3)`, or a main effect of the probability of the outcome, $\chi^2(2)$ = `r round(lmr3cspb.outcome$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3cspb.outcome$'Pr(>Chisq)'[2]),digits=3)`. We also probed interaction effects but none of them was significant, including the three-way *Knowledge* $\times$ *Norm* $\times$ *Outcome* interaction, $\chi^2(2)$ = `r round(lmr3cspb.3way$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3cspb.3way$'Pr(>Chisq)'[2],digits=3))`, and the three two-way interactions of *Knowledge* $\times$ *Norm*, $\chi^2(2)$ = `r round(lmr3cspb.NxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3cspb.NxK$'Pr(>Chisq)'[2],digits=3))`, *Knowledge* $\times$ *Outcome*, $\chi^2(2)$ = `r round(lmr3cspb.OxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3cspb.OxK$'Pr(>Chisq)'[2],digits=3))`, and *Outcome* $\times$ *Norm*, $\chi^2(2)$ = `r round(lmr3cspb.NxO$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3cspb.NxO$'Pr(>Chisq)'[2],digits=3))`, suggesting that participants' causal judgments did not differentiate much across conditions.

```{r study3a plots, echo=FALSE, warning=FALSE, message=FALSE}

### ProbNor Causation plots
d3.cspb.sum <- d3.cspb %>%
  dplyr::select(`causation.response`, norm, outcome, knowledge) %>%
  group_by(knowledge,norm,outcome) %>% 
                      summarise(N = length(`causation.response`),
                                mean = mean(as.numeric(`causation.response`), na.rm=TRUE),
                                sd = sd(as.numeric(`causation.response`),na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(causationN = N) %>%
  rename(causationMean = mean) %>%
  rename(causationSD = sd) %>%
  rename(causationSE = se)

d3cs.fig <- ggplot(d3.cspb.sum,aes(y=causationMean,x=outcome,fill=knowledge)) +
                  facet_grid(~norm) +
                  geom_bar(position = "dodge",stat="identity") +
                  geom_errorbar(aes(ymin= causationMean - causationSE, ymax = causationMean + causationSE),width=0.2,position=position_dodge(.9)) +
                  ylab("Completely disagree with causation (1) ~ Completely agree with causation (7)") +
                  xlab("Outcome type") +
                  ggtitle("Causation ratings in abnormal or normal outcomes") +
                  scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
                  coord_cartesian(ylim=c(1,7)) +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,plot.title=element_text(hjust=.5)
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    #,legend.position = c(.9,.85)
                    #,legend.position = "null"
                    ,legend.title=element_text(size=rel(1))
                    ,legend.text=element_text(size=rel(1))
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                  )
d3cs.fig
```

# Experiment 3b: Valence and normality judgments in normal and abnormal outcomes

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study.

```{r study3b participants&demo, echo=FALSE, warning=FALSE, message=FALSE}
d3.oc.pb <- read.csv("../data/probnor_ValenceNormality_num.csv")
d3.oc.pb <- d3.oc.pb[-c(1:2), ]

# ProbNor ValeNorm demo (age, gender, education, ethnicity, ses): 
d3.oc.pb_demo <- read.csv("../data/probnor_ValenceNormality_txt.csv")
d3.oc.pb_demo <- d3.oc.pb_demo[-(1:2),] %>%
  select(c("age", "edu", "gender", "ethn", "ses"))
d3.oc.pb_demo$gender <- as.factor(d3.oc.pb_demo$gender)
d3.oc.pb_demo$edu <- as.factor(d3.oc.pb_demo$edu)
d3.oc.pb_demo$ethn <- as.factor(d3.oc.pb_demo$ethn)
d3.oc.pb_demo$ses <- as.factor(d3.oc.pb_demo$ses)
```

### Participants

For ratings of normality and valence for outcomes that were categorized as normal versus abnormal, `r length(d3.oc.pb_demo$age)` participants were recruited (*M*~age~=`r round(mean(as.numeric(d3.oc.pb_demo$age), na.rm=T),digits=2)`, *SD*~age~=`r round(sd(as.numeric(d3.oc.pb_demo$age), na.rm=T),digits=2)`; `r length(which(d3.oc.pb_demo$gender=="Female"))` females), among which `r sum(!is.na(d3.oc.pb_demo$age))` answered all our demographic questions.\
All participants were recruited through Amazon Mechanical Turk (<http://www.mturk.com>).

```{r study3b dataset, echo=FALSE, warning=FALSE, message=FALSE}
# ProbNor ValeNorm cleaning
# d3.ocpb <- d3.oc.pb[,grepl("vale|norm|ResponseId", colnames(d3.oc.pb))] %>%
#   pivot_longer(col=2:257, names_to = "condition", values_to = "responses", values_drop_na = T) %>%
#   filter(`responses` != "") %>%
#   mutate(question = case_when(str_detect(condition, "vale") ~ "Valence",
#                               str_detect(condition, "norm") ~ "Normality"))%>%
#   mutate(norm = case_when(str_detect(condition, "R") ~ "Rationality",
#                           str_detect(condition, "M") ~ "Morality")) %>%
#   mutate(knowledge = case_when(str_detect(condition, "K") ~ "Knowledge",
#                           str_detect(condition, "I") ~ "Ignorance")) %>%
#   mutate(outcome = case_when(str_detect(condition, "B") ~ "Abnormal",
#                           str_detect(condition, "G") ~ "Normal")) %>%
#   mutate(scenario = case_when(str_detect(condition, "\\bvale10.\\b|\\bnorm10.\\b") ~ 10,
#                               str_detect(condition, "\\bvale11.\\b|\\bnorm11.\\b") ~ 11,
#                               str_detect(condition, "\\bvale12.\\b|\\bnorm12.\\b") ~ 12,
#                               str_detect(condition, "\\bvale13.\\b|\\bnorm13.\\b") ~ 13,
#                               str_detect(condition, "\\bvale14.\\b|\\bnorm14.\\b") ~ 14,
#                               str_detect(condition, "\\bvale15.\\b|\\bnorm15.\\b") ~ 15,
#                               str_detect(condition, "\\bvale16.\\b|\\bnorm16.\\b") ~ 16,
#                               str_detect(condition, "\\bvale1.\\b|\\bnorm1.\\b") ~ 1,
#                               str_detect(condition, "\\bvale2.\\b|\\bnorm2.\\b") ~ 2,
#                               str_detect(condition, "\\bvale3.\\b|\\bnorm3.\\b") ~ 3,
#                               str_detect(condition, "\\bvale4.\\b|\\bnorm4.\\b") ~ 4,
#                               str_detect(condition, "\\bvale5.\\b|\\bnorm5.\\b") ~ 5,
#                               str_detect(condition, "\\bvale6.\\b|\\bnorm6.\\b") ~ 6,
#                               str_detect(condition, "\\bvale7.\\b|\\bnorm7.\\b") ~ 7,
#                               str_detect(condition, "\\bvale8.\\b|\\bnorm8.\\b") ~ 8,
#                               str_detect(condition, "\\bvale9.\\b|\\bnorm9.\\b") ~ 9
#                               )) %>%
#   dplyr::rename(condCod = condition) %>%
#   mutate(condition = case_when(str_detect(condCod, "MKB") ~ "MKB",
#                                str_detect(condCod, "MKG") ~ "MKG",
#                                str_detect(condCod, "MIB") ~ "MIB",
#                                str_detect(condCod, "MIG") ~ "MIG",
#                                str_detect(condCod, "RKB") ~ "RKB",
#                                str_detect(condCod, "RKG") ~ "RKG",
#                                str_detect(condCod, "RIB") ~ "RIB",
#                                str_detect(condCod, "RIG") ~ "RIG"))
# write.csv(d3.ocpb, "../data/d3ocpb.csv", row.names = FALSE)
d3.ocpb <- read.csv("../data/d3ocpb.csv")

```

### Materials

In this experiment, participants completed 16 trials which each involved reading a vignette where an agent's action resulted in an outcome that was normal or abnormal (defined by probability of occurrence). The action would have violated a moral or a rational norm. In addition, the agent was either ignorant or knowledgeable about the norm violated. As in Study 3a, the study used a 2 (Norm Type) $\times$ 2 (Agent Knowledge) $\times$ 2 (Outcome Probability) $\times$ 16 (Scenario) design that was administered in a mixed within- and between-subjects fashion, such that participants saw all 16 scenarios and on each trial were randomly assigned to read 1 of the 8 different versions of that scenario.

For instance, participants may read a vignette as follows:

> **Rational Norm / Knowledgeable Agent / Abnormal Outcome** : The owner of a construction company, who was hired to remodel a skyscraper, decided to use a new material called Plyvex to cover the inner walls of the building. When the building inspector reviewed the plans, she realized that Plyvex was one of the least efficient choices for this project. She told the owner of the construction company about this. Although the owner of the construction company understood this, he decided to use Plyvex anyway, like he originally planned. It turns out that Plyvex creates a scent that smells almost exactly like ripe kiwis. Because of this, a number of people in the company noticed that the entire building smelled of kiwis after the Plyvex had been installed.

### Procedure

After reading the brief vignette, participants rated the extent to which they thought the outcome was good or bad and the extent to which they thought the outcome was normal or abnormal.

> *Valence Question*: After the plyvex was installed, the entire building smelled of kiwis. Do you think this was a good or bad thing to have happened?

> *Normality Question*: After the plyvex was installed, the entire building smelled of kiwis. Do you think it was a normal or abnormal thing to have happened?

Participants answered the question on a 7-point Likert scale from 1 ('Completely bad' or 'Completely abnormal') to 7 ('Completely good' or 'Completely normal'), with a midpoint of 4 ('In between').

Participants were asked to complete a brief demographic questionnaire after completing all 16 trials.

```{r study3b analyses, echo=FALSE, warning=FALSE, message=FALSE}

## ProbNor ValeNorm

###ocpb main effects (outcome significant, norm barely significant)
  # lmr3ocpb.main <- lmer(responses ~ knowledge + outcome + norm +  (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocpb)
  # 
  # lmr3ocpb.outcome <- lmer(responses ~ knowledge + norm + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocpb)
  # lmr3ocpb.outcome <- anova(lmr3ocpb.main,lmr3ocpb.outcome)
  # saveRDS(lmr3ocpb.outcome,"models/lmr3ocpb.outcome.rds")
lmr3ocpb.outcome <- readRDS("models/lmr3ocpb.outcome.rds")
d3b.sumO <- d3.ocpb %>% 
  select(outcome,responses,ResponseId) %>%
  group_by(outcome,ResponseId) %>%
  summarise(responseM = mean(responses),na.rm=TRUE) %>%
  group_by(outcome) %>%
  summarise(N = length(responseM),
           mean = mean(responseM, na.rm=TRUE),
           sd = sd(responseM,na.rm=TRUE),
           se = sd / sqrt(N))

  # lmr3ocpb.norm <- lmer(responses ~ knowledge + outcome + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocpb)
  # lmr3ocpb.norm <- anova(lmr3ocpb.main,lmr3ocpb.norm)
  # saveRDS(lmr3ocpb.norm,"models/lmr3ocpb.norm.rds")
lmr3ocpb.norm <- readRDS("models/lmr3ocpb.norm.rds")

  # lmr3ocpb.knowledge <- lmer(responses ~ outcome + norm + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocpb)
  # lmr3ocpb.knowledge <- anova(lmr3ocpb.main,lmr3ocpb.knowledge)
  # saveRDS(lmr3ocpb.knowledge,"models/lmr3ocpb.knowledge.rds")
lmr3ocpb.knowledge <- readRDS("models/lmr3ocpb.knowledge.rds")

###interaction

###ocpb interactions

  ## ocpb three-way interaction (insignificant)
# lmr3ocpb.i0 <- lmer(responses ~ knowledge * norm * outcome + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocpb)
# lmr3ocpb.i1 <- lmer(responses ~ (knowledge * norm) + (outcome * knowledge) + (outcome * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocpb)
# lmr3ocpb.3way <- anova(lmr3ocpb.i0,lmr3ocpb.i1)
# saveRDS(lmr3ocpb.3way,"models/lmr3ocpb.3way.rds")
lmr3ocpb.3way <- readRDS("models/lmr3ocpb.3way.rds")

  ## ocpb two-way: Norm x Knowledge interaction (insignificant)
# lmr3ocpb.NK <- lmer(responses ~ (knowledge * outcome) + (outcome * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocpb)
# lmr3ocpb.NxK <- anova(lmr3ocpb.i1, lmr3ocpb.NK)
# saveRDS(lmr3ocpb.NxK,"models/lmr3ocpb.NxK.rds")
lmr3ocpb.NxK <- readRDS("models/lmr3ocpb.NxK.rds")

  ## ocpb two-way: Norm x Outcome interaction (insignificant)
# lmr3ocpb.NO <- lmer(responses ~ (knowledge * outcome) + (knowledge * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocpb)
# lmr3ocpb.NxO <- anova(lmr3ocpb.i1, lmr3ocpb.NO)
# saveRDS(lmr3ocpb.NxO,"models/lmr3ocpb.NxO.rds")
lmr3ocpb.NxO <- readRDS("models/lmr3ocpb.NxO.rds")

  ## ocpb two-way: Outcome x Knowledge interaction (insignificant)
# lmr3ocpb.OK <- lmer(responses ~ (norm * outcome) + (knowledge * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocpb)
# lmr3ocpb.OxK <- anova(lmr3ocpb.i1,lmr3ocpb.OK)
# saveRDS(lmr3ocpb.OxK,"models/lmr3ocpb.OxK.rds")
lmr3ocpb.OxK <- readRDS("models/lmr3ocpb.OxK.rds")

```

### Data analysis

No participant was excluded from the analyses as long as the entire study was completed.

## Results

We analyzed participants' ratings, which revealed a main effect of the type of outcome, $\chi^2(2)$ = `r round(lmr3ocpb.outcome$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocpb.outcome$'Pr(>Chisq)'[2],digits=3))`, such that participants thought it was a less normal and less good thing to have happened when the outcome was abnormal (*M* = `r round(d3b.sumO$mean[d3b.sumO$outcome=="Abnormal"],digits=2)`, *SD* = `r round(d3b.sumO$sd[d3b.sumO$outcome=="Abnormal"],digits=2)`) than when it was normal (*M* = `r round(d3b.sumO$mean[d3b.sumO$outcome=="Normal"],digits=2)`, *SD* = `r round(d3b.sumO$sd[d3b.sumO$outcome=="Normal"],digits=2)`). We did not observe either a main effect of whether or not the agent had *Knowledge* about the outcome, $\chi^2(2)$ = `r round(lmr3ocpb.knowledge$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocpb.knowledge$'Pr(>Chisq)'[2]),digits=3)`, or a main effect of the type of the norm violated, $\chi^2(2)$ = `r round(lmr3ocpb.norm$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocpb.norm$'Pr(>Chisq)'[2]),digits=3)`. We also probed interaction effects but none of them was significant, including the three-way *Knowledge* $\times$ *Norm* $\times$ *Outcome* interaction, $\chi^2(2)$ = `r round(lmr3ocpb.3way$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocpb.3way$'Pr(>Chisq)'[2],digits=3))`, and the three two-way interactions of *Knowledge* $\times$ *Norm*, $\chi^2(2)$ = `r round(lmr3ocpb.NxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocpb.NxK$'Pr(>Chisq)'[2],digits=3))`, *Knowledge* $\times$ *Outcome*, $\chi^2(2)$ = `r round(lmr3ocpb.OxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocpb.OxK$'Pr(>Chisq)'[2],digits=3))`, and *Outcome* $\times$ *Norm*, $\chi^2(2)$ = `r round(lmr3ocpb.NxO$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocpb.NxO$'Pr(>Chisq)'[2],digits=3))`, suggesting that participants' valence and normality judgments did not differentiate much across conditions.

```{r study3b plots, echo=FALSE, warning=FALSE, message=FALSE}

### ProbNor ValeNorm plots
d3ocpb.normsum <- d3.ocpb[d3.ocpb$question=="Normality",] %>%
  dplyr::select(responses, norm, outcome, knowledge) %>%
  group_by(knowledge,norm,outcome) %>% 
                      summarise(N = length(responses),
                                mean = mean(as.numeric(responses), na.rm=TRUE),
                                sd = sd(as.numeric(responses),na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(normalityN = N) %>%
  rename(normalityMean = mean) %>%
  rename(normalitySD = sd) %>%
  rename(normalitySE = se)

d3ocpb.valesum <- d3.ocpb[d3.ocpb$question=="Valence",] %>%
  dplyr::select(responses, norm, outcome, knowledge) %>%
  group_by(knowledge,norm,outcome) %>% 
                      summarise(N = length(responses),
                                mean = mean(as.numeric(responses), na.rm=TRUE),
                                sd = sd(as.numeric(responses),na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(valenceN = N) %>%
  rename(valenceMean = mean) %>%
  rename(valenceSD = sd) %>%
  rename(valenceSE = se)

d3ocpb.norm.fig <- ggplot(d3ocpb.normsum,aes(y=normalityMean,x=outcome,fill=knowledge)) +
                  facet_grid(~norm) +
                  geom_bar(position = "dodge",stat="identity") +
                  geom_errorbar(aes(ymin= normalityMean - normalitySE, ymax = normalityMean + normalitySE),width=0.2,position=position_dodge(.9)) +
                  ylab("Abnormal (1) ~ Normal (7)") +
                  xlab("Outcome type") +
                  ggtitle("Normality ratings in abnormal or normal outcomes") +
                  scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
                  coord_cartesian(ylim=c(1,7)) +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,plot.title=element_text(hjust=.5)
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    #,legend.position = c(.9,.85)
                    #,legend.position = "null"
                    ,legend.title=element_text(size=rel(1))
                    ,legend.text=element_text(size=rel(1))
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                  )
d3ocpb.norm.fig

d3ocpb.vale.fig <- ggplot(d3ocpb.valesum,aes(y=valenceMean,x=outcome,fill=knowledge)) +
                  facet_grid(~norm) +
                  geom_bar(position = "dodge",stat="identity") +
                  geom_errorbar(aes(ymin= valenceMean - valenceSE, ymax = valenceMean + valenceSE),width=0.2,position=position_dodge(.9)) +
                  ylab("Bad (1) ~ Good (7)") +
                  xlab("Outcome type") +
                  ggtitle("Valence ratings in abnormal or normal outcomes") +
                  scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
                  coord_cartesian(ylim=c(1,7)) +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,plot.title=element_text(hjust=.5)
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    #,legend.position = c(.9,.85)
                    #,legend.position = "null"
                    ,legend.title=element_text(size=rel(1))
                    ,legend.text=element_text(size=rel(1))
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                  )
d3ocpb.vale.fig
```

# Experiment 3c: Valence and normality judgments in good and bad outcomes

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study.

```{r study3c participants&demo, echo=FALSE, warning=FALSE, message=FALSE}
d3.oc.gb <- read.csv("../data/goodbad_ValenceNormality_num.csv")
d3.oc.gb <- d3.oc.gb[-c(1:2), ]

# GoodBad ValeNorm demo (age, gender, education, ethnicity, ses):
d3.oc.gb_demo <- read.csv("../data/goodbad_ValenceNormality_txt.csv")
d3.oc.gb_demo <- d3.oc.gb_demo[-(1:2),] %>%
  select(c("age", "edu", "gender", "ethn", "ses"))
d3.oc.gb_demo$gender <- as.factor(d3.oc.gb_demo$gender)
d3.oc.gb_demo$edu <- as.factor(d3.oc.gb_demo$edu)
d3.oc.gb_demo$ethn <- as.factor(d3.oc.gb_demo$ethn)
d3.oc.gb_demo$ses <- as.factor(d3.oc.gb_demo$ses)
```

### Participants

For ratings of normality and valence for outcomes that were categorized as good versus bad, `r length(d3.oc.gb_demo$age)` participants were recruited (*M*~age~=`r round(mean(as.numeric(d3.oc.gb_demo$age), na.rm=T),digits=2)`, *SD*~age~=`r round(sd(as.numeric(d3.oc.gb_demo$age), na.rm=T),digits=2)`; `r length(which(d3.oc.gb_demo$gender=="Female"))` females), among which `r sum(!is.na(d3.oc.gb_demo$age))` answered all our demographic questions.\
All participants were recruited through Amazon Mechanical Turk (<http://www.mturk.com>).

```{r study3c dataset, echo=FALSE, warning=FALSE, message=FALSE}
#GoodBad ValeNorm cleaning
# d3.ocgb <- d3.oc.gb[,grepl("vale|norm|ResponseId", colnames(d3.oc.gb))] %>%
#   pivot_longer(col=2:257, names_to = "condition", values_to = "responses", values_drop_na = T) %>%
#   filter(`responses` != "") %>%
#   mutate(question = case_when(str_detect(condition, "vale") ~ "Valence",
#                               str_detect(condition, "norm") ~ "Normality"))%>%
#   mutate(norm = case_when(str_detect(condition, "R") ~ "Rationality",
#                           str_detect(condition, "M") ~ "Morality")) %>%
#   mutate(knowledge = case_when(str_detect(condition, "K") ~ "Knowledge",
#                           str_detect(condition, "I") ~ "Ignorance")) %>%
#   mutate(outcome = case_when(str_detect(condition, "B") ~ "Bad",
#                           str_detect(condition, "G") ~ "Good")) %>%
#   mutate(scenario = case_when(str_detect(condition, "\\bvale10.\\b|\\bnorm10.\\b") ~ 10,
#                               str_detect(condition, "\\bvale11.\\b|\\bnorm11.\\b") ~ 11,
#                               str_detect(condition, "\\bvale12.\\b|\\bnorm12.\\b") ~ 12,
#                               str_detect(condition, "\\bvale13.\\b|\\bnorm13.\\b") ~ 13,
#                               str_detect(condition, "\\bvale14.\\b|\\bnorm14.\\b") ~ 14,
#                               str_detect(condition, "\\bvale15.\\b|\\bnorm15.\\b") ~ 15,
#                               str_detect(condition, "\\bvale16.\\b|\\bnorm6.\\b") ~ 16,
#                               str_detect(condition, "\\bvale01.\\b|\\bnorm01.\\b") ~ 1,
#                               str_detect(condition, "\\bvale02.\\b|\\bnorm02.\\b") ~ 2,
#                               str_detect(condition, "\\bvale03.\\b|\\bnorm03.\\b") ~ 3,
#                               str_detect(condition, "\\bvale04.\\b|\\bnorm04.\\b") ~ 4,
#                               str_detect(condition, "\\bvale05.\\b|\\bnorm05.\\b") ~ 5,
#                               str_detect(condition, "\\bvale06.\\b|\\bnorm06.\\b") ~ 6,
#                               str_detect(condition, "\\bvale07.\\b|\\bnorm07.\\b") ~ 7,
#                               str_detect(condition, "\\bvale08.\\b|\\bnorm08.\\b") ~ 8,
#                               str_detect(condition, "\\bvale09.\\b|\\bnorm09.\\b") ~ 9)) %>%
#   dplyr::rename(condCod = condition) %>%
#   mutate(condition = case_when(str_detect(condCod, "MKB") ~ "MKB",
#                                str_detect(condCod, "MKG") ~ "MKG",
#                                str_detect(condCod, "MIB") ~ "MIB",
#                                str_detect(condCod, "MIG") ~ "MIG",
#                                str_detect(condCod, "RKB") ~ "RKB",
#                                str_detect(condCod, "RKG") ~ "RKG",
#                                str_detect(condCod, "RIB") ~ "RIB",
#                                str_detect(condCod, "RIG") ~ "RIG"))
# write.csv(d3.ocgb, "../data/d3ocgb.csv", row.names = FALSE)
d3.ocgb <- read.csv("../data/d3ocgb.csv")
```

### Materials

In this experiment, participants completed 16 trials which each involved reading a vignette where an agent's action resulted in an outcome that was good or bad and the action would have violated a moral or a rational norm. In addition, the agent was either ignorant or knowledgeable about the norm violated. As in Study 3a and Study 3b, the study used a 2 (Norm Type) $\times$ 2 (Agent Knowledge) $\times$ 2 (Outcome Valence) $\times$ 16 (Scenario) design that was administered in a mixed within- and between-subjects fashion, such that participants saw all 16 scenarios and on each trial were randomly assigned to read 1 of the 8 different versions of that scenario.

For instance, participants may read a vignette as follows:

> **Rational Norm / Knowledgeable Agent / Good Outcome** : The owner of a construction company, who was hired to remodel a skyscraper, decided to use a new material called Plyvex to cover the inner walls of the building. When the building inspector reviewed the plans, she realized that Plyvex was one of the least efficient choices for this project. She told the owner of the construction company about this. Although the owner of the construction company understood this, he decided to use Plyvex anyway, like he originally planned. It turns out that Plyvex is particularly resistant to mold. Because of this, a number of people in the company who were suffering from lung problems became much healthier after the Plyvex had been installed.

### Procedure

After reading the brief vignette, participants rated the extent to which they thought the outcome was good or bad and the extent to which they thought the outcome was normal or abnormal.

> *Valence Question*: After the plyvex was installed, the entire building smelled of kiwis. Do you think this was a good or bad thing to have happened?

> *Normality Question*: After the plyvex was installed, the entire building smelled of kiwis. Do you think it was a normal or abnormal thing to have happened?

Participants answered the question on a 7-point Likert scale from 1 ('Completely bad' or 'Completely abnormal') to 7 ('Completely good' or 'Completely normal'), with a midpoint of 4 ('In between').

Participants were asked to complete a brief demographic questionnaire after completing all 16 trials.

```{r study3c analyses, echo=FALSE, warning=FALSE, message=FALSE}
## GoodBad ValeNorms
###ocgb main effects (outcome and norm significant)

# lmr3ocgb.main <- lmer(responses ~ knowledge + outcome + norm +  (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocgb)
# 
#   lmr3ocgb.outcome <- lmer(responses ~ knowledge + norm + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocgb)
#   lmr3ocgb.outcome <- anova(lmr3ocgb.main,lmr3ocgb.outcome)
#   saveRDS(lmr3ocgb.outcome,"models/lmr3ocgb.outcome.rds")
lmr3ocgb.outcome <- readRDS("models/lmr3ocgb.outcome.rds")
d3c.sumO <- d3.ocgb %>% 
  select(outcome,responses,ResponseId) %>%
  group_by(outcome,ResponseId) %>%
  summarise(outcomeM = mean(responses),na.rm=TRUE) %>%
  group_by(outcome) %>%
  summarise(N = length(outcomeM),
           mean = mean(outcomeM, na.rm=TRUE),
           sd = sd(outcomeM,na.rm=TRUE),
           se = sd / sqrt(N))

  # lmr3ocgb.norm <- lmer(responses ~ knowledge + outcome + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocgb)
  # lmr3ocgb.norm <- anova(lmr3ocgb.main,lmr3ocgb.norm)
  # saveRDS(lmr3ocgb.norm,"models/lmr3ocgb.norm.rds")
lmr3ocgb.norm <- readRDS("models/lmr3ocgb.norm.rds")
d3c.sumN <- d3.ocgb %>% 
  select(norm,responses,ResponseId) %>%
  group_by(norm,ResponseId) %>%
  summarise(normM = mean(responses),na.rm=TRUE) %>%
  group_by(norm) %>%
  summarise(N = length(normM),
           mean = mean(normM, na.rm=TRUE),
           sd = sd(normM,na.rm=TRUE),
           se = sd / sqrt(N))

  # lmr3ocgb.knowledge <- lmer(responses ~ outcome + norm + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocgb)
  # lmr3ocgb.knowledge <- anova(lmr3ocgb.main,lmr3ocgb.knowledge)
  # saveRDS(lmr3ocgb.knowledge,"models/lmr3ocgb.knowledge.rds")
lmr3ocgb.knowledge <- readRDS("models/lmr3ocgb.knowledge.rds")



###ocgb interactions

  ## ocgb three-way interaction (insignificant)
# lmr3ocgb.i0 <- lmer(responses ~ knowledge * norm * outcome + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocgb)
# lmr3ocgb.i1 <- lmer(responses ~ (knowledge * norm) + (outcome * knowledge) + (outcome * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocgb)
# lmr3ocgb.3way <- anova(lmr3ocgb.i0,lmr3ocgb.i1)
# saveRDS(lmr3ocgb.3way,"models/lmr3ocgb.3way.rds")
lmr3ocgb.3way <- readRDS("models/lmr3ocgb.3way.rds")

  ## ocgb two-way: Norm x Knowledge interaction (insignificant)
# lmr3ocgb.NK <- lmer(responses ~ (knowledge * outcome) + (outcome * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocgb)
# lmr3ocgb.NxK <- anova(lmr3ocgb.i1, lmr3ocgb.NK)
# saveRDS(lmr3ocgb.NxK,"models/lmr3ocgb.NxK.rds")
lmr3ocgb.NxK <- readRDS("models/lmr3ocgb.NxK.rds")
    # d3.ocgb %>% 
    # group_by(knowledge,norm,ResponseId) %>% 
    # summarise(means=mean(responses, na.rm = T)) 

  ## ocgb two-way: Norm x Outcome interaction (significant)
# lmr3ocgb.NO <- lmer(responses ~ (knowledge * outcome) + (knowledge * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocgb)
# lmr3ocgb.NxO <- anova(lmr3ocgb.i1, lmr3ocgb.NO)
# saveRDS(lmr3ocgb.NxO,"models/lmr3ocgb.NxO.rds")
lmr3ocgb.NxO <- readRDS("models/lmr3ocgb.NxO.rds")
    # ggplot(d3ocgb.valesum,aes(y=valenceMean,x=outcome,fill=norm)) +
    #                   geom_bar(position = "dodge",stat="identity")
    # ggplot(d3ocgb.normsum,aes(y=normalityMean,x=outcome,fill=norm)) +
    #                   geom_bar(position = "dodge",stat="identity")

  ## ocgb two-way: Outcome x Knowledge interaction (insignificant)
# lmr3ocgb.OK <- lmer(responses ~ (norm * outcome) + (knowledge * norm) + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d3.ocgb)
# lmr3ocgb.OxK <- anova(lmr3ocgb.i1,lmr3ocgb.OK)
# saveRDS(lmr3ocgb.OxK,"models/lmr3ocgb.OxK.rds")
lmr3ocgb.OxK <- readRDS("models/lmr3ocgb.OxK.rds")
```

### Data analysis

No participant was excluded from the analyses as long as the entire study was completed.

## Results

We analyzed participants' ratings, which revealed a main effect of the valence of outcome, $\chi^2(2)$ = `r round(lmr3ocgb.outcome$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocgb.outcome$'Pr(>Chisq)'[2],digits=3))`, such that participants thought it was a less normal and less good thing to have happened when the outcome was bad (*M* = `r round(d3c.sumO$mean[d3c.sumO$outcome=="Bad"],digits=2)`, *SD* = `r round(d3c.sumO$sd[d3c.sumO$outcome=="Bad"],digits=2)`) than when it was good (*M* = `r round(d3c.sumO$mean[d3c.sumO$outcome=="Good"],digits=2)`, *SD* = `r round(d3c.sumO$sd[d3c.sumO$outcome=="Good"],digits=2)`). We also found a main effect of the type of norm violated, $\chi^2(2)$ = `r round(lmr3ocgb.norm$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocgb.norm$'Pr(>Chisq)'[2]),digits=3)`, which indicates that participants thought it was a less normal and less good thing to have happened when moral norm was violated (*M* = `r round(d3c.sumN$mean[d3c.sumN$norm=="Morality"],digits=2)`, *SD* = `r round(d3c.sumN$sd[d3c.sumN$norm=="Morality"],digits=2)`) than when rational norm was violated (*M* = `r round(d3c.sumN$mean[d3c.sumN$norm=="Rationality"],digits=2)`, *SD* = `r round(d3c.sumN$sd[d3c.sumN$norm=="Rationality"],digits=2)`). However, we did not observe a main effect of whether or not the agent had *Knowledge* about the outcome, $\chi^2(2)$ = `r round(lmr3ocgb.knowledge$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocgb.knowledge$'Pr(>Chisq)'[2]),digits=3)`. We also probed interaction effects and only the one between *Outcome* $\times$ *Norm* was significant, $\chi^2(2)$ = `r round(lmr3ocgb.NxO$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocgb.NxO$'Pr(>Chisq)'[2],digits=3))` was significant, suggesting that participants' normality and valence ratings tend to differentiate more between rational norm and moral norm when the event resulted in a good outcome. The other interaction effects we looked into were not significant, including the three-way *Knowledge* $\times$ *Norm* $\times$ *Outcome* interaction, $\chi^2(2)$ = `r round(lmr3ocgb.3way$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocgb.3way$'Pr(>Chisq)'[2],digits=3))`, and the two two-way interactions of *Knowledge* $\times$ *Norm*, $\chi^2(2)$ = `r round(lmr3ocgb.NxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocgb.NxK$'Pr(>Chisq)'[2],digits=3))`, *Knowledge* $\times$ *Outcome*, $\chi^2(2)$ = `r round(lmr3ocgb.OxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr3ocgb.OxK$'Pr(>Chisq)'[2],digits=3))`.

```{r study3c plots, echo=FALSE, warning=FALSE, message=FALSE}

### GoodBad ValeNorm plots
d3ocgb.normsum <- d3.ocgb[d3.ocgb$question=="Normality",]%>%
  dplyr::select(responses, norm, outcome, knowledge) %>%
  group_by(knowledge,norm,outcome) %>% 
                      summarise(N = length(responses),
                                mean = mean(as.numeric(responses), na.rm=TRUE),
                                sd = sd(as.numeric(responses),na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(normalityN = N) %>%
  rename(normalityMean = mean) %>%
  rename(normalitySD = sd) %>%
  rename(normalitySE = se)

d3ocgb.valesum <- d3.ocgb[d3.ocgb$question=="Valence",] %>%
  dplyr::select(responses, norm, outcome, knowledge) %>%
  group_by(knowledge,norm,outcome) %>% 
                      summarise(N = length(responses),
                                mean = mean(as.numeric(responses), na.rm=TRUE),
                                sd = sd(as.numeric(responses),na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(valenceN = N) %>%
  rename(valenceMean = mean) %>%
  rename(valenceSD = sd) %>%
  rename(valenceSE = se)

d3ocgb.norm.fig <- ggplot(d3ocgb.normsum,aes(y=normalityMean,x=outcome,fill=knowledge)) +
                  facet_grid(~norm) +
                  geom_bar(position = "dodge",stat="identity") +
                  geom_errorbar(aes(ymin= normalityMean - normalitySE, ymax = normalityMean + normalitySE),width=0.2,position=position_dodge(.9)) +
                  ylab("Abnormal (1) ~ Normal (7)") +
                  xlab("Outcome type") +
                  ggtitle("Normality ratings in bad or good outcomes") +
                  scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
                  coord_cartesian(ylim=c(1,7)) +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,plot.title=element_text(hjust=.5)
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    #,legend.position = c(.9,.85)
                    #,legend.position = "null"
                    ,legend.title=element_text(size=rel(1))
                    ,legend.text=element_text(size=rel(1))
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                  )
d3ocgb.norm.fig

d3ocgb.vale.fig <- ggplot(d3ocgb.valesum,aes(y=valenceMean,x=outcome,fill=knowledge)) +
                  facet_grid(~norm) +
                  geom_bar(position = "dodge",stat="identity") +
                  geom_errorbar(aes(ymin= valenceMean - valenceSE, ymax = valenceMean + valenceSE),width=0.2,position=position_dodge(.9)) +
                  ylab("Bad (1) ~ Good (7)") +
                  xlab("Outcome type") +
                  ggtitle("Valence ratings in bad or good outcomes") +
                  scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
                  coord_cartesian(ylim=c(1,7)) +
                  theme_bw() +
                  theme(
                    plot.background = element_blank()
                    ,plot.title=element_text(hjust=.5)
                    ,panel.grid.major = element_blank()
                    ,panel.grid.minor = element_blank()
                    #,legend.position = c(.9,.85)
                    #,legend.position = "null"
                    ,legend.title=element_text(size=rel(1))
                    ,legend.text=element_text(size=rel(1))
                    ,axis.text.y=element_text(size=rel(1))
                    ,axis.text.x=element_text(size=rel(1))
                    ,axis.title.y=element_text(vjust=.9)
                    ,axis.ticks = element_blank()
                    ,axis.title=element_text(size=rel(1))
                  )
d3ocgb.vale.fig
```

# Experiment 4

## Methods

We report how we determined our sample size, all data exclusions (if any), all manipulations, and all measures in the study.

### Participants

```{r study4 participants, echo=FALSE, warning=FALSE, message=FALSE}
d4.pb <- read.csv("../data/probnor_CounterFactuals_num.csv")
d4.pb <- d4.pb[-c(1:2), ]

d4.gb <- read.csv("../data/goodbad_CounterFactuals_num.csv")
d4.gb <- d4.gb[-c(1:2), ]


# ProbNor CounterFactual demo (age, gender, education, ethnicity, ses):
d4.pb_demo <- read.csv("../data/probnor_CounterFactuals_txt.csv")
d4.pb_demo <- d4.pb_demo[-c(1:2),] %>%
  select(c("age", "edu", "gender", "ethn", "ses"))
d4.pb_demo$gender <- as.factor(d4.pb_demo$gender)
d4.pb_demo$edu <- as.factor(d4.pb_demo$edu)
d4.pb_demo$ethn <- as.factor(d4.pb_demo$ethn)
d4.pb_demo$ses <- as.factor(d4.pb_demo$ses)


# GoodBad CounterFactual demo (age, gender, education, ethnicity, ses): 
d4.gb_demo <- read.csv("../data/goodbad_CounterFactuals_txt.csv")
d4.gb_demo <- d4.gb_demo[-(1:2),] %>%
  select(c("age", "edu", "gender", "ethn", "ses"))
d4.gb_demo$gender <- as.factor(d4.gb_demo$gender)
d4.gb_demo$edu <- as.factor(d4.gb_demo$edu)
d4.gb_demo$ethn <- as.factor(d4.gb_demo$ethn)
d4.gb_demo$ses <- as.factor(d4.gb_demo$ses)

d4_demo <- rbind(d4.gb_demo, d4.pb_demo)
d4_demo$gender <- as.factor(d4_demo$gender)
d4_demo$edu <- as.factor(d4_demo$edu)
d4_demo$ethn <- as.factor(d4_demo$ethn)
d4_demo$ses <- as.factor(d4_demo$ses)

###write.csv(d4.pb_demo, "../data/d4pbCFdemo.csv", row.names = FALSE)
###write.csv(d4.gb_demo, "../data/d4gbCFdemo.csv", row.names = FALSE)
```

In Experiment 4, `r length(d4_demo$age)` participants were recruited (*M*~age~=`r round(mean(as.numeric(d4_demo$age), na.rm=T),digits=2)`, *SD*~age~=`r round(sd(as.numeric(d4_demo$age), na.rm=T),digits=2)`; `r length(which(d4_demo$gender=="Female"))` females), among which `r sum(d4_demo$edu != "")` answered all our demographic questions.\
All participants were recruited through Amazon Mechanical Turk (<http://www.mturk.com>).

### Materials

```{r study4 datasets, echo=FALSE, warning=FALSE, message=FALSE}

# ProbNor CounterFactual cleaning
# d4pb <- d4.pb[,grepl("modal|cfcon|ResponseId", colnames(d4.pb))] %>%
#   pivot_longer(cols=2:257, names_to = "condition", values_to = "CF responses", values_drop_na = T) %>%
#   filter(`CF responses` != "") %>% 
#   # mutate("modal response" = ifelse(grepl("modal", condition), `CF responses`, "")) %>%
#   # mutate("cfcon response" = ifelse(grepl("cfcon", condition), `CF responses`, "")) %>%
#   # mutate(`cfcon response` = as.numeric(`cfcon response`)) %>%
#   # mutate(`modal response` = as.numeric(`modal response`)) %>%
#   mutate(question = case_when(str_detect(condition, "cfcon") ~ "Counterfactual",
#                               str_detect(condition, "modal") ~ "Modal"))%>%
#   mutate(norm = case_when(str_detect(condition, "R") ~ "Rationality",
#                           str_detect(condition, "M") ~ "Morality")) %>%
#   mutate(knowledge = case_when(str_detect(condition, "K") ~ "Knowledge",
#                           str_detect(condition, "I|i") ~ "Ignorance")) %>%
#   mutate(outcome = case_when(str_detect(condition, "B") ~ "Abnormal",
#                           str_detect(condition, "G") ~ "Normal")) %>%
#   mutate(scenario = case_when(str_detect(condition, "\\bmodal01\\b|cfcon01") ~ 1,
#                               str_detect(condition, "\\bmodal02\\b|cfcon02") ~ 2,
#                               str_detect(condition, "\\bmodal03\\b|cfcon03") ~ 3,
#                               str_detect(condition, "\\bmodal04\\b|cfcon04") ~ 4,
#                               str_detect(condition, "\\bmodal05\\b|cfcon05") ~ 5,
#                               str_detect(condition, "\\bmodal06\\b|cfcon06") ~ 6,
#                               str_detect(condition, "\\bmodal07\\b|cfcon07") ~ 7,
#                               str_detect(condition, "\\bmodal08\\b|cfcon08") ~ 8,
#                               str_detect(condition, "\\bmodal09\\b|cfcon09") ~ 9,
#                               str_detect(condition, "\\bmodal10\\b|cfcon10") ~ 10,
#                               str_detect(condition, "\\bmodal11\\b|cfcon11") ~ 11,
#                               str_detect(condition, "\\bmodal12\\b|cfcon12") ~ 12,
#                               str_detect(condition, "\\bmodal13\\b|cfcon13") ~ 13,
#                               str_detect(condition, "\\bmodal14\\b|cfcon14") ~ 14,
#                               str_detect(condition, "\\bmodal15\\b|cfcon15") ~ 15,
#                               str_detect(condition, "\\bmodal16\\b|cfcon16") ~ 16)) %>%
#   dplyr::rename(condCod = condition) %>%
#   mutate(condition = case_when(str_detect(condCod, "MKB") ~ "MKB",
#                                str_detect(condCod, "MKG") ~ "MKG",
#                                str_detect(condCod, "MIB") ~ "MIB",
#                                str_detect(condCod, "MIG") ~ "MIG",
#                                str_detect(condCod, "MiG") ~ "MIG",
#                                str_detect(condCod, "RKB") ~ "RKB",
#                                str_detect(condCod, "RKG") ~ "RKG",
#                                str_detect(condCod, "RIB") ~ "RIB",
#                                str_detect(condCod, "RIG") ~ "RIG")) %>%
# mutate(`CF responses` = ifelse(question == "Modal", case_when(`CF responses` == 1 ~ "Completely agree",
#                                     `CF responses` == 2 ~ "Agree",
#                                     `CF responses` == 3 ~ "Somewhat agree",
#                                     `CF responses` == 4 ~ "Neutral",
#                                     `CF responses` == 5 ~ "Somewhat disagree",
#                                     `CF responses` == 6 ~ "Disagree",
#                                     `CF responses` == 7 ~ "Completely disagree"), `CF responses`)) %>%
#   mutate(`CF responses` = ifelse(question == "Modal", case_when(`CF responses` == "Completely agree" ~ 7,
#                                     `CF responses` == "Agree" ~ 6,
#                                     `CF responses` == "Somewhat agree" ~ 5,
#                                     `CF responses` == "Neutral" ~ 4,
#                                     `CF responses` == "Somewhat disagree" ~ 3,
#                                     `CF responses` == "Disagree" ~ 2,
#                                     `CF responses` == "Completely disagree" ~ 1), `CF responses`)) %>%
# mutate(`CF responses` = ifelse(question == "Counterfactual", case_when(`CF responses` == 1 ~ "Completely relevant",
#                                     `CF responses` == 2 ~ "Relevant",
#                                     `CF responses` == 3 ~ "Somewhat relevant",
#                                     `CF responses` == 4 ~ "Neutral",
#                                     `CF responses` == 5 ~ "Somewhat irrelevant",
#                                     `CF responses` == 6 ~ "Irrelevant",
#                                     `CF responses` == 7 ~ "Completely irrelevant"), `CF responses`)) %>%
#   mutate(`CF responses` = ifelse(question == "Counterfactual", case_when(`CF responses` == "Completely relevant" ~ 7,
#                                     `CF responses` == "Relevant" ~ 6,
#                                     `CF responses` == "Somewhat relevant" ~ 5,
#                                     `CF responses` == "Neutral" ~ 4,
#                                     `CF responses` == "Somewhat irrelevant" ~ 3,
#                                     `CF responses` == "Irrelevant" ~ 2,
#                                     `CF responses` == "Completely irrelevant" ~ 1), `CF responses`)) 
# 
# table(d4pb[d4pb$question=="Modal",]$`CF responses`)
# table(d4pb[d4pb$question=="Counterfactual",]$`CF responses`)


# GoodBad CounterFactual cleaning
# d4gb <- d4.gb[,grepl("modal|cfcon|ResponseId", colnames(d4.gb))] %>%
#   pivot_longer(cols=2:257, names_to = "condition", values_to = "CF responses") %>%
#   filter(`CF responses` != "") %>%
#   # mutate("modal response" = ifelse(grepl("modal", condition), `CF responses`, "")) %>%
#   # mutate("cfcon response" = ifelse(grepl("cfcon", condition), `CF responses`, "")) %>%
#   # mutate(`cfcon response` = as.numeric(`cfcon response`)) %>%
#   # mutate(`modal response` = as.numeric(`modal response`)) %>%
#   mutate(question = case_when(str_detect(condition, "cfcon") ~ "Counterfactual",
#                               str_detect(condition, "modal") ~ "Modal"))%>%
#   mutate(norm = case_when(str_detect(condition, "R") ~ "Rationality",
#                           str_detect(condition, "M") ~ "Morality")) %>%
#   mutate(knowledge = case_when(str_detect(condition, "K") ~ "Knowledge",
#                           str_detect(condition, "I|i") ~ "Ignorance")) %>%
#   mutate(outcome = case_when(str_detect(condition, "B") ~ "Bad",
#                           str_detect(condition, "G") ~ "Good")) %>%
#   mutate(scenario = case_when(str_detect(condition, "\\bmodal01\\b|cfcon01") ~ 1,
#                               str_detect(condition, "\\bmodal02\\b|cfcon02") ~ 2,
#                               str_detect(condition, "\\bmodal03\\b|cfcon03") ~ 3,
#                               str_detect(condition, "\\bmodal04\\b|cfcon04") ~ 4,
#                               str_detect(condition, "\\bmodal05\\b|cfcon05") ~ 5,
#                               str_detect(condition, "\\bmodal06\\b|cfcon06") ~ 6,
#                               str_detect(condition, "\\bmodal07\\b|cfcon07") ~ 7,
#                               str_detect(condition, "\\bmodal08\\b|cfcon08") ~ 8,
#                               str_detect(condition, "\\bmodal09\\b|cfcon09") ~ 9,
#                               str_detect(condition, "\\bmodal10\\b|cfcon10") ~ 10,
#                               str_detect(condition, "\\bmodal11\\b|cfcon11") ~ 11,
#                               str_detect(condition, "\\bmodal12\\b|cfcon12") ~ 12,
#                               str_detect(condition, "\\bmodal13\\b|cfcon13") ~ 13,
#                               str_detect(condition, "\\bmodal14\\b|cfcon14") ~ 14,
#                               str_detect(condition, "\\bmodal15\\b|cfcon15") ~ 15,
#                               str_detect(condition, "\\bmodal16\\b|cfcon16") ~ 16)) %>%
#   dplyr::rename(condCod = condition) %>%
#   mutate(condition = case_when(str_detect(condCod, "MKB") ~ "MKB",
#                                str_detect(condCod, "MKG") ~ "MKG",
#                                str_detect(condCod, "MIB") ~ "MIB",
#                                str_detect(condCod, "MIG") ~ "MIG",
#                                str_detect(condCod, "MiG") ~ "MIG",
#                                str_detect(condCod, "RKB") ~ "RKB",
#                                str_detect(condCod, "RKG") ~ "RKG",
#                                str_detect(condCod, "RIB") ~ "RIB",
#                                str_detect(condCod, "RIG") ~ "RIG")) %>%
# mutate(`CF responses` = ifelse(question == "Counterfactual", case_when(`CF responses` == 1 ~ "Completely relevant",
#                                     `CF responses` == 2 ~ "Relevant",
#                                     `CF responses` == 3 ~ "Somewhat relevant",
#                                     `CF responses` == 4 ~ "Neutral",
#                                     `CF responses` == 5 ~ "Somewhat irrelevant",
#                                     `CF responses` == 6 ~ "Irrelevant",
#                                     `CF responses` == 7 ~ "Completely irrelevant"), `CF responses`)) %>%
#   mutate(`CF responses` = ifelse(question == "Counterfactual", case_when(`CF responses` == "Completely relevant" ~ 7,
#                                     `CF responses` == "Relevant" ~ 6,
#                                     `CF responses` == "Somewhat relevant" ~ 5,
#                                     `CF responses` == "Neutral" ~ 4,
#                                     `CF responses` == "Somewhat irrelevant" ~ 3,
#                                     `CF responses` == "Irrelevant" ~ 2,
#                                     `CF responses` == "Completely irrelevant" ~ 1), `CF responses`)) 
# table(d4gb[d4gb$question=="Modal",]$`CF responses`)
# table(d4gb[d4gb$question=="Counterfactual",]$`CF responses`)

# d4 <- rbind(d4pb, d4gb) %>%
#   rename(ocOri = outcome) %>%
#   mutate(outcome = case_when(ocOri == "Good"|ocOri =="Normal" ~ "Normal",
#                              ocOri == "Bad"|ocOri =="Abnormal" ~ "Abnormal")) %>%
#   mutate(`CF responses` = as.numeric(`CF responses`))

# write.csv(d4, "../data/d4mdcf.csv", row.names = FALSE)
d4 <- read_csv("../data/d4mdcf.csv") 
#for some reason reading from saved csv created NAs in knowledge ("MiG") the first time; working now
```

Participants completed 16 trials which each involved reading a vignette where an agent's action resulted in an outcome that was normal or abnormal (defined by probability of occurrence). The action would have violated a moral or a rational norm. In addition, the agent was either ignorant or knowledgeable about the norm violated.

For instance, participants may read a vignette as follows:

> **Rational Norm / Knowledgeable Agent / Abnormal Outcome** : The owner of a construction company, who was hired to remodel a skyscraper, decided to use a new material called Plyvex to cover the inner walls of the building. When the building inspector reviewed the plans, she realized that Plyvex was one of the least efficient choices for this project. She told the owner of the construction company about this. Although the owner of the construction company understood this, he decided to use Plyvex anyway, like he originally planned. It turns out that Plyvex creates a scent that smells almost exactly like ripe kiwis. Because of this, a number of people in the company noticed that the entire building smelled of kiwis after the Plyvex had been installed.

### Procedure

After reading each vignette, participants answered two questions: a modal one and a counterfactual one. More specifically, they rated their agreement with a statement about whether the agent could have not completed the action and one about whether the absence of the agent's action could have prevented the outcome, as in the following example:

> *Modal question*: The owner of the construction company could have not used Plyvex.

> *Counterfactual question*: If the owner of the construction company had not used Plyvex, the entire building would not have smelled of kiwis.

\noindent After completing all 16 trials, participants were asked to complete some optional demographic questions.

```{r study4 md & cf interactions, echo=FALSE, warning=FALSE, message=FALSE}
# ###check for little variation across 8*16 for modal responses (histogram of avg.)
# mean(d4[d4$question=="Modal",]$`CF responses`)
# mean(d4[d4$question=="Counterfactual",]$`CF responses`)
# d4 %>%
#   filter(question=="Modal") %>%
#   group_by(scenario, norm, knowledge, outcome) %>%
#   summarise(`modal mean` = mean(as.numeric(`CF responses`)))
# 
# d4 %>%
#   filter(question=="Modal") %>%
#   #group_by(scenario, norm, knowledge, outcome) %>%
#   #summarise(`modal mean` = mean(as.numeric(`CF responses`)))
#   ggplot(aes(x=outcome, y=as.numeric(`CF responses`), fill=knowledge)) +
#   geom_bar(position = "dodge",
#            stat = "summary",
#            fun = "mean") +
#   facet_wrap(scenario~norm)
# 
# d4 %>%
#   filter(question=="Counterfactual") %>%
#   #group_by(scenario, norm, knowledge, outcome) %>%
#   #summarise(`modal mean` = mean(as.numeric(`CF responses`)))
#   ggplot(aes(x=outcome, y=as.numeric(`CF responses`), fill=knowledge)) +
#   geom_bar(position = "dodge",
#            stat = "summary",
#            fun = "mean") +
#   facet_wrap(scenario~norm)


# Test main effects

## md main effects (knowledge significant)
# lmr4md.main <- lmer(`CF responses` ~ knowledge + outcome + norm +  (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d4[d4$question=="Modal",])
# 
# lmr4md.outcome <- lmer(`CF responses` ~ knowledge + norm + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d4[d4$question=="Modal",])
# lmr4md.outcome <- anova(lmr4md.main,lmr4md.outcome)
# saveRDS(lmr4md.outcome,"models/lmr4md.outcome.rds")
lmr4md.outcome <- readRDS("models/lmr4md.outcome.rds")

# lmr4md.norm <- lmer(`CF responses` ~ knowledge + outcome + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d4[d4$question=="Modal",])
# lmr4md.norm <- anova(lmr4md.main,lmr4md.norm)
# saveRDS(lmr4md.norm,"models/lmr4md.norm.rds")
lmr4md.norm <- readRDS("models/lmr4md.norm.rds")

# lmr4md.knowledge <- lmer(`CF responses` ~ outcome + norm + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d4[d4$question=="Modal",])
# lmr4md.knowledge <- anova(lmr4md.main,lmr4md.knowledge)
# saveRDS(lmr4md.knowledge,"models/lmr4md.knowledge.rds")
lmr4md.knowledge <- readRDS("models/lmr4md.knowledge.rds")
d4md.sumK <- d4[d4$question=="Modal",] %>% 
  select(knowledge, `CF responses`, ResponseId) %>%
  group_by(knowledge,ResponseId) %>%
  summarise(modalM = mean(`CF responses`),na.rm=TRUE) %>%
  group_by(knowledge) %>%
  summarise(N = length(modalM),
           mean = mean(modalM, na.rm=TRUE),
           sd = sd(modalM,na.rm=TRUE),
           se = sd / sqrt(N))

## cf main effects ( significant)
# lmr4cf.main <- lmer(`CF responses` ~ knowledge + outcome + norm +  (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d4[d4$question=="Counterfactual",])

# lmr4cf.outcome <- lmer(`CF responses` ~ knowledge + norm + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d4[d4$question=="Counterfactual",])
# lmr4cf.outcome <- anova(lmr4cf.main,lmr4cf.outcome)
# saveRDS(lmr4cf.outcome,"models/lmr4cf.outcome.rds")
lmr4cf.outcome <- readRDS("models/lmr4cf.outcome.rds")
d4cf.sumO <- d4[d4$question=="Counterfactual",] %>% 
  select(outcome, `CF responses`, ResponseId) %>%
  group_by(outcome,ResponseId) %>%
  summarise(counterfactualM = mean(`CF responses`),na.rm=TRUE) %>%
  group_by(outcome) %>%
  summarise(N = length(counterfactualM),
           mean = mean(counterfactualM, na.rm=TRUE),
           sd = sd(counterfactualM,na.rm=TRUE),
           se = sd / sqrt(N))

# lmr4cf.norm <- lmer(`CF responses` ~ knowledge + outcome + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d4[d4$question=="Counterfactual",])
# lmr4cf.norm <- anova(lmr4cf.main,lmr4cf.norm)
# saveRDS(lmr4cf.norm,"models/lmr4cf.norm.rds")
lmr4cf.norm <- readRDS("models/lmr4cf.norm.rds")

# lmr4cf.knowledge <- lmer(`CF responses` ~ outcome + norm + (knowledge*norm*outcome|condition) + (knowledge*norm*outcome|scenario) + (1|ResponseId), data=d4[d4$question=="Counterfactual",])
# lmr4cf.knowledge <- anova(lmr4cf.main,lmr4cf.knowledge)
# saveRDS(lmr4cf.knowledge,"models/lmr4cf.knowledge.rds")
lmr4cf.knowledge <- readRDS("models/lmr4cf.knowledge.rds")

# Test interaction between outcome and knowledge like in normative CF (little effect in norm therefore omitted)

## Md: Three-way interaction (insignificant)
# lm4md.0 <- lmer(`CF responses` ~ outcome*knowledge*norm + (knowledge*norm*outcome|ResponseId) + (1|scenario), data=d4[d4$question=="Modal",])
# lm4md.1 <- lmer(`CF responses` ~ (knowledge*norm) + (outcome*knowledge) + (outcome*norm) + (knowledge*norm*outcome|ResponseId) + (1|scenario), data=d4[d4$question=="Modal",])
# lm4md.3way <- anova(lm4md.0, lm4md.1)
# saveRDS(lm4md.3way, "models/lm4md.3way.rds")
lm4md.3way <- readRDS("models/lm4md.3way.rds")

## Md: Outcome x Knowledge interaction (insignificant)
# lm4md.2 <- lmer(`CF responses` ~ (knowledge*norm) + (outcome*norm) + (knowledge*norm*outcome|ResponseId) + (1|scenario), data=d4[d4$question=="Modal",])
# lm4md.OxK <- anova(lm4md.1,lm4md.2)
# saveRDS(lm4md.OxK,"models/lm4md.OxK.rds")
lm4md.OxK <- readRDS("models/lm4md.OxK.rds")
          # #different approach (can compare with what's above):
          # t1 <- lmer(`CF responses` ~ knowledge*outcome + (knowledge*outcome|ResponseId) + (1|scenario), data=d4[d4$question=="Modal",])
          # t2 <- lmer(`CF responses` ~ knowledge+outcome + (knowledge*outcome|ResponseId) + (1|scenario), data=d4[d4$question=="Modal",])
          # anova(t1, t2)


## Cf: Three-way interaction (insignificant)
# lm4cf.0 <- lmer(`CF responses` ~ outcome*knowledge*norm + (knowledge*norm*outcome|ResponseId) + (1|scenario), data=d4[d4$question=="Counterfactual",])
# lm4cf.1 <- lmer(`CF responses` ~ (knowledge*norm) + (outcome*knowledge) + (outcome*norm) + (knowledge*norm*outcome|ResponseId) + (1|scenario), data=d4[d4$question=="Counterfactual",])
# lm4cf.3way <- anova(lm4cf.0, lm4cf.1)
# saveRDS(lm4cf.3way, "models/lm4cf.3way.rds")
lm4cf.3way <- readRDS("models/lm4cf.3way.rds")

## Cf: Outcome x Knowledge interaction (significant)
# lm4cf.2 <- lmer(`CF responses` ~ (knowledge*norm) + (outcome*norm) + (knowledge*norm*outcome|ResponseId) + (1|scenario), data=d4[d4$question=="Counterfactual",])
# lm4cf.OxK <- anova(lm4cf.1,lm4cf.2)
# saveRDS(lm4cf.OxK,"models/lm4cf.OxK.rds")
lm4cf.OxK <- readRDS("models/lm4cf.OxK.rds")



## LMM of knowledge, outcome, norm; separately for modal and CF (subject and scenario as random effects)
# lmm4md.k <- lmer(`CF responses` ~ knowledge + (knowledge|ResponseId) + (1|scenario) + (1|ResponseId), data=d4[d4$question=="Modal",])
# lmm4md.o <- lmer(`CF responses` ~ outcome + (outcome|ResponseId) + (1|scenario) + (1|ResponseId), data=d4[d4$question=="Modal",])
# lmm4md.n <- lmer(`CF responses` ~ norm + (norm|ResponseId) + (1|scenario) + (1|ResponseId), data=d4[d4$question=="Modal",])
# 
# lmm4cf.k <- lmer(`CF responses` ~ knowledge + (knowledge|ResponseId) + (1|scenario) + (1|ResponseId), data=d4[d4$question=="Counterfactual",])
# lmm4cf.o <- lmer(`CF responses` ~ outcome + (outcome|ResponseId) + (1|scenario) + (1|ResponseId), data=d4[d4$question=="Counterfactual",])
# lmm4cf.n <- lmer(`CF responses` ~ norm + (norm|ResponseId) + (1|scenario) + (1|ResponseId), data=d4[d4$question=="Counterfactual",])

```

### Data analysis

No participants were excluded from the analyses as long as they completed the entire study. The primary analyses were conducted with linear mixed-effects models and included random effects for both participants and scenarios.

## Results

### Main effects and interactions effects

We first explored main effects of *Knowledge*, *Norm*, and *Outcome* in both modal and counterfactual ratings. In modal ratings, we found only one significant main effect, *Knowledge*, $\chi^2(2)$ = `r round(lmr4md.knowledge$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr4md.knowledge$'Pr(>Chisq)'[2],digits=3))`, such that participants believed that ignorant agents were less likely to have not done what they did (*M* = `r round(d4md.sumK$mean[d4md.sumK$knowledge=="Ignorance"],digits=2)`, *SD* = `r round(d4md.sumK$sd[d4md.sumK$knowledge=="Ignorance"],digits=2)`) than knowledgeable agents (*M* = `r round(d4md.sumK$mean[d4md.sumK$knowledge=="Knowledge"],digits=2)`, *SD* = `r round(d4md.sumK$sd[d4md.sumK$knowledge=="Knowledge"],digits=2)`). As for counterfactual ratings, only one significant main effect was discovered as well and it was that of *Outcome*, $\chi^2(2)$ = `r round(lmr4cf.outcome$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr4cf.outcome$'Pr(>Chisq)'[2],digits=3))`, suggesting that participants agreed more with the statement that if the agent had not done what they did, the outcome would not have occurred when the outcome itself was abnormal (*M* = `r round(d4cf.sumO$mean[d4cf.sumO$outcome=="Abnormal"],digits=2)`, *SD* = `r round(d4cf.sumO$sd[d4cf.sumO$outcome=="Abnormal"],digits=2)`) than when it was normal (*M* = `r round(d4cf.sumO$mean[d4cf.sumO$outcome=="Normal"],digits=2)`, *SD* = `r round(d4cf.sumO$sd[d4cf.sumO$outcome=="Normal"],digits=2)`). We then looked into interaction effects for both modal and counterfactual ratings. In modal ratings, we did not find a significant *Knowledge* $\times$ *Norm* $\times$ *Outcome* interaction effect, $\chi^2(2)$ = `r round(lm4md.3way$Chisq[2],digits=3)`, *p* = `r max(.001,round(lm4md.3way$'Pr(>Chisq)'[2],digits=3))`, or a significant *Knowledge* $\times$ *Outcome* interaction effect, $\chi^2(2)$ = `r round(lm4md.OxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lm4md.OxK$'Pr(>Chisq)'[2],digits=3))`, such that participants' modal judgments did not differentiate much across conditions. As for counterfactual ratings, we did not find a significant *Knowledge* $\times$ *Norm* $\times$ *Outcome* interaction effect, $\chi^2(2)$ = `r round(lm4cf.3way$Chisq[2],digits=3)`, *p* = `r max(.001,round(lm4cf.3way$'Pr(>Chisq)'[2],digits=3))`, but we found a significant *Knowledge* $\times$ *Outcome* interaction effect, $\chi^2(2)$ = `r round(lm4cf.OxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lm4cf.OxK$'Pr(>Chisq)'[2],digits=3))`, suggesting that people's counterfactual judgment differentiated more between knowledgeable and ignorant agents when the outcome was abnormal than when it was normal.

```{r study4 plots, echo=FALSE, warning=FALSE, message=FALSE}
d4.sum <- d4 %>%
  dplyr::select(`CF responses`, question, norm, outcome, knowledge) %>%
  group_by(knowledge,norm,question,outcome) %>% 
                      summarise(N = length(`CF responses`),
                                mean = mean(as.numeric(`CF responses`), na.rm=TRUE),
                                sd = sd(as.numeric(`CF responses`),na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(cfN = N) %>%
  rename(cfMean = mean) %>%
  rename(cfSD = sd) %>%
  rename(cfSE = se)

d4.mdplot <- d4.sum[d4.sum$question=="Modal",] %>%
  ggplot(., aes(x=norm, y=cfMean, fill=knowledge)) +
  geom_bar(stat="identity", position="dodge") +
  facet_grid(~outcome) +
  scale_fill_manual(values=wes_palette("Royal1",4)) + 
  ylab("Modal Rating") +
  xlab("") +
  coord_cartesian(ylim=c(1,7)) +
  geom_errorbar(aes(ymin=cfMean-cfSE, ymax=cfMean+cfSE), width=.1, position=position_dodge(.9)) +
  theme_bw() +
  theme(
    plot.background = element_blank()
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    #,legend.position = "null"
    ,legend.title=element_blank()
    ,legend.text=element_text(size=rel(1.5))
    ,axis.text.y=element_text(size=rel(2))
    ,axis.text.x=element_text(size=rel(2))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1.5))
  )
d4.mdplot

d4.cfplot <- d4.sum[d4.sum$question=="Counterfactual",] %>%
  ggplot(., aes(x=norm, y=cfMean, fill=knowledge)) +
  geom_bar(stat="identity", position="dodge") +
  facet_grid(~outcome) +
  scale_fill_manual(values=wes_palette("Royal1",4)) + 
  ylab("Counterfactual Rating") +
  xlab("") +
  coord_cartesian(ylim=c(1,7)) +
  geom_errorbar(aes(ymin=cfMean-cfSE, ymax=cfMean+cfSE), width=.1, position=position_dodge(.9)) +
  theme_bw() +
  theme(
    plot.background = element_blank()
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    #,legend.position = "null"
    ,legend.title=element_blank()
    ,legend.text=element_text(size=rel(1.5))
    ,axis.text.y=element_text(size=rel(2))
    ,axis.text.x=element_text(size=rel(2))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1.5))
  )
d4.cfplot

########KEEP CONSISTENT? as below???!!!
# facet_grid(~norm) +
#                   geom_bar(position = "dodge",stat="identity") +
#                   geom_errorbar(aes(ymin= valenceMean - valenceSE, ymax = valenceMean + valenceSE),width=0.2,position=position_dodge(.9)) +
#                   ylab("Bad (1) ~ Good (7)") +
#                   xlab("Outcome type") +
#                   ggtitle("Valence ratings in bad or good outcomes") +
#                   scale_fill_manual("Knowledge:", values=wes_palette("Royal1",2)) + 
#                   coord_cartesian(ylim=c(1,7)) +
#                   theme_bw() +
#                   theme(
#                     plot.background = element_blank()
#                     ,plot.title=element_text(hjust=.5)
#                     ,panel.grid.major = element_blank()
#                     ,panel.grid.minor = element_blank()
#                     #,legend.position = c(.9,.85)
#                     #,legend.position = "null"
#                     ,legend.title=element_text(size=rel(1))
#                     ,legend.text=element_text(size=rel(1))
#                     ,axis.text.y=element_text(size=rel(1))
#                     ,axis.text.x=element_text(size=rel(1))
#                     ,axis.title.y=element_text(vjust=.9)
#                     ,axis.ticks = element_blank()
#                     ,axis.title=element_text(size=rel(1))
#                   )
```

```{r study4 potency & study3 causation, echo=FALSE, warning=FALSE, message=FALSE}
##For each condition in a scenario, use causal to predict cf*md --> create a new column potency
d4pot <- d4 %>%
  select(-condCod) %>%
  pivot_wider(values_from = `CF responses`, names_from = "question") %>%
  mutate(Potency = as.numeric(Modal)*as.numeric(Counterfactual)) %>%
  drop_na()

##Merge summaries of potency and causal judgment
d4pot.sum <- d4pot %>%
  dplyr::select(Potency, norm, outcome, knowledge, scenario, condition) %>%
  group_by(knowledge,norm,outcome, scenario, condition) %>% 
                      summarise(N = length(Potency),
                                mean = mean(as.numeric(Potency), na.rm=TRUE),
                                sd = sd(as.numeric(Potency),na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(potencyN = N) %>%
  rename(potencyMean = mean) %>%
  rename(potencySD = sd) %>%
  rename(potencySE = se)

d3.cspbpot.sum <- d3.cspb %>%
  dplyr::select(`causation.response`, norm, outcome, knowledge, scenario, condition) %>%
  group_by(knowledge,norm,outcome, scenario, condition) %>% 
                      summarise(N = length(`causation.response`),
                                mean = mean(as.numeric(`causation.response`), na.rm=TRUE),
                                sd = sd(as.numeric(`causation.response`),na.rm=TRUE),
                                se = sd / sqrt(N)) %>%
  dplyr::rename(causationN = N) %>%
  rename(causationMean = mean) %>%
  rename(causationSD = sd) %>%
  rename(causationSE = se)


#Test main effects of norm, knowledge, outcome (normality) + interactions, in relation to potency

##main effects (outcome and norm significant)
  # lmr4pot.main <- lmer(Potency ~ knowledge + outcome + norm + (knowledge*norm*outcome|ResponseId) + (1|condition), data=d4pot)

  # lmr4pot.outcome <- lmer(Potency ~ knowledge + norm + (knowledge*norm*outcome|ResponseId) + (1|condition), data=d4pot)
  # lmr4pot.outcome <- anova(lmr4pot.main,lmr4pot.outcome)
  # saveRDS(lmr4pot.outcome,"models/lmr4pot.outcome.rds")
lmr4pot.outcome <- readRDS("models/lmr4pot.outcome.rds")
d4pot.sumO <- d4pot %>% 
  select(outcome, Potency, ResponseId) %>%
  group_by(outcome,ResponseId) %>%
  summarise(potencyM = mean(Potency),na.rm=TRUE) %>%
  group_by(outcome) %>%
  summarise(N = length(potencyM),
           mean = mean(potencyM, na.rm=TRUE),
           sd = sd(potencyM,na.rm=TRUE),
           se = sd / sqrt(N))

  # lmr4pot.norm <- lmer(Potency ~ knowledge + outcome + (knowledge*norm*outcome|ResponseId) + (1|condition), data=d4pot)
  # lmr4pot.norm <- anova(lmr4pot.main,lmr4pot.norm)
  # saveRDS(lmr4pot.norm,"models/lmr4pot.norm.rds")
lmr4pot.norm <- readRDS("models/lmr4pot.norm.rds")

  # lmr4pot.knowledge <- lmer(Potency ~ outcome + norm + (knowledge*norm*outcome|ResponseId) + (1|condition), data=d4pot)
  # lmr4pot.knowledge <- anova(lmr4pot.main,lmr4pot.knowledge)
  # saveRDS(lmr4pot.knowledge,"models/lmr4pot.knowledge.rds")
lmr4pot.knowledge <- readRDS("models/lmr4pot.knowledge.rds")
d4pot.sumK <- d4pot %>% 
  select(knowledge, Potency, ResponseId) %>%
  group_by(knowledge,ResponseId) %>%
  summarise(potencyM = mean(Potency),na.rm=TRUE) %>%
  group_by(knowledge) %>%
  summarise(N = length(potencyM),
           mean = mean(potencyM, na.rm=TRUE),
           sd = sd(potencyM,na.rm=TRUE),
           se = sd / sqrt(N))


## three-way interaction (insignificant)
# lmr4pot.i0 <- lmer(Potency ~ knowledge * norm * outcome + (knowledge*norm*outcome|ResponseId) + (1|condition), data=d4pot)
# lmr4pot.i1 <- lmer(Potency ~ (knowledge * norm) + (outcome * knowledge) + (outcome * norm) + (knowledge*norm*outcome|ResponseId) + (1|condition), data=d4pot)
# lmr4pot.3way <- anova(lmr4pot.i0,lmr4pot.i1)
# saveRDS(lmr4pot.3way,"models/lmr4pot.3way.rds")
lmr4pot.3way <- readRDS("models/lmr4pot.3way.rds")


## two-way: Norm x Knowledge interaction (insignificant)
# lmr4pot.NK <- lmer(Potency ~ (knowledge * outcome) + (outcome * norm) + (knowledge*norm*outcome|ResponseId) + (1|condition), data=d4pot)
# lmr4pot.NxK <- anova(lmr4pot.i1, lmr4pot.NK)
# saveRDS(lmr4pot.NxK,"models/lmr4pot.NxK.rds")
lmr4pot.NxK <- readRDS("models/lmr4pot.NxK.rds")
    # d4pot %>% 
    #   group_by(knowledge,norm,ResponseId) %>% 
    #   summarise(means=mean(Potency, na.rm = T)) 

## two-way: Norm x Outcome interaction (insignificant)
# lmr4pot.NO <- lmer(Potency ~ (knowledge * outcome) + (knowledge * norm) + (knowledge*norm*outcome|ResponseId) + (1|condition), data=d4pot)
# lmr4pot.NxO <- anova(lmr4pot.i1, lmr4pot.NO)
# saveRDS(lmr4pot.NxO,"models/lmr4pot.NxO.rds")
lmr4pot.NxO <- readRDS("models/lmr4pot.NxO.rds")


## two-way: Outcome x Knowledge interaction (significant)
# lmr4pot.OK <- lmer(Potency ~ (norm * outcome) + (knowledge * norm) + (knowledge*norm*outcome|ResponseId) + (1|condition), data=d4pot)
# lmr4pot.OxK <- anova(lmr4pot.i1,lmr4pot.OK)
# saveRDS(lmr4pot.OxK,"models/lmr4pot.OxK.rds")
lmr4pot.OxK <- readRDS("models/lmr4pot.OxK.rds")

##causal ~ potency + knowledge (test whether potency is a mediator between knowledge and causation)
d3d4_cspot <- merge(d3.cspbpot.sum, d4pot.sum, by=c("knowledge", "norm", "outcome", "scenario", "condition")) 
# lmr4.cspot1 <- lme4::lmer(causationMean ~ knowledge*outcome + (1|scenario), data=d3d4_cspot)
# lmr4.cspot2 <- lme4::lmer(causationMean ~ potencyMean + knowledge*outcome + (1|scenario) , data=d3d4_cspot)
# lmr4.cspot3 <- lme4::lmer(causationMean ~ knowledge + outcome + (1|scenario), data=d3d4_cspot)
# lmr4.cspot4 <- lme4::lmer(causationMean ~ potencyMean + knowledge + outcome + (1|scenario), data=d3d4_cspot)

# lmr4.cspotmed.OxK <- mediate(lmr4.cspot1, lmr4.cspot2, treat = "knowledge", mediator = "potencyMean", robustSE = TRUE)
# saveRDS(lmr4.cspotmed.OxK, "models/lmr4.cspotmed.OxK.rds")
lmr4.cspotmed.OxK <- readRDS("models/lmr4.cspotmed.OxK.rds")
#summary(lmr4.cspotmed.OxK)

# lmr4.cspotmed.OK <- mediate(lmr4.cspot3, lmr4.cspot4, treat = "knowledge", mediator = "potencyMean", robustSE = TRUE)
# saveRDS(lmr4.cspotmed.OK, "models/lmr4.cspotmed.OK.rds")
lmr4.cspotmed.OK <- readRDS("models/lmr4.cspotmed.OK.rds")
#summary(lmr4.cspotmed.OK)


#Test interaction between potency and normality/outcome in predicting causal judgments (insignificant)
# lmr4.potoutint0 <- lmer(causationMean ~ outcome*potencyMean + (1|scenario) + (1|condition), data=d3d4_cspot)
# lmr4.potoutint1 <- lmer(causationMean ~ outcome + potencyMean + (1|scenario) + (1|condition), data=d3d4_cspot)
# lmr4.potoutint <- anova(lmr4.potoutint0, lmr4.potoutint1)
# saveRDS(lmr4.potoutint, "models/lmr4.potoutint.rds")
lmr4.potoutint <- readRDS("models/lmr4.potoutint.rds")

```

#### Potency and its relationship with causal judgments

In this part of the analysis, we constructed the measure of potency by taking the product of participants' modal rating and counterfactual rating. Embedded in this measure is the perceived likelihood of the counterfactual antecedent and the perceived likelihood of the counterfactual's outcome based on the given antecedent (Petrocelli et al., 2011). Moreover, we included participants' causal judgement from Study 3a in order to explore its relationship with potency. We first explored main effects of *Knowledge*, *Norm*, and *Outcome* on potency and we found statistical significance in both *Knowledge*, $\chi^2(2)$ = `r round(lmr4pot.knowledge$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr4pot.knowledge$'Pr(>Chisq)'[2],digits=3))`, and *Outcome*, $\chi^2(2)$ = `r round(lmr4pot.outcome$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr4pot.outcome$'Pr(>Chisq)'[2],digits=3))`. More specifically, while potency would be lower in ignorant agents (*M* = `r round(d4pot.sumK$mean[d4pot.sumK$knowledge=="Ignorance"],digits=2)`, *SD* = `r round(d4pot.sumK$sd[d4pot.sumK$knowledge=="Ignorance"],digits=2)`) than in knowledgeable agents (*M* = `r round(d4pot.sumK$mean[d4pot.sumK$knowledge=="Knowledge"],digits=2)`, *SD* = `r round(d4pot.sumK$sd[d4pot.sumK$knowledge=="Knowledge"],digits=2)`) it would be higher in abnormal outcomes (*M* = `r round(d4pot.sumO$mean[d4pot.sumO$outcome=="Abnormal"],digits=2)`, *SD* = `r round(d4pot.sumO$sd[d4pot.sumO$outcome=="Abnormal"],digits=2)`) than in normal outcomes (*M* = `r round(d4pot.sumO$mean[d4pot.sumO$outcome=="Normal"],digits=2)`, *SD* = `r round(d4pot.sumO$sd[d4pot.sumO$outcome=="Normal"],digits=2)`). In addition, we found a *Knowledge* $\times$ *Outcome* interaction for potency, $\chi^2(2)$ = `r round(lmr4pot.OxK$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr4pot.OxK$'Pr(>Chisq)'[2],digits=3))`, suggesting that potency tends to differentiate more between ignorant and knowledgeable agents in abnormal outcomes than in normal outcomes. Our analysis also shows that potency is a mediator between *Knowledge*, *Outcome* and *Causal Judgment*, (*ACME* = .034, *p* $<$ .001). We did not, however, find an interaction between potency and normality of outcome (defined by probability of occurrence) in predicting causal judgments, $\chi^2(2)$ = `r round(lmr4.potoutint$Chisq[2],digits=3)`, *p* = `r max(.001,round(lmr4.potoutint$'Pr(>Chisq)'[2],digits=3))`.

```{r pot & cspot plots [in case of use], echo=FALSE, warning=FALSE, message=FALSE}
#####by knowledge
# d4pot %>%
#   dplyr::select(Potency, norm, outcome, knowledge, scenario) %>%
#   group_by(knowledge,norm,outcome, scenario) %>% 
#                       summarise(N = length(Potency),
#                                 mean = mean(as.numeric(Potency), na.rm=TRUE),
#                                 sd = sd(as.numeric(Potency),na.rm=TRUE),
#                                 se = sd / sqrt(N)) %>%
#   dplyr::rename(potencyN = N) %>%
#   rename(potencyMean = mean) %>%
#   rename(potencySD = sd) %>%
#   rename(potencySE = se) %>%
#   ggplot(aes(x=scenario, y=potencyMean, color=knowledge)) +
#   geom_point()
# 
# d3d4_cspot %>%
#   dplyr::select(potencyMean, causationMean, knowledge, scenario, outcome) %>%
#   ggplot(aes(x=causationMean, y=potencyMean, color=knowledge)) +
#   facet_wrap(~outcome) +
#   geom_point() +
#   geom_smooth(method="lm")
##can add label for scenario (number)


d4pot.plot <- d4pot %>%
    dplyr::select(Potency, norm, outcome, knowledge,condition) %>%
    group_by(knowledge,norm,outcome, condition) %>% 
    summarise(N = length(Potency),
              mean = mean(as.numeric(Potency), na.rm=TRUE),
              sd = sd(as.numeric(Potency),na.rm=TRUE),
              se = sd / sqrt(N)) %>%
    dplyr::rename(potencyN = N) %>%
    rename(potencyMean = mean) %>%
    rename(potencySD = sd) %>%
    rename(potencySE = se) %>%
  ggplot(., aes(x=norm, y=potencyMean, fill=knowledge)) +
  geom_bar(stat="identity", position="dodge") +
  facet_grid(~outcome) +
  scale_fill_manual(values=wes_palette("Royal1",4)) + 
  ylab("Potency") +
  xlab("") +
  geom_errorbar(aes(ymin=potencyMean-potencySE, ymax=potencyMean+potencySE), width=.1, position=position_dodge(.9)) +
  theme_bw() +
  theme(
    plot.background = element_blank()
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    #,legend.position = "null"
    ,legend.title=element_blank()
    ,legend.text=element_text(size=rel(1.5))
    ,axis.text.y=element_text(size=rel(2))
    ,axis.text.x=element_text(size=rel(2))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1.5))
  )
d4pot.plot


d3d4cspot.plot <- d3d4_cspot %>%
  dplyr::select(potencyMean, causationMean, knowledge, scenario, outcome) %>%
  ggplot(aes(x=causationMean, y=potencyMean, color=knowledge)) +
  facet_wrap(~outcome) +
  geom_point() +
  geom_smooth(method="lm") +
  scale_fill_manual(values=wes_palette("Royal1",3)) + 
  ylab("Potency") +
  xlab("Causal Judgment") +
   theme_bw() +
  theme(
    plot.background = element_blank()
    ,panel.grid.major = element_blank()
    ,panel.grid.minor = element_blank()
    #,legend.position = "null"
    ,legend.title=element_blank()
    ,legend.text=element_text(size=rel(1.5))
    ,axis.text.y=element_text(size=rel(2))
    ,axis.text.x=element_text(size=rel(2))
    ,axis.title.y=element_text(vjust=.9)
    ,axis.ticks = element_blank()
    ,axis.title=element_text(size=rel(1.5))
  )
d3d4cspot.plot
```

New Citations: Petrocelli, J. V., Percy, E. J., Sherman, S. J., & Tormala, Z. L. (2011). Counterfactual potency. Journal of personality and social psychology, 100(1), 30--46. <https://doi.org/10.1037/a0021523>)
